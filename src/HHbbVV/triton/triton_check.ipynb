{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Dict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tritonclient.grpc as triton_grpc\n",
    "import tritonclient.http as triton_http\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from https://github.com/lgray/hgg-coffea/blob/triton-bdts/src/hgg_coffea/tools/chained_quantile.py\n",
    "class wrapped_triton:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_url: str,\n",
    "    ) -> None:\n",
    "        fullprotocol, location = model_url.split(\"://\")\n",
    "        _, protocol = fullprotocol.split(\"+\")\n",
    "        address, model, version = location.split(\"/\")\n",
    "\n",
    "        self._protocol = protocol\n",
    "        self._address = address\n",
    "        self._model = model\n",
    "        self._version = version\n",
    "\n",
    "    def __call__(self, input_dict: Dict[str, np.ndarray]) -> np.ndarray:\n",
    "        if self._protocol == \"grpc\":\n",
    "            client = triton_grpc.InferenceServerClient(url=self._address, verbose=False)\n",
    "            triton_protocol = triton_grpc\n",
    "        elif self._protocol == \"http\":\n",
    "            client = triton_http.InferenceServerClient(\n",
    "                url=self._address,\n",
    "                verbose=False,\n",
    "                concurrency=12,\n",
    "            )\n",
    "            triton_protocol = triton_http\n",
    "        else:\n",
    "            raise ValueError(f\"{self._protocol} does not encode a valid protocol (grpc or http)\")\n",
    "\n",
    "        # Infer\n",
    "        inputs = []\n",
    "\n",
    "        for key in input_dict:\n",
    "            input = triton_protocol.InferInput(key, input_dict[key].shape, \"FP32\")\n",
    "            input.set_data_from_numpy(input_dict[key])\n",
    "            inputs.append(input)\n",
    "\n",
    "        output = triton_protocol.InferRequestedOutput(\"softmax\")\n",
    "\n",
    "        request = client.infer(\n",
    "            self._model,\n",
    "            model_version=self._version,\n",
    "            inputs=inputs,\n",
    "            outputs=[output],\n",
    "        )\n",
    "\n",
    "        out = request.as_numpy(\"softmax\")\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "# pfs = 100\n",
    "# svs = 7\n",
    "pfs = 128\n",
    "svs = 10\n",
    "\n",
    "# input_dict = {\n",
    "#     \"pf_points\": np.random.rand(batch_size, 2, pfs).astype(\"float32\"),\n",
    "#     \"pf_features\": np.random.rand(batch_size, 19, pfs).astype(\"float32\"),\n",
    "#     \"pf_mask\": (np.random.rand(batch_size, 1, pfs) > 0.2).astype(\"float32\"),\n",
    "#     \"sv_points\": np.random.rand(batch_size, 2, svs).astype(\"float32\"),\n",
    "#     \"sv_features\": np.random.rand(batch_size, 11, svs).astype(\"float32\"),\n",
    "#     \"sv_mask\": (np.random.rand(batch_size, 1, svs) > 0.2).astype(\"float32\"),\n",
    "# }\n",
    "\n",
    "input_dict = {\n",
    "    \"pf_features\": np.random.rand(batch_size, 25, pfs).astype(\"float32\"),\n",
    "    \"pf_vectors\": np.random.rand(batch_size, 4, pfs).astype(\"float32\"),\n",
    "    \"pf_mask\": (np.random.rand(batch_size, 1, pfs) > 0.2).astype(\"float32\"),\n",
    "    \"sv_features\": np.random.rand(batch_size, 11, svs).astype(\"float32\"),\n",
    "    \"sv_vectors\": np.random.rand(batch_size, 4, svs).astype(\"float32\"),\n",
    "    \"sv_mask\": (np.random.rand(batch_size, 1, svs) > 0.2).astype(\"float32\"),\n",
    "}\n",
    "\n",
    "# input_dict = {\n",
    "#     \"pf_points__0\": np.random.rand(batch_size, 2, pfs).astype(\"float32\"),\n",
    "#     \"pf_features__1\": np.random.rand(batch_size, 19, pfs).astype(\"float32\"),\n",
    "#     \"pf_mask__2\": (np.random.rand(batch_size, 1, pfs) > 0.2).astype(\"float32\"),\n",
    "#     \"sv_points__3\": np.random.rand(batch_size, 2, svs).astype(\"float32\"),\n",
    "#     \"sv_features__4\": np.random.rand(batch_size, 11, svs).astype(\"float32\"),\n",
    "#     \"sv_mask__5\": (np.random.rand(batch_size, 1, svs) > 0.2).astype(\"float32\"),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.85230140e-04  2.15207180e-03  1.54539419e-03  4.45811916e-03\n",
      "   4.36031818e-03  2.87689827e-02  4.50783918e-05  2.07938254e-04\n",
      "   1.43657178e-02  1.15830921e-01  8.53165329e-05  2.84879375e-03\n",
      "   6.13200059e-03  1.18893813e-02  6.13800330e-06  4.22881676e-05\n",
      "   5.42556569e-02  5.57915047e-02  2.41703703e-03  2.60232016e-03\n",
      "   1.62428751e-05  4.68920407e-05  4.61138058e-07  1.10413991e-01\n",
      "   5.05645536e-02  1.00873776e-01  3.43784019e-02  3.10834255e-02\n",
      "   1.22029074e-02  5.25399446e-02  8.64188820e-02  1.05023786e-01\n",
      "   5.61055203e-04  9.55004618e-02  2.67956231e-04  8.01808725e-04\n",
      "   1.06152203e-02  7.55188293e+01 -2.86533618e+00 -2.83437681e+00\n",
      "   6.32742703e-01 -1.67260396e+00  8.82147968e-01  1.15630671e-01\n",
      "   2.15264723e-01  2.29086235e-01  1.25586379e+00  6.61229432e-01\n",
      "  -2.39497113e+00  1.61977410e-01  8.29905927e-01  1.01231778e+00\n",
      "   4.86270577e-01 -3.73178899e-01  1.53381646e-01 -3.12015861e-01\n",
      "  -1.14642099e-01  1.96895230e+00 -1.53730050e-01  1.35994267e+00\n",
      "   3.33601207e-01 -1.49197683e-01 -4.72644448e-01  1.28970361e+00\n",
      "  -1.30774021e+00  8.83046985e-02  8.39880347e-01  5.27690172e+00\n",
      "   3.79302472e-01  1.65501088e-02 -1.96537942e-01  1.64017260e-01\n",
      "  -1.59982130e-01 -1.49916136e+00  1.70633554e+00 -3.08335871e-01\n",
      "   8.09714854e-01  9.42276865e-02  2.24992648e-01 -1.15160358e+00\n",
      "  -1.17536092e+00  6.69794381e-01 -1.03506960e-01  2.27757454e+00\n",
      "   9.76266921e-01  4.53054100e-01 -1.76735616e+00 -1.46879971e+00\n",
      "   7.49381125e-01 -1.11970007e-01 -9.24355149e-01 -3.12018007e-01\n",
      "  -5.24635017e-01 -2.60192251e+00  1.33871734e+00 -3.71671081e-01\n",
      "   1.24008512e+00  2.00322330e-01 -1.44932413e+00  1.70309871e-01\n",
      "  -6.22573853e-01 -1.53424811e+00 -1.29966438e+00 -3.88756618e-02\n",
      "  -2.74877763e+00 -4.98508662e-02  7.44614840e+00  6.21213615e-01\n",
      "   4.83078718e-01  1.10314882e+00 -8.75781119e-01  8.30596626e-01\n",
      "  -1.25262237e+00 -1.00358903e+00 -1.31511605e+00  1.26250550e-01\n",
      "  -4.81774569e-01  2.54647862e-02 -1.16161120e+00  7.90250242e-01\n",
      "  -9.79016972e+00  6.84527576e-01 -1.40357256e+00 -2.38521266e+00\n",
      "  -2.89408088e-01  2.35257149e+00 -2.78766483e-01 -3.31898594e+00\n",
      "   8.64161193e-01  1.31162870e+00  1.69009781e+00  8.38672400e-01\n",
      "  -4.19918686e-01 -8.17161024e-01  2.69863796e+00  1.19108367e+00\n",
      "  -1.27819717e+00 -1.14266360e+00 -1.68610603e-01 -3.01708460e-01\n",
      "  -3.05874020e-01 -2.71787494e-01 -1.56714487e+00 -4.45584476e-01\n",
      "  -6.68629587e-01 -2.87060380e-01  1.99759230e-01  1.81680024e+00\n",
      "   9.65127409e-01 -4.35057312e-01  1.94863677e+00 -7.84324229e-01\n",
      "   1.03157830e+00  3.91336411e-01 -5.92015922e-01  1.36990917e+00\n",
      "   5.64438462e-01 -5.85612357e-01 -1.18976094e-01 -1.18897760e+00\n",
      "   5.07232606e-01  2.41240606e-01 -4.78596449e-01 -1.93995571e+00\n",
      "   1.94461465e+00  1.08616602e+00]]\n"
     ]
    }
   ],
   "source": [
    "# model_url = \"triton+grpc://ailab01.fnal.gov:8001/particlenet_hww/1\"\n",
    "# model_url = \"triton+grpc://prp-gpu-1.t2.ucsd.edu:8001/particlenet_hww/1\"\n",
    "model_url = \"triton+grpc://67.58.49.52:8001/ak8_MD_vminclv2ParT_manual_fixwrap/1\"\n",
    "# model_url = \"triton+grpc://localhost:8001/particlenet_hww_ul_4q_3q/1\"\n",
    "# model_url = \"triton+grpc://67.58.49.52:8001/particlenet_hww_ul_4q_3q/1\"\n",
    "triton_model = wrapped_triton(model_url)\n",
    "output = triton_model(input_dict)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[8.85232002e-04, 2.15207506e-03, 1.54539733e-03, 4.45813034e-03,\n",
      "        4.36032098e-03, 2.87691113e-02, 4.50789557e-05, 2.07940859e-04,\n",
      "        1.43656582e-02, 1.15830332e-01, 8.53175952e-05, 2.84882332e-03,\n",
      "        6.13200106e-03, 1.18893655e-02, 6.13805332e-06, 4.22883531e-05,\n",
      "        5.42557947e-02, 5.57915345e-02, 2.41703819e-03, 2.60232110e-03,\n",
      "        1.62429624e-05, 4.68914222e-05, 4.61137432e-07, 1.10414192e-01,\n",
      "        5.05647399e-02, 1.00873932e-01, 3.43785509e-02, 3.10834944e-02,\n",
      "        1.22029325e-02, 5.25400266e-02, 8.64187554e-02, 1.05023898e-01,\n",
      "        5.61060035e-04, 9.54999030e-02, 2.67956406e-04, 8.01815011e-04,\n",
      "        1.06151653e-02]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "onnx_model = onnx.load(\"model.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "ort_sess = ort.InferenceSession('model.onnx')\n",
    "outputs = ort_sess.run(None, input_dict)\n",
    "print(outputs)\n",
    "\n",
    "# Print Result \n",
    "# predicted, actual = classes[outputs[0][0].argmax(0)], classes[y]\n",
    "# print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 166)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ParticleTransformerHidden import ParticleTransformerTagger\n",
    "\n",
    "part_model = ParticleTransformerTagger(\n",
    "    pf_input_dim=25,\n",
    "    sv_input_dim=11,\n",
    "    num_classes=37 + 1, # one dim for regression\n",
    "    # network configurations\n",
    "    pair_input_dim=4,\n",
    "    embed_dims=[128, 512, 128],\n",
    "    pair_embed_dims=[64, 64, 64],\n",
    "    num_heads=8,\n",
    "    num_layers=8,\n",
    "    num_cls_layers=2,\n",
    "    block_params=None,\n",
    "    cls_block_params={'dropout': 0, 'attn_dropout': 0, 'activation_dropout': 0},\n",
    "    fc_params=[],\n",
    "    activation='gelu',\n",
    "    # misc\n",
    "    trim=True,\n",
    "    for_inference=True,\n",
    ").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/python310/lib/python3.10/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "/opt/anaconda3/envs/python310/lib/python3.10/site-packages/torch/nn/functional.py:5046: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert embed_dim == embed_dim_to_check, \\\n",
      "/opt/anaconda3/envs/python310/lib/python3.10/site-packages/torch/nn/functional.py:5053: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert head_dim * num_heads == embed_dim, f\"embed_dim {embed_dim} not divisible by num_heads {num_heads}\"\n",
      "/opt/anaconda3/envs/python310/lib/python3.10/site-packages/torch/nn/functional.py:5059: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert key.shape == value.shape, f\"key shape {key.shape} does not match value shape {value.shape}\"\n",
      "/opt/anaconda3/envs/python310/lib/python3.10/site-packages/torch/nn/functional.py:5093: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_mask.shape != correct_3d_size:\n",
      "/opt/anaconda3/envs/python310/lib/python3.10/site-packages/torch/nn/functional.py:5155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert key_padding_mask.shape == (bsz, src_len), \\\n",
      "/opt/anaconda3/envs/python310/lib/python3.10/site-packages/torch/nn/functional.py:4849: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  q = q / math.sqrt(E)\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n"
     ]
    }
   ],
   "source": [
    "part_model.load_state_dict(torch.load(\"net_best_epoch_state.pt\", map_location=torch.device(\"cpu\")))\n",
    "_ = part_model.eval()\n",
    "\n",
    "data_config = {\n",
    "    \"input_names\": [\"pf_features\", \"pf_vectors\", \"pf_mask\", \"sv_features\", \"sv_vectors\", \"sv_mask\"],\n",
    "    \"input_shapes\": {\n",
    "        \"pf_features\": (-1, 25, pfs),\n",
    "        \"pf_vectors\": (-1, 4, pfs),\n",
    "        \"pf_mask\": (-1, 1, pfs),\n",
    "        \"sv_features\": (-1, 11, svs),\n",
    "        \"sv_vectors\": (-1, 4, svs),\n",
    "        \"sv_mask\": (-1, 1, svs),\n",
    "    },\n",
    "}\n",
    "\n",
    "model_info = {\n",
    "    \"input_names\": list(data_config[\"input_names\"]),\n",
    "    \"input_shapes\": {k: ((1,) + s[1:]) for k, s in data_config[\"input_shapes\"].items()},\n",
    "    \"output_names\": [\"softmax\"],\n",
    "    \"dynamic_axes\": {\n",
    "        **{k: {0: \"N\", 2: \"n_\" + k.split(\"_\")[0]} for k in data_config[\"input_names\"]},\n",
    "        **{\"softmax\": {0: \"N\"}},\n",
    "    },\n",
    "}\n",
    "\n",
    "inputs = tuple(\n",
    "    torch.ones(model_info[\"input_shapes\"][k], dtype=torch.float32)\n",
    "    for k in model_info[\"input_names\"]\n",
    ")\n",
    "torch.onnx.export(\n",
    "    part_model,\n",
    "    inputs,\n",
    "    \"model.onnx\",\n",
    "    input_names=model_info[\"input_names\"],\n",
    "    output_names=model_info[\"output_names\"],\n",
    "    dynamic_axes=model_info.get(\"dynamic_axes\", None),\n",
    "    opset_version=11,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5299e-03,  2.9319e-03,  1.9769e-03,  5.4878e-03,  7.8053e-03,\n",
      "          1.2931e-02,  1.3580e-04,  6.4316e-05,  5.6223e-03,  3.5439e-03,\n",
      "          5.7096e-05,  7.1246e-05,  2.4305e-03,  7.1927e-04,  4.5472e-05,\n",
      "          2.3293e-05,  7.5924e-02,  3.5818e-02,  8.9561e-03,  9.3922e-03,\n",
      "          4.7991e-06,  2.2116e-05,  4.7249e-07,  9.0073e-02,  4.4058e-02,\n",
      "          1.9110e-01,  5.3661e-02,  8.5326e-02,  2.5597e-02,  6.6441e-02,\n",
      "          1.0755e-01,  1.1822e-01,  5.6389e-04,  2.4701e-02,  1.2583e-03,\n",
      "          8.0306e-04,  1.5152e-02,  1.1746e+02, -1.4494e+00, -3.8877e+00,\n",
      "         -4.1724e-01, -2.1862e+00,  4.6684e-01,  2.2150e-01,  2.5049e-01,\n",
      "          1.4588e+00,  5.7455e-01,  6.8124e-01, -2.3397e+00, -7.7287e-01,\n",
      "          7.0747e-01,  1.9500e+00, -3.2054e-01, -3.3750e-01, -3.7859e-01,\n",
      "         -3.5869e-01,  8.4656e-01,  2.2947e+00, -5.7608e-01,  1.1714e+00,\n",
      "         -9.2651e-02, -8.0103e-01,  2.5926e-02,  1.4265e+00, -2.4823e+00,\n",
      "          1.6136e+00,  1.8963e+00,  6.2551e+00,  6.8286e-01, -3.8628e-01,\n",
      "         -1.1575e+00,  6.8476e-01,  8.5872e-01, -7.8506e-01,  2.7799e+00,\n",
      "          4.6129e-01,  7.1114e-01, -3.3843e-02, -5.5794e-01, -2.9919e-01,\n",
      "         -1.4846e+00,  4.3219e-01, -1.4646e-01,  1.8458e+00, -2.4080e-01,\n",
      "          1.0279e+00, -1.6629e+00, -7.0566e-01, -1.8657e-01, -7.4921e-02,\n",
      "         -1.1353e+00,  1.0703e-01,  2.0712e-01, -2.2964e+00,  1.6433e+00,\n",
      "          8.9940e-02,  3.7805e-01, -2.2146e+00, -5.3493e-01, -4.0156e-02,\n",
      "         -5.8408e-01, -8.0333e-01, -2.4586e+00,  9.8550e-02, -3.2820e+00,\n",
      "         -1.4683e+00,  7.9389e+00,  6.2665e-01,  1.6939e-01,  1.1479e+00,\n",
      "         -3.5398e-01,  3.5816e-01, -1.0650e+00, -1.2613e+00, -1.1165e+00,\n",
      "         -1.5212e-01, -7.9048e-01, -2.9893e-02, -1.7999e+00,  4.1555e-01,\n",
      "         -9.1506e+00,  2.9598e-01, -1.1166e-01, -2.2689e+00, -4.0743e-01,\n",
      "          2.9964e+00,  1.1030e+00, -4.7359e+00,  1.6196e-01,  9.1396e-01,\n",
      "          1.6023e+00,  9.6509e-01,  1.3732e-02, -1.0029e+00,  2.4971e+00,\n",
      "          1.9553e+00, -1.7973e+00, -1.4033e+00, -7.1935e-01, -2.5925e-01,\n",
      "         -2.3469e-01, -8.4961e-01, -5.0476e-01, -6.1761e-01, -9.6350e-01,\n",
      "         -1.0327e+00,  5.3326e-01,  3.7144e+00,  5.2717e-01,  7.0532e-01,\n",
      "          2.7586e-01, -7.5351e-01,  9.4370e-01,  2.7028e-01, -9.8784e-02,\n",
      "         -3.4679e-01,  1.8617e-01, -3.3025e-01,  5.8429e-02,  1.1500e-01,\n",
      "          2.0636e-01,  4.2734e-01,  5.0767e-02, -1.4037e+00,  2.5175e+00,\n",
      "          1.6230e+00]], grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/python310/lib/python3.10/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "in_tensors = [torch.Tensor(val) for key, val in input_dict.items()]\n",
    "in_tensors[2] = in_tensors[2].bool()\n",
    "in_tensors[5] = in_tensors[5].bool()\n",
    "\n",
    "out = part_model(*in_tensors)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.52987312e-03,  2.93191988e-03,  1.97693706e-03,\n",
       "         5.48777496e-03,  7.80526781e-03,  1.29312817e-02,\n",
       "         1.35801572e-04,  6.43163876e-05,  5.62225794e-03,\n",
       "         3.54393735e-03,  5.70958327e-05,  7.12459951e-05,\n",
       "         2.43050908e-03,  7.19271193e-04,  4.54720794e-05,\n",
       "         2.32931434e-05,  7.59244114e-02,  3.58182155e-02,\n",
       "         8.95608403e-03,  9.39224847e-03,  4.79914434e-06,\n",
       "         2.21154678e-05,  4.72491791e-07,  9.00733918e-02,\n",
       "         4.40584160e-02,  1.91101983e-01,  5.36605977e-02,\n",
       "         8.53259340e-02,  2.55966950e-02,  6.64411336e-02,\n",
       "         1.07548602e-01,  1.18220098e-01,  5.63886017e-04,\n",
       "         2.47012507e-02,  1.25828688e-03,  8.03059200e-04,\n",
       "         1.51520669e-02,  1.17462372e+02, -1.44942522e+00,\n",
       "        -3.88765955e+00, -4.17238146e-01, -2.18617630e+00,\n",
       "         4.66837943e-01,  2.21496135e-01,  2.50485390e-01,\n",
       "         1.45877016e+00,  5.74553132e-01,  6.81239963e-01,\n",
       "        -2.33971190e+00, -7.72875249e-01,  7.07470357e-01,\n",
       "         1.94998372e+00, -3.20540398e-01, -3.37501228e-01,\n",
       "        -3.78589600e-01, -3.58688295e-01,  8.46563578e-01,\n",
       "         2.29472423e+00, -5.76084495e-01,  1.17144680e+00,\n",
       "        -9.26510617e-02, -8.01026106e-01,  2.59260591e-02,\n",
       "         1.42652380e+00, -2.48230267e+00,  1.61363983e+00,\n",
       "         1.89631426e+00,  6.25512600e+00,  6.82864428e-01,\n",
       "        -3.86280149e-01, -1.15748513e+00,  6.84761107e-01,\n",
       "         8.58720064e-01, -7.85056114e-01,  2.77994680e+00,\n",
       "         4.61292177e-01,  7.11136281e-01, -3.38433571e-02,\n",
       "        -5.57939529e-01, -2.99192607e-01, -1.48460102e+00,\n",
       "         4.32187229e-01, -1.46460190e-01,  1.84582233e+00,\n",
       "        -2.40803346e-01,  1.02788234e+00, -1.66289389e+00,\n",
       "        -7.05655456e-01, -1.86570972e-01, -7.49205500e-02,\n",
       "        -1.13534272e+00,  1.07026987e-01,  2.07119957e-01,\n",
       "        -2.29636812e+00,  1.64329708e+00,  8.99407342e-02,\n",
       "         3.78047019e-01, -2.21461058e+00, -5.34928858e-01,\n",
       "        -4.01555151e-02, -5.84082127e-01, -8.03329110e-01,\n",
       "        -2.45860362e+00,  9.85501930e-02, -3.28197074e+00,\n",
       "        -1.46827316e+00,  7.93893337e+00,  6.26650393e-01,\n",
       "         1.69391245e-01,  1.14793801e+00, -3.53978753e-01,\n",
       "         3.58162254e-01, -1.06499791e+00, -1.26129329e+00,\n",
       "        -1.11649430e+00, -1.52122587e-01, -7.90478647e-01,\n",
       "        -2.98935622e-02, -1.79986322e+00,  4.15549010e-01,\n",
       "        -9.15061665e+00,  2.95982957e-01, -1.11661263e-01,\n",
       "        -2.26893806e+00, -4.07427788e-01,  2.99639583e+00,\n",
       "         1.10301161e+00, -4.73590517e+00,  1.61961943e-01,\n",
       "         9.13960874e-01,  1.60228312e+00,  9.65091646e-01,\n",
       "         1.37326941e-02, -1.00292659e+00,  2.49710369e+00,\n",
       "         1.95532024e+00, -1.79733491e+00, -1.40328312e+00,\n",
       "        -7.19354153e-01, -2.59252250e-01, -2.34689966e-01,\n",
       "        -8.49607408e-01, -5.04762590e-01, -6.17605746e-01,\n",
       "        -9.63499486e-01, -1.03271711e+00,  5.33264279e-01,\n",
       "         3.71438241e+00,  5.27171910e-01,  7.05322683e-01,\n",
       "         2.75861830e-01, -7.53513157e-01,  9.43696380e-01,\n",
       "         2.70279795e-01, -9.87844542e-02, -3.46789420e-01,\n",
       "         1.86171070e-01, -3.30248594e-01,  5.84291182e-02,\n",
       "         1.14996746e-01,  2.06357971e-01,  4.27338094e-01,\n",
       "         5.07665314e-02, -1.40367317e+00,  2.51749849e+00,\n",
       "         1.62298036e+00]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.1155e-04,  2.0606e-03,  1.5020e-03,  2.6562e-03,  9.1622e-03,\n",
       "          3.2599e-03,  1.4781e-03,  9.5434e-04,  3.3028e-04,  6.9261e-04,\n",
       "          8.2008e-04,  9.9679e-04,  1.7369e-04,  2.3844e-04,  3.0242e-04,\n",
       "          3.9385e-04,  4.7146e-03,  1.8696e-03,  1.0828e-03,  8.7911e-04,\n",
       "          1.6338e-04,  4.5681e-05,  9.7771e-06,  1.5454e-01,  3.1454e-02,\n",
       "          3.7411e-02,  1.8826e-02,  9.6202e-02,  1.1759e-02,  4.5734e-02,\n",
       "          2.2030e-01,  1.1428e-01,  6.0745e-02,  5.3709e-02,  2.1316e-02,\n",
       "          4.7606e-02,  5.1513e-02,  4.4246e+01, -2.1041e-02, -3.4620e+00,\n",
       "         -5.6576e-02,  2.3017e-01, -4.3493e-01, -4.8431e-01,  5.6465e-02,\n",
       "         -5.0499e-01,  8.3038e-02,  2.3239e-01, -1.3889e+00,  1.7120e+00,\n",
       "          1.3771e-01, -1.2663e+00,  6.6230e-01,  7.4898e-02, -3.1588e-01,\n",
       "          3.6870e-01, -6.8668e-01,  1.6357e+00, -8.1999e-01,  2.1713e-01,\n",
       "          6.4083e-01,  8.7478e-01,  9.4118e-01, -4.9381e-01, -1.2368e+00,\n",
       "          1.0730e+00,  1.7268e+00,  3.7660e+00, -6.7726e-01,  8.4824e-01,\n",
       "          4.6144e-01,  2.0225e-01,  1.7881e+00,  1.9420e-01,  1.8283e+00,\n",
       "          9.1964e-01,  5.5956e-01, -4.7744e-01, -5.5663e-01, -5.8612e-01,\n",
       "         -1.4102e+00,  2.4762e-01,  6.0904e-01,  3.9106e-01,  5.6764e-01,\n",
       "          1.3071e-01,  2.4557e-01, -4.7081e-02,  2.8010e-01,  4.1005e-01,\n",
       "         -3.8123e-01, -2.4296e-01,  6.7043e-02, -1.6497e+00,  8.9188e-01,\n",
       "         -3.1135e-01, -1.0625e-02, -3.0718e+00, -5.4417e-01,  2.4900e-02,\n",
       "          4.6762e-01,  1.0117e-01, -3.3451e+00, -5.2773e-01, -4.1818e+00,\n",
       "         -2.4967e-01,  7.9518e+00, -2.8008e-01, -3.0822e-01,  3.9351e-01,\n",
       "         -2.2870e-01, -4.7540e-02, -2.3264e-01, -3.3452e-01, -2.4542e-01,\n",
       "         -1.0442e+00,  7.3891e-01,  5.5050e-01, -1.6255e+00, -4.6427e-02,\n",
       "         -6.1029e+00, -6.0916e-01, -7.7775e-01, -2.9953e+00, -7.7228e-01,\n",
       "          9.6793e-01, -9.4810e-01, -1.9821e+00,  1.9788e-01, -1.3584e-01,\n",
       "          2.5486e+00,  2.9703e-01,  2.3074e-01, -1.8084e-01, -4.3078e-01,\n",
       "          6.9299e-01, -1.9842e+00, -7.0539e-01, -2.4653e-01, -9.6330e-01,\n",
       "         -7.8405e-01, -8.5037e-01, -9.2285e-01, -5.4372e-01,  1.0601e+00,\n",
       "          6.9960e-02, -8.5179e-01,  4.2882e+00,  6.4952e-02, -3.8099e-01,\n",
       "          1.5795e+00,  8.3206e-02,  6.9494e-01, -5.4985e-01,  2.3210e-02,\n",
       "          6.0039e-01, -2.0198e-01, -2.7308e-01, -2.6412e-01,  5.0381e-01,\n",
       "         -5.9945e-01,  2.0151e-02,  3.9549e-01, -5.9732e-01,  2.6158e+00,\n",
       "          1.5727e+00]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31a7b1cb5f073f7a7d37b3db504c6954ce2b88e0f82e412b65ad0b5f2dd17394"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
