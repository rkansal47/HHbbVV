{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse, combine and interpolate limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import mplhep as hep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import interpolate\n",
    "from tqdm import tqdm\n",
    "\n",
    "from HHbbVV.hh_vars import res_sigs\n",
    "from HHbbVV.postprocessing import plotting\n",
    "from HHbbVV.postprocessing.utils import mxmy\n",
    "from HHbbVV.resonant import ProcessLimits\n",
    "from HHbbVV.resonant.ProcessLimits import get_lim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = \"../../../\"\n",
    "plot_dir = Path(f\"{MAIN_DIR}/plots/XHY/Limits/25Feb22Unblinding\")\n",
    "plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# cards_dir = Path(\"/eos/uscms/store/user/rkansal/bbVV/cards/25Feb27QCDTF\")\n",
    "cards_dir = Path(\"/eos/uscms/store/user/rkansal/bbVV/cards/25Feb19ResUnblinded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load / process limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = ProcessLimits.get_limits(cards_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Amitav's limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alimits_path = Path(\n",
    "    \"/uscms/home/ammitra/nobackup/2DAlphabet/fitting/CMSSW_14_1_0_pre4/src/XHYbbWW/limits/\"\n",
    ")\n",
    "alimits = {\n",
    "    \" 2.5\": [],\n",
    "    \"16.0\": [],\n",
    "    \"50.0\": [],\n",
    "    \"84.0\": [],\n",
    "    \"97.5\": [],\n",
    "    \"Observed\": [],\n",
    "    \"Significance\": [],\n",
    "}\n",
    "key_map = {\n",
    "    # mine: amitav's\n",
    "    \" 2.5\": \"limits_Minus2\",\n",
    "    \"16.0\": \"limits_Minus1\",\n",
    "    \"50.0\": \"limits_Expected\",\n",
    "    \"84.0\": \"limits_Plus1\",\n",
    "    \"97.5\": \"limits_Plus2\",\n",
    "    \"Observed\": \"limits_OBSERVED\",\n",
    "    \"Significance\": \"significance\",\n",
    "}\n",
    "\n",
    "for mkey, akey in key_map.items():\n",
    "    alimits[mkey] = pd.read_csv(alimits_path / f\"{akey}.csv\").values[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min expected limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(limits[\"50.0\"][:, 2]))\n",
    "print(np.min(alimits[\"50.0\"][:, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking excesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twosigma = limits[\"97.5\"][:, 2] < limits[\"Observed\"][:, 2]\n",
    "\n",
    "for i in range(np.sum(twosigma)):\n",
    "    mx, my = limits[\"50.0\"][twosigma][i][:2]\n",
    "    print(\n",
    "        f\"({mx}, {my}):\\t Expected {limits['50.0'][twosigma][i, 2]}+{limits['97.5'][twosigma][i, 2]}\\t Observed {limits['Observed'][twosigma][i, 2]:.2f}\\t Sign {limits['Significance'][twosigma][i, 2]:.2f}\"\n",
    "    )\n",
    "\n",
    "# print(limits[\"50.0\"][twosigma], limits[\"97.5\"][twosigma], limits[\"Observed\"][twosigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alimits[\"Significance\"][np.argmax(alimits[\"Significance\"][:, 2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosted alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymax = 250\n",
    "mxs = np.logspace(np.log10(600), np.log10(3999), 100, base=10)\n",
    "mys = np.logspace(np.log10(60), np.log10(mymax), 100, base=10)\n",
    "\n",
    "xx, yy = np.meshgrid(mxs, mys)\n",
    "\n",
    "interpolated = {}\n",
    "grids = {}\n",
    "\n",
    "for key, val in limits.items():\n",
    "    interpolated[key] = interpolate.LinearNDInterpolator(val[:, :2], np.log(val[:, 2]))\n",
    "    grids[key] = np.exp(interpolated[key](xx, yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, grid in grids.items():\n",
    "    label = (\n",
    "        f\"{key}% expected exclusion limits (fb)\"\n",
    "        if key != \"50.0\"\n",
    "        else \"Median expected exclusion limits (fb)\"\n",
    "    )\n",
    "    plotting.colormesh(xx, yy, grid, label, f\"{plot_dir}/upper{mymax}_mesh_{key}_turbo.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"50.0\"\n",
    "val = limits[key]\n",
    "plotting.scatter2d(val, f\"Median expected exclusion limits (fb)\", f\"{plot_dir}/scatter_{key}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whose expected limit is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_better = []\n",
    "alim_med = alimits[\"50.0\"]\n",
    "\n",
    "for mx, my, lim in limits[\"50.0\"]:\n",
    "    match = (alim_med[:, 0] == mx) * (alim_med[:, 1] == my)\n",
    "    if np.any(match):\n",
    "        alim = float(alim_med[:, 2][match])\n",
    "\n",
    "    if alim < lim:\n",
    "        pbetter = (lim - alim) / lim\n",
    "        print(f\"Semiboosted better for ({mx}, {my}) by {pbetter * 100:.2f}%\")\n",
    "        sb_better.append([mx, my, pbetter])\n",
    "\n",
    "sb_better = np.array(sb_better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.scatter2d_overlay(\n",
    "    limits[\"50.0\"],\n",
    "    sb_better,\n",
    "    f\"Median expected exclusion limits (fb)\",\n",
    "    f\"{plot_dir}/scatter_overlay.pdf\",\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_limits = {\n",
    "    \" 2.5\": [],\n",
    "    \"16.0\": [],\n",
    "    \"50.0\": [],\n",
    "    \"84.0\": [],\n",
    "    \"97.5\": [],\n",
    "    \"Observed\": [],\n",
    "    \"Significance\": [],\n",
    "}\n",
    "alim_med = alimits[\"50.0\"]\n",
    "blim_med = limits[\"50.0\"]\n",
    "\n",
    "checked_mxmy = []\n",
    "\n",
    "for mxy in np.vstack((alim_med, blim_med))[:, :2]:\n",
    "    mx, my = mxy\n",
    "    mxy = (int(mxy[0]), int(mxy[1]))\n",
    "    if mx < 900:\n",
    "        continue\n",
    "\n",
    "    if mxy in checked_mxmy:\n",
    "        continue\n",
    "\n",
    "    amatch, alim = get_lim(alim_med, mxy)\n",
    "    bmatch, blim = get_lim(blim_med, mxy)\n",
    "\n",
    "    alim = alim[0, 2] if np.any(amatch) else np.inf\n",
    "    blim = blim[0, 2] if np.any(bmatch) else np.inf\n",
    "\n",
    "    if alim < blim and (my < 200):\n",
    "        # skipping samples for which 2018 PFNano failed !! :(\n",
    "        print(f\"Skipping {mxy} because of missing PFNano!\")\n",
    "        continue\n",
    "\n",
    "    use_lims = alimits if alim < blim else limits\n",
    "\n",
    "    for key, lims in combined_limits.items():\n",
    "        umatch, lim = get_lim(use_lims[key], mxy)\n",
    "        if np.any(umatch):\n",
    "            lims.append([*mxy, use_lims[key][umatch][0, 2]])\n",
    "        else:\n",
    "            print(f\"Missing {mxy} for {key}!\")\n",
    "\n",
    "    checked_mxmy.append(mxy)\n",
    "\n",
    "for key, val in combined_limits.items():\n",
    "    combined_limits[key] = np.array(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argmax(alimits[\"Significance\"][:, 2])\n",
    "print(alimits[\"Significance\"][idx])\n",
    "idx = np.argmax(limits[\"Significance\"][:, 2])\n",
    "print(limits[\"Significance\"][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking excesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twosigma = combined_limits[\"97.5\"][:, 2] < combined_limits[\"Observed\"][:, 2]\n",
    "\n",
    "for i in range(np.sum(twosigma)):\n",
    "    mx, my = combined_limits[\"50.0\"][twosigma][i][:2]\n",
    "    print(\n",
    "        f\"({mx}, {my}): Expected {combined_limits['50.0'][twosigma][i, 2]}+{combined_limits['97.5'][twosigma][i, 2]}\\t Observed {combined_limits['Observed'][twosigma][i, 2]:.2f}\\t Sign {combined_limits['Significance'][twosigma][i, 2]:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxs = np.logspace(np.log10(800), np.log10(3999), 300, base=10)\n",
    "mys = np.logspace(np.log10(60), np.log10(2800), 300, base=10)\n",
    "cxx, cyy = np.meshgrid(mxs, mys)\n",
    "\n",
    "for key, val in combined_limits.items():\n",
    "    # if key != \"50.0\":\n",
    "    #     continue\n",
    "\n",
    "    interpolated = interpolate.LinearNDInterpolator(val[:, :2], np.log(val[:, 2]))\n",
    "    grid = np.exp(interpolated(cxx, cyy))\n",
    "\n",
    "    if key == \"50.0\":\n",
    "        label = \"Median expected exclusion limits (fb)\"\n",
    "    elif key == \"Observed\":\n",
    "        label = \"Exclusion limits (fb)\"\n",
    "    elif key == \"Significance\":\n",
    "        label = \"Signal Significance\"\n",
    "    else:\n",
    "        label = f\"{key}% expected exclusion limits (fb)\"\n",
    "\n",
    "    plotting.colormesh(\n",
    "        cxx, cyy, grid, label, f\"{plot_dir}/combined_mesh_{key}.pdf\", figsize=(12, 8), show=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
