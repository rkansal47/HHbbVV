{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "\n",
    "import corrections\n",
    "\n",
    "# from pandas.errors import SettingWithCopyWarning\n",
    "import hist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import mplhep as hep\n",
    "import plotting\n",
    "import postprocessing\n",
    "import utils\n",
    "from corrections import get_lpsf, postprocess_lpsfs\n",
    "from hist import Hist\n",
    "from regions import (\n",
    "    Region,\n",
    "    get_nonres_selection_regions,\n",
    "    get_nonres_vbf_selection_regions,\n",
    "    get_res_selection_regions,\n",
    ")\n",
    "from utils import ShapeVar\n",
    "\n",
    "from HHbbVV import hh_vars\n",
    "from HHbbVV.hh_vars import (\n",
    "    bg_keys,\n",
    "    data_key,\n",
    "    hbb_bg_keys,\n",
    "    jec_shifts,\n",
    "    jmsr_shifts,\n",
    "    nonres_samples,\n",
    "    nonres_sig_keys,\n",
    "    norm_preserving_weights,\n",
    "    qcd_key,\n",
    "    res_samples,\n",
    "    res_sig_keys,\n",
    "    samples,\n",
    "    years,\n",
    ")\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "hep.style.use(\"CMS\")\n",
    "formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_powerlimits((-3, 3))\n",
    "plt.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "# ignore these because they don't seem to apply\n",
    "# warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_samples = OrderedDict()\n",
    "\n",
    "# res_mps = [(900, 80), (1200, 190), (2000, 125), (3000, 250), (4000, 150)]\n",
    "res_mps = [(900, 80)]\n",
    "\n",
    "for mX, mY in res_mps:\n",
    "    res_samples[f\"X[{mX}]->H(bb)Y[{mY}](VV)\"] = f\"NMSSM_XToYHTo2W2BTo4Q2B_MX-{mX}_MY-{mY}\"\n",
    "\n",
    "res_sig_keys = list(res_samples.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del nonres_samples[\"VBFHHbbVV\"]\n",
    "nonres_sig_keys = [\n",
    "    \"HHbbVV\",\n",
    "    \"VBFHHbbVV\",\n",
    "    \"qqHH_CV_1_C2V_1_kl_2_HHbbVV\",\n",
    "    \"qqHH_CV_1_C2V_2_kl_1_HHbbVV\",\n",
    "]\n",
    "nonres_samples = {key: nonres_samples[key] for key in nonres_sig_keys}\n",
    "\n",
    "# bg_keys = [\"QCD\", \"TT\", \"ST\", \"V+Jets\", \"Diboson\"]\n",
    "# samples = {key: samples[key] for key in [\"Data\"] + bg_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = Path(\"../../../\")\n",
    "# samples_dir = MAIN_DIR / \"../data/skimmer/24Mar14UpdateData\"\n",
    "samples_dir = \"/ceph/cms/store/user/rkansal/bbVV/skimmer/24Mar14UpdateData\"\n",
    "# samples_dir = f\"{MAIN_DIR}/../data/skimmer/Feb24\"\n",
    "# nonres_signal_samples_dir = f\"{MAIN_DIR}/../data/skimmer/Jun10\"\n",
    "# res_signal_samples_dir = f\"{MAIN_DIR}/../data/skimmer/Apr11\"\n",
    "# samples_dir = \"/eos/uscms/store/user/rkansal/bbVV/skimmer/Feb24\"\n",
    "# nonres_signal_samples_dir = \"/eos/uscms/store/user/cmantill/bbVV/skimmer/Jun10/\"\n",
    "# res_signal_samples_dir = \"/eos/uscms/store/user/rkansal/bbVV/skimmer/Apr11/\"\n",
    "year = \"2018\"\n",
    "\n",
    "date = \"25Feb24ExcessChecks\"\n",
    "plot_dir = MAIN_DIR / f\"plots/PostProcessing/{date}/\"\n",
    "templates_dir = Path(f\"templates/{date}/\")\n",
    "\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/ControlPlots/{year}\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/cutflows\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/templates/wshifts\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/templates/jshifts\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/templates/hists2d\")\n",
    "_ = os.system(f\"mkdir -p {templates_dir}/cutflows/{year}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systematics = {year: {}}\n",
    "samples_dir = \"/ceph/cms/store/user/rkansal/bbVV/skimmer/24Mar14UpdateData\"\n",
    "\n",
    "# load_samples = list(samples.keys()) + list(nonres_samples.keys()) + list(res_samples.keys())\n",
    "load_samples = {\"Data\": \"JetHT\"}\n",
    "\n",
    "# save cutflow as pandas table\n",
    "cutflow = pd.DataFrame(index=list(load_samples.keys()))\n",
    "\n",
    "events_dict = postprocessing.load_samples(\n",
    "    samples_dir,\n",
    "    {**load_samples},  # , **res_samples, **samples},\n",
    "    year,\n",
    "    postprocessing.load_filters,\n",
    "    variations=False,\n",
    ")\n",
    "\n",
    "utils.add_to_cutflow(events_dict, \"Preselection\", \"finalWeight\", cutflow)\n",
    "cutflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import mplhep as hep\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "hep.style.use(\"CMS\")\n",
    "formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_powerlimits((-3, 3))\n",
    "\n",
    "# this is needed for some reason to update the font size for the first plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "plt.rcParams.update({\"font.size\": 24})\n",
    "plt.close()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "for sample, events in events_dict.items():\n",
    "    plt.hist(\n",
    "        events[\"ak8FatJetParticleNetMass\"].to_numpy().reshape(-1),\n",
    "        bins=np.arange(50, 250, 10),\n",
    "        label=sample,\n",
    "        histtype=\"step\",\n",
    "        density=True,\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"AK8 Jet pT (GeV)\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale factors and bb VV assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# postprocessing.qcd_sf(events_dict, cutflow)\n",
    "bb_masks = postprocessing.bb_VV_assignment(events_dict)\n",
    "postprocessing.derive_variables(\n",
    "    events_dict, bb_masks, resonant=True, nonres_vars=False, do_jshifts=False\n",
    ")\n",
    "cutflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data mass sculpting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = events_dict[\"Data\"]\n",
    "bb_mask = bb_masks[\"Data\"]\n",
    "vvtagger = utils.get_feat(events, \"VVFatJetParTMD_THWWvsT\", bb_mask)\n",
    "bbtagger = utils.get_feat(events, \"bbFatJetParticleNetMD_Txbb\", bb_mask)\n",
    "bbregmass = utils.get_feat(events, f\"bbFatJetParticleNetMass\", bb_mask)\n",
    "\n",
    "for mass_var, mlabel in zip([\"Msd\", \"ParticleNetMass\"], [\"SD\", \"reg\"]):\n",
    "    vvmass = utils.get_feat(events, f\"VVFatJet{mass_var}\", bb_mask)\n",
    "    bbmass = utils.get_feat(events, f\"bbFatJet{mass_var}\", bb_mask)\n",
    "    plotting.plotMassSculpting(\n",
    "        bbmass,\n",
    "        vvmass,\n",
    "        events[\"finalWeight\"],\n",
    "        vvtagger,\n",
    "        [0.0, 0.4, 0.6, 0.8, 0.9, 0.96],\n",
    "        mlabel,\n",
    "        r\"$T_{HVV}$\",\n",
    "        year,\n",
    "        show=True,\n",
    "    )\n",
    "    plotting.plotMassSculpting(\n",
    "        bbmass,\n",
    "        vvmass,\n",
    "        events[\"finalWeight\"],\n",
    "        bbtagger,\n",
    "        [0.8, \"LP\", \"MP\", \"HP\"],\n",
    "        mlabel,\n",
    "        r\"$T_{Xbb}$\",\n",
    "        year,\n",
    "        show=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mplot_dir = Path(f\"../../../plots/PostProcessing/25Feb24Sculpting/MassSculpting\")\n",
    "\n",
    "for key in [\"Data\", \"QCD\"]:\n",
    "    for mass_var, mlabel in zip([\"Msd\", \"ParticleNetMass\"], [\"SD\", \"reg\"]):\n",
    "        for tagger_cuts, tlabel, tagger in zip(\n",
    "            [[0.0, 0.4, 0.6, 0.8, 0.9, 0.96], [0.8, \"LP\", \"MP\", \"HP\"]],\n",
    "            [r\"$T_{HVV}$\", r\"$T_{Xbb}$\"],\n",
    "            [\"vv\", \"bb\"],\n",
    "        ):\n",
    "            hists = {}\n",
    "            for jet in [\"bb\", \"VV\"]:\n",
    "                hists[jet] = []\n",
    "                for year in years:\n",
    "                    with (mplot_dir / f\"{year}/pickles/{jet}_{key}_{tagger}cuts_{mlabel}.pkl\").open(\n",
    "                        \"rb\"\n",
    "                    ) as f:\n",
    "                        hists[jet].append(pickle.load(f))\n",
    "\n",
    "                summed_hists = []\n",
    "                for i in range(len(hists[jet][0])):\n",
    "                    summed_hists.append(sum([hist[i] for hist in hists[jet]]))\n",
    "\n",
    "                hists[jet] = summed_hists\n",
    "\n",
    "            plotting.plotMassSculptingAllYears(\n",
    "                hists,\n",
    "                tagger_cuts,\n",
    "                mlabel,\n",
    "                tlabel,\n",
    "                mplot_dir / f\"{key}_{tagger}cuts_{mlabel}.pdf\",\n",
    "                show=True,\n",
    "            )\n",
    "\n",
    "# hists = {}\n",
    "# for year in years:\n",
    "#     with Path(f\"../../../plots/PostProcessing/25Feb24Sculpting/MassSculpting/{year}/pickles/VV_Data_vvcuts_reg.pkl\").open(\"rb\") as f:\n",
    "#         hists.append(pickle.load(f))\n",
    "\n",
    "# summed_hists = []\n",
    "# for i in range(len(hists[0])):\n",
    "#     summed_hists.append(sum([hist[i] for hist in hists]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_hists"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {var: (bins, label)}\n",
    "control_plot_vars = [\n",
    "    # ShapeVar(var=\"MET_pt\", label=r\"$p^{miss}_T$ (GeV)\", bins=[50, 0, 300]),\n",
    "    # ShapeVar(var=\"DijetEta\", label=r\"$\\eta^{jj}$\", bins=[30, -8, 8]),\n",
    "    # ShapeVar(var=\"DijetPt\", label=r\"$p_T^{jj}$ (GeV)\", bins=[30, 0, 750]),\n",
    "    # ShapeVar(var=\"DijetMass\", label=r\"$m^{jj}$ (GeV)\", bins=[30, 600, 4000]),\n",
    "    # ShapeVar(var=\"bbFatJetEta\", label=r\"$\\eta^{bb}$\", bins=[20, -2.4, 2.4]),\n",
    "    # ShapeVar(\n",
    "    #     var=\"bbFatJetPt\", label=r\"$p^{bb}_T$ (GeV)\", bins=[20, 300, 2300], significance_dir=\"right\"\n",
    "    # ),\n",
    "    # ShapeVar(\n",
    "    #     var=\"bbFatJetParticleNetMass\",\n",
    "    #     label=r\"$m^{bb}_{reg}$ (GeV)\",\n",
    "    #     bins=[20, 50, 250],\n",
    "    #     significance_dir=\"bin\",\n",
    "    # ),\n",
    "    ShapeVar(var=\"bbFatJetMsd\", label=r\"$m^{bb}_{msd}$ (GeV)\", bins=[20, 0, 300]),\n",
    "    # ShapeVar(var=\"bbFatJetParticleNetMD_Txbb\", label=r\"$T^{bb}_{Xbb}$\", bins=[50, 0.8, 1]),\n",
    "    # ShapeVar(var=\"VVFatJetEta\", label=r\"$\\eta^{VV}$\", bins=[30, -2.4, 2.4]),\n",
    "    # ShapeVar(var=\"VVFatJetPt\", label=r\"$p^{VV}_T$ (GeV)\", bins=[20, 300, 2300]),\n",
    "    # ShapeVar(var=\"VVFatJetParticleNetMass\", label=r\"$m^{VV}_{reg}$ (GeV)\", bins=[20, 50, 250]),\n",
    "    # ShapeVar(var=\"VVFatJetMsd\", label=r\"$m^{VV}_{msd}$ (GeV)\", bins=[40, 50, 250]),\n",
    "    # ShapeVar(var=\"VVFatJetParticleNet_Th4q\", label=r\"Prob($H \\to 4q$) vs Prob(QCD) (Non-MD)\", bins=[50, 0, 1]),\n",
    "    # ShapeVar(var=\"VVFatJetParTMD_THWW4q\", label=r\"Prob($H \\to VV \\to 4q$) vs Prob(QCD) (Mass-Decorrelated)\", bins=[50, 0, 1]),\n",
    "    # ShapeVar(var=\"VVFatJetParTMD_probT\", label=r\"Prob(Top) (Mass-Decorrelated)\", bins=[50, 0, 1]),\n",
    "    # ShapeVar(var=\"VVFatJetParTMD_THWWvsT\", label=r\"$T^{VV}_{HWW}$\", bins=[50, 0, 1]),\n",
    "    # ShapeVar(var=\"bbFatJetPtOverDijetPt\", label=r\"$p^{bb}_T / p_T^{jj}$\", bins=[50, 0, 40]),\n",
    "    # ShapeVar(var=\"VVFatJetPtOverDijetPt\", label=r\"$p^{VV}_T / p_T^{jj}$\", bins=[50, 0, 40]),\n",
    "    # ShapeVar(var=\"VVFatJetPtOverbbFatJetPt\", label=r\"$p^{VV}_T / p^{bb}_T$\", bins=[50, 0.4, 2.0]),\n",
    "    # ShapeVar(var=\"nGoodMuonsHbb\", label=r\"# of Muons\", bins=[3, 0, 3]),\n",
    "    # ShapeVar(var=\"nGoodMuonsHH\", label=r\"# of Muons\", bins=[3, 0, 3]),\n",
    "    # ShapeVar(var=\"nGoodElectronsHbb\", label=r\"# of Electrons\", bins=[3, 0, 3]),\n",
    "    # ShapeVar(var=\"nGoodElectronsHH\", label=r\"# of Electrons\", bins=[3, 0, 3]),\n",
    "    # ShapeVar(var=\"nGoodJets\", label=r\"# of AK4 B-Jets\", bins=[5, 0, 5]),\n",
    "    # removed if not ggF nonresonant - needs to be the last variable!\n",
    "    # ShapeVar(var=\"BDTScore\", label=r\"BDT Score\", bins=[50, 0, 1]),\n",
    "]\n",
    "\n",
    "hists = postprocessing.control_plots(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    nonres_sig_keys + res_sig_keys,\n",
    "    control_plot_vars,\n",
    "    plot_dir / f\"ControlPlots/{year}\",\n",
    "    year,\n",
    "    bg_keys=bg_keys,\n",
    "    sig_scale_dict={\"HHbbVV\": 1e5, \"VBFHHbbVV\": 2e6} | {key: 2e4 for key in res_sig_keys},\n",
    "    # bg_keys=[\"QCD\", \"TT\", \"ST\", \"V+Jets\", \"Hbb\"],\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (MAIN_DIR / \"plots/PostProcessing/24Mar6Mass/ControlPlots/2016/hists.pkl\").open(\"rb\") as f:\n",
    "    hists2 = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall LP SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from postprocessing import Region, nonres_shape_vars\n",
    "\n",
    "# temp region to check systematics\n",
    "selection_regions = {\n",
    "    \"pass\": Region(\n",
    "        cuts={\n",
    "            \"bbFatJetParticleNetMD_Txbb\": [0.97, CUT_MAX_VAL],\n",
    "            \"VVFatJetParTMD_THWWvsT\": [0.8, CUT_MAX_VAL],\n",
    "        },\n",
    "        label=\"Pass\",\n",
    "    ),\n",
    "    \"lpsf\": Region(\n",
    "        cuts={\n",
    "            \"VVFatJetParTMD_THWWvsT\": [0.8, CUT_MAX_VAL],\n",
    "        },\n",
    "        label=\"LP SF\",\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "sel, cf = utils.make_selection(\n",
    "    selection_regions[\"lpsf\"].cuts, events_dict, bb_masks, prev_cutflow=cutflow\n",
    ")\n",
    "\n",
    "sf_table = OrderedDict()\n",
    "\n",
    "for sig_key in tqdm(nonres_sig_keys + res_sig_keys):\n",
    "    systematics[sig_key] = {}\n",
    "    # calculate only for current year\n",
    "    events_dict[sig_key] = postprocessing.postprocess_lpsfs(events_dict[sig_key])\n",
    "    lp_sf, unc, uncs = postprocessing.get_lpsf(events_dict[sig_key], sel[sig_key])\n",
    "    # print(f\"BDT LP Scale Factor for {sig_key}: {lp_sf:.2f} ± {unc:.2f}\")\n",
    "    # print(uncs)\n",
    "\n",
    "    systematics[sig_key][\"lp_sf\"] = lp_sf\n",
    "    systematics[sig_key][\"lp_sf_unc\"] = unc / lp_sf\n",
    "\n",
    "    sf_table[sig_key] = {\"SF\": f\"{lp_sf:.2f} ± {unc:.2f}\", **uncs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_df = pd.DataFrame(index=nonres_sig_keys + res_sig_keys)\n",
    "\n",
    "for key in sf_table[sig_key]:\n",
    "    sf_df[key] = [sf_table[skey][key] for skey in nonres_sig_keys + res_sig_keys]\n",
    "\n",
    "sf_df.to_clipboard()\n",
    "sf_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_regions = postprocessing.get_res_selection_regions(year)\n",
    "# del selection_regions[\"fail\"], selection_regions[\"failBlinded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = postprocessing.get_templates(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    year,\n",
    "    [\"HHbbVV\"],\n",
    "    # nonres_sig_keys + res_sig_keys,\n",
    "    # res_sig_keys,\n",
    "    selection_regions,\n",
    "    # res_shape_vars[:1],\n",
    "    nonres_shape_vars,\n",
    "    systematics,\n",
    "    templates_dir,\n",
    "    # bg_keys=[\"QCD\", \"TT\", \"V+Jets\", \"Diboson\", \"Hbb\"],\n",
    "    plot_dir=plot_dir / \"templates\",\n",
    "    prev_cutflow=cutflow,\n",
    "    sig_scale_dict={\"HHbbVV\": 1e3, \"VBFHHbbVV\": 1e4} | {key: 1e2 for key in res_sig_keys},\n",
    "    # sig_splits=sig_splits[:2],\n",
    "    weight_shifts={},\n",
    "    jshift=\"\",\n",
    "    lpsfs=True,\n",
    "    plot_shifts=False,\n",
    "    pass_ylim=500,\n",
    "    fail_ylim=40000,\n",
    "    # blind_pass=True,\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {}\n",
    "\n",
    "for jshift in [\"\"]:  # + jec_shifts + jmsr_shifts:\n",
    "    print(jshift)\n",
    "    ttemps = postprocessing.get_templates(\n",
    "        events_dict,\n",
    "        bb_masks,\n",
    "        year,\n",
    "        nonres_sig_keys,\n",
    "        selection_regions,\n",
    "        # res_selection_regions[year],\n",
    "        nonres_shape_vars,\n",
    "        # res_shape_vars,\n",
    "        systematics,\n",
    "        templates_dir,\n",
    "        plot_dir=plot_dir / \"templates\",\n",
    "        prev_cutflow=cutflow,\n",
    "        sig_scale_dict={\"HHbbVV\": 1e3, \"VBFHHbbVV\": 2e4} | {key: 1e2 for key in res_sig_keys},\n",
    "        weight_shifts=postprocessing.weight_shifts,\n",
    "        jshift=jshift,\n",
    "        lpsfs=True,\n",
    "        pass_ylim=500,\n",
    "        fail_ylim=40000,\n",
    "        # blind_pass=True,\n",
    "        show=False,\n",
    "        plot_shifts=True,\n",
    "    )\n",
    "\n",
    "    templates = {**templates, **ttemps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{templates_dir}/{year}_templates.pkl\", \"wb\") as f:\n",
    "    pickle.dump(templates, f)\n",
    "\n",
    "with open(f\"{templates_dir}/systematics.json\", \"w\") as f:\n",
    "    json.dump(systematics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"templates/Apr10//2017_templates.pkl\", \"rb\") as f:\n",
    "    templates = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(templates[\"pass\"].axes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.hist2ds(\n",
    "    templates,\n",
    "    f\"{plot_dir}/templates/hists2d/\",\n",
    "    regions=[\"pass\", \"fail\", \"passBlinded\", \"failBlinded\"],\n",
    "    region_labels=selection_regions_label,\n",
    "    samples=[\"Data\", \"TT\", \"V+Jets\", \"X[3000]->H(bb)Y[190](VV)\"],\n",
    "    # fail_zlim=5e3,\n",
    "    # pass_zlim=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_dict = {}\n",
    "\n",
    "for year in years:\n",
    "    with open(f\"templates/{date}/{year}_templates.pkl\", \"rb\") as f:\n",
    "        templates_dict[year] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = []\n",
    "for year in years:\n",
    "    with open(f\"templates/Apr7//{year}_templates.pkl\", \"rb\") as f:\n",
    "        templates.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HIG BTV OR Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbb2 = events_dict[\"HHbbVV\"][\n",
    "    np.all(events_dict[\"HHbbVV\"][\"ak8FatJetParticleNetMD_Txbb\"] > 0.9714, axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higher_txbbjet = np.argmax(hbb2[\"ak8FatJetParticleNetMD_Txbb\"].values, axis=1)\n",
    "higher_pt = np.argmax(hbb2[\"ak8FatJetPt\"].values, axis=1)\n",
    "higher_mpnet = np.argmax(hbb2[\"ak8FatJetParticleNetMass\"].values, axis=1)\n",
    "print(\n",
    "    \"higher txbb sorting\",\n",
    "    np.mean(hbb2[\"ak8FatJetHbb\"].values[np.arange(len(hbb2)), higher_txbbjet]),\n",
    ")\n",
    "print(\"higher pt sorting\", np.mean(hbb2[\"ak8FatJetHbb\"].values[np.arange(len(hbb2)), higher_pt]))\n",
    "print(\"higher eta sorting\", np.mean(hbb2[\"ak8FatJetHbb\"].values[np.arange(len(hbb2)), higher_pt]))\n",
    "print(\n",
    "    \"higher mpnet sorting\", np.mean(hbb2[\"ak8FatJetHbb\"].values[np.arange(len(hbb2)), higher_mpnet])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in events_dict:\n",
    "    print(sample)\n",
    "    print(\n",
    "        np.mean(\n",
    "            np.all(events_dict[sample][\"ak8FatJetParticleNetMD_Txbb\"] > 0.9714, axis=1)\n",
    "            * (events_dict[sample][\"VVFatJetParTMD_THWWvsT\"].values.squeeze() > 0.6)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(\n",
    "    np.all(events_dict[\"HHbbVV\"][\"ak8FatJetParticleNetMD_Txbb\"] > 0.9714, axis=1)\n",
    "    * (events_dict[\"HHbbVV\"][\"VVFatJetParTMD_THWWvsT\"].values.squeeze() > 0.6)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
