{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import plotting\n",
    "import postprocessing\n",
    "import corrections\n",
    "\n",
    "from utils import CUT_MAX_VAL, ShapeVar\n",
    "from hh_vars import (\n",
    "    years,\n",
    "    data_key,\n",
    "    qcd_key,\n",
    "    bg_keys,\n",
    "    samples,\n",
    "    nonres_sig_keys,\n",
    "    # res_samples,\n",
    "    # res_sig_keys,\n",
    "    nonres_samples,\n",
    "    txbb_wps,\n",
    "    jec_shifts,\n",
    "    jmsr_shifts,\n",
    "    LUMI,\n",
    ")\n",
    "from postprocessing import res_shape_vars, new_filters, old_filters\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle, json\n",
    "import hist\n",
    "from hist import Hist\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from inspect import cleandoc\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_samples = OrderedDict()\n",
    "\n",
    "res_mps = [(900, 80), (1200, 190), (2000, 125), (3000, 250), (4000, 150)]\n",
    "\n",
    "for mX, mY in res_mps:\n",
    "    res_samples[f\"X[{mX}]->H(bb)Y[{mY}](VV)\"] = f\"NMSSM_XToYHTo2W2BTo4Q2B_MX-{mX}_MY-{mY}\"\n",
    "\n",
    "res_sig_keys = list(res_samples.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del nonres_samples[\"VBFHHbbVV\"]\n",
    "nonres_sig_keys = [\"HHbbVV\", \"VBFHHbbVV\"]\n",
    "nonres_samples = {key: nonres_samples[key] for key in nonres_sig_keys}\n",
    "\n",
    "bg_keys = [\"QCD\", \"TT\", \"ST\", \"V+Jets\", \"Diboson\"]\n",
    "samples = {key: samples[key] for key in [\"Data\"] + bg_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = \"../../../\"\n",
    "samples_dir = f\"{MAIN_DIR}/../data/skimmer/Feb24\"\n",
    "nonres_signal_samples_dir = f\"{MAIN_DIR}/../data/skimmer/Jun10\"\n",
    "res_signal_samples_dir = f\"{MAIN_DIR}/../data/skimmer/Apr11\"\n",
    "# samples_dir = \"/eos/uscms/store/user/rkansal/bbVV/skimmer/Feb24\"\n",
    "# nonres_signal_samples_dir = \"/eos/uscms/store/user/cmantill/bbVV/skimmer/Jun10/\"\n",
    "# res_signal_samples_dir = \"/eos/uscms/store/user/rkansal/bbVV/skimmer/Apr11/\"\n",
    "year = \"2018\"\n",
    "\n",
    "date = \"24Jan13Res\"\n",
    "plot_dir = f\"../../../plots/PostProcessing/{date}/\"\n",
    "templates_dir = f\"templates/{date}/\"\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/ControlPlots/{year}\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/cutflows\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/templates/wshifts\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/templates/jshifts\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/templates/hists2d\")\n",
    "_ = os.system(f\"mkdir -p {templates_dir}\")\n",
    "\n",
    "selection_regions = postprocessing.get_res_selection_regions(year)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\n",
    "    f\"{res_signal_samples_dir}/2018/NMSSM_XToYHTo2W2BTo4Q2B_MX-2000_MY-125/pickles/out_0.pkl\", \"rb\"\n",
    ") as f:\n",
    "    cf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systematics = {year: {}}\n",
    "\n",
    "# save cutflow as pandas table\n",
    "cutflow = pd.DataFrame(index=list(samples.keys()) + list(res_samples.keys()))\n",
    "\n",
    "# hem cleaning in load_samples not implemented yet for res samples\n",
    "hem_cleaning = False\n",
    "\n",
    "# utils.remove_empty_parquets(samples_dir, year)\n",
    "events_dict = utils.load_samples(\n",
    "    res_signal_samples_dir, res_samples, year, new_filters, hem_cleaning=hem_cleaning\n",
    ")\n",
    "events_dict |= utils.load_samples(\n",
    "    nonres_signal_samples_dir, nonres_samples, year, new_filters, hem_cleaning=hem_cleaning\n",
    ")\n",
    "events_dict |= utils.load_samples(\n",
    "    samples_dir, samples, year, new_filters, hem_cleaning=hem_cleaning\n",
    ")\n",
    "\n",
    "utils.add_to_cutflow(events_dict, \"Preselection\", \"weight\", cutflow)\n",
    "\n",
    "print(\"\")\n",
    "# print weighted sample yields\n",
    "for sample in events_dict:\n",
    "    tot_weight = np.sum(events_dict[sample][\"weight\"].values)\n",
    "    print(f\"Pre-selection {sample} yield: {tot_weight:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higgs_samples = OrderedDict(\n",
    "    [\n",
    "        (\"Hbb\", \"*HToBB\"),\n",
    "        # (\"HWW\", (\"*HToWW\", \"*HToNonbb\")),\n",
    "        # (\"HH\", (\"VBF_HHTobbVV_CV_1_C2V_1_C3_1\", \"GluGluToHHTo4B_node_cHHH1_preUL\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "events_dict |= utils.load_samples(samples_dir, higgs_samples, year)\n",
    "\n",
    "cutflow = pd.DataFrame(\n",
    "    index=list(samples.keys()) + list(res_samples.keys()) + list(higgs_samples.keys())\n",
    ")\n",
    "utils.add_to_cutflow(events_dict, \"Preselection\", \"weight\", cutflow)\n",
    "\n",
    "print(\"\")\n",
    "# print weighted sample yields\n",
    "for sample in events_dict:\n",
    "    tot_weight = np.sum(events_dict[sample][\"weight\"].values)\n",
    "    print(f\"Pre-selection {sample} yield: {tot_weight:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale factors and bb VV assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessing.apply_weights(events_dict, year, cutflow)\n",
    "bb_masks = postprocessing.bb_VV_assignment(events_dict)\n",
    "postprocessing.derive_variables(events_dict)\n",
    "cutflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = list(events_dict.keys())\n",
    "weight_key = \"finalWeight\"\n",
    "\n",
    "control_plot_2d_vars = [\n",
    "    {\n",
    "        f\"{jet}FatJetPhi\": ([40, -3.5, 3.5], rf\"$\\varphi^{{{jet}}}$\"),\n",
    "        f\"{jet}FatJetEta\": ([40, -3, 3], rf\"$\\eta^{{{jet}}}$\"),\n",
    "    }\n",
    "    for jet in [\"bb\", \"VV\"]\n",
    "]\n",
    "\n",
    "hists2d = []\n",
    "\n",
    "for vars2d in control_plot_2d_vars:\n",
    "    h = Hist(\n",
    "        hist.axis.StrCategory(samples, name=\"Sample\"),\n",
    "        *[hist.axis.Regular(*bins, name=var, label=label) for var, (bins, label) in vars2d.items()],\n",
    "        storage=hist.storage.Weight(),\n",
    "    )\n",
    "\n",
    "    for sample in samples:\n",
    "        events = events_dict[sample]\n",
    "\n",
    "        fill_data = {var: utils.get_feat(events, var, bb_masks[sample]) for var in vars2d}\n",
    "        weight = events[weight_key].values.squeeze()\n",
    "\n",
    "        # if selection is not None:\n",
    "        #     sel = selection[sample]\n",
    "        #     fill_data[var] = fill_data[var][sel]\n",
    "        #     weight = weight[sel]\n",
    "\n",
    "        if len(weight):\n",
    "            h.fill(Sample=sample, **fill_data, weight=weight)\n",
    "\n",
    "    hists2d.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "\n",
    "plot_keys = [\"Data\", \"QCD\", \"TT\", \"HHbbVV\", \"X[3000]->H(bb)Y[250](VV)\"]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    len(plot_keys),\n",
    "    2,\n",
    "    figsize=(20, 8 * len(plot_keys)),\n",
    "    gridspec_kw={\"wspace\": 0.25, \"hspace\": 0.25},\n",
    ")\n",
    "\n",
    "for j, key in enumerate(plot_keys):\n",
    "    for i in range(2):\n",
    "        ax = axs[j][i]\n",
    "        hep.hist2dplot(hists2d[i][key, ...], cmap=\"turbo\", ax=ax)\n",
    "        hep.cms.label(\n",
    "            \"Work in Progress\", data=True, lumi=round(LUMI[year] * 1e-3), year=year, ax=ax\n",
    "        )\n",
    "        ax.set_title(key, y=1.07)\n",
    "        ax._children[0].colorbar.set_label(\"Events\")\n",
    "\n",
    "plt.savefig(f\"{plot_dir}/ControlPlots/{year}/HEM2d.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {var: (bins, label)}\n",
    "control_plot_vars = [\n",
    "    # ShapeVar(var=\"MET_pt\", label=r\"$p^{miss}_T$ (GeV)\", bins=[50, 0, 300]),\n",
    "    # ShapeVar(var=\"DijetEta\", label=r\"$\\eta^{jj}$\", bins=[30, -8, 8]),\n",
    "    # ShapeVar(var=\"DijetPt\", label=r\"$p_T^{jj}$ (GeV)\", bins=[30, 0, 750]),\n",
    "    # ShapeVar(var=\"DijetMass\", label=r\"$m^{jj}$ (GeV)\", bins=[30, 600, 4000]),\n",
    "    # ShapeVar(var=\"bbFatJetEta\", label=r\"$\\eta^{bb}$\", bins=[30, -2.4, 2.4]),\n",
    "    # ShapeVar(\n",
    "    #     var=\"bbFatJetPt\", label=r\"$p^{bb}_T$ (GeV)\", bins=[30, 300, 1500], significance_dir=\"right\"\n",
    "    # ),\n",
    "    # ShapeVar(\n",
    "    #     var=\"bbFatJetParticleNetMass\",\n",
    "    #     label=r\"$m^{bb}_{reg}$ (GeV)\",\n",
    "    #     bins=[20, 50, 250],\n",
    "    #     significance_dir=\"bin\",\n",
    "    # ),\n",
    "    # ShapeVar(var=\"bbFatJetMsd\", label=r\"$m^{bb}_{msd}$ (GeV)\", bins=[50, 0, 300]),\n",
    "    ShapeVar(var=\"bbFatJetParticleNetMD_Txbb\", label=r\"$T^{bb}_{Xbb}$\", bins=[50, 0.8, 1]),\n",
    "    # ShapeVar(var=\"VVFatJetEta\", label=r\"$\\eta^{VV}$\", bins=[30, -2.4, 2.4]),\n",
    "    # ShapeVar(var=\"VVFatJetPt\", label=r\"$p^{VV}_T$ (GeV)\", bins=[30, 300, 1500]),\n",
    "    # ShapeVar(var=\"VVParticleNetMass\", label=r\"$m^{VV}_{reg}$ (GeV)\", bins=[20, 50, 250]),\n",
    "    # ShapeVar(var=\"VVFatJetMsd\", label=r\"$m^{VV}_{msd}$ (GeV)\", bins=[40, 50, 250]),\n",
    "    # ShapeVar(var=\"VVFatJetParticleNet_Th4q\", label=r\"Prob($H \\to 4q$) vs Prob(QCD) (Non-MD)\", bins=[50, 0, 1]),\n",
    "    # ShapeVar(var=\"VVFatJetParTMD_THWW4q\", label=r\"Prob($H \\to VV \\to 4q$) vs Prob(QCD) (Mass-Decorrelated)\", bins=[50, 0, 1]),\n",
    "    # ShapeVar(var=\"VVFatJetParTMD_probT\", label=r\"Prob(Top) (Mass-Decorrelated)\", bins=[50, 0, 1]),\n",
    "    ShapeVar(var=\"VVFatJetParTMD_THWWvsT\", label=r\"$T^{VV}_{HWW}$\", bins=[50, 0, 1]),\n",
    "    # ShapeVar(var=\"bbFatJetPtOverDijetPt\", label=r\"$p^{bb}_T / p_T^{jj}$\", bins=[50, 0, 40]),\n",
    "    # ShapeVar(var=\"VVFatJetPtOverDijetPt\", label=r\"$p^{VV}_T / p_T^{jj}$\", bins=[50, 0, 40]),\n",
    "    # ShapeVar(var=\"VVFatJetPtOverbbFatJetPt\", label=r\"$p^{VV}_T / p^{bb}_T$\", bins=[50, 0.4, 2.0]),\n",
    "    # ShapeVar(var=\"nGoodMuons\", label=r\"# of Muons\", bins=[3, 0, 3]),\n",
    "    # ShapeVar(var=\"nGoodElectrons\", label=r\"# of Electrons\", bins=[3, 0, 3]),\n",
    "    # ShapeVar(var=\"nGoodJets\", label=r\"# of AK4 B-Jets\", bins=[5, 0, 5]),\n",
    "    # removed if not ggF nonresonant - needs to be the last variable!\n",
    "    # ShapeVar(var=\"BDTScore\", label=r\"BDT Score\", bins=[50, 0, 1]),\n",
    "]\n",
    "\n",
    "hists = postprocessing.control_plots(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    nonres_sig_keys + res_sig_keys,\n",
    "    control_plot_vars,\n",
    "    f\"{plot_dir}/ControlPlots/{year}/\",\n",
    "    year,\n",
    "    bg_keys=bg_keys,\n",
    "    sig_scale_dict={\"HHbbVV\": 1e5, \"VBFHHbbVV\": 2e6} | {key: 2e4 for key in res_sig_keys},\n",
    "    # bg_keys=[\"QCD\", \"TT\", \"ST\", \"V+Jets\", \"Hbb\"],\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection, _ = utils.make_selection(\n",
    "    {\n",
    "        \"VVFatJetParTMD_THWWvsT\": [0.8, CUT_MAX_VAL],\n",
    "        \"bbFatJetParticleNetMD_Txbb\": [0.98, CUT_MAX_VAL],\n",
    "        \"bbFatJetParticleNetMass\": [110, 145],\n",
    "    },\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    ")\n",
    "cutstr = f\"pass_noveto\"\n",
    "\n",
    "postprocessing.control_plots(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    nonres_sig_keys + res_sig_keys,\n",
    "    control_plot_vars,\n",
    "    f\"{plot_dir}/ControlPlots/{year}/\",\n",
    "    year,\n",
    "    sig_splits=sig_splits[:1],\n",
    "    hists={},\n",
    "    # bg_keys=bg_keys + list(higgs_samples.keys()),\n",
    "    # bg_keys=[\"QCD\", \"TT\", \"ST\", \"V+Jets\", \"Hbb\"],\n",
    "    bg_keys=[\"QCD\", \"TT\", \"ST\", \"V+Jets\"],\n",
    "    sig_scale_dict={key: 10 for key in nonres_sig_keys + res_sig_keys},\n",
    "    selection=selection,\n",
    "    cutstr=cutstr,\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sb1, sb2 in [[0, 300], [75, 180], [92.5, 162.5]]:\n",
    "    selection, _ = utils.make_selection(\n",
    "        {\n",
    "            \"VVFatJetParTMD_THWWvsT\": [0.8, CUT_MAX_VAL],\n",
    "            \"bbFatJetParticleNetMD_Txbb\": [0.98, CUT_MAX_VAL],\n",
    "            \"bbFatJetParticleNetMass\": [[sb1, 110], [145, sb2]],\n",
    "        },\n",
    "        events_dict,\n",
    "        bb_masks,\n",
    "    )\n",
    "    cutstr = f\"sidebands_{sb1}_{sb2}\"\n",
    "\n",
    "    postprocessing.control_plots(\n",
    "        events_dict,\n",
    "        bb_masks,\n",
    "        nonres_sig_keys + res_sig_keys,\n",
    "        control_plot_vars,\n",
    "        f\"{plot_dir}/ControlPlots/{year}/\",\n",
    "        year,\n",
    "        sig_splits=sig_splits,\n",
    "        hists={},\n",
    "        # bg_keys=bg_keys + list(higgs_samples.keys()),\n",
    "        bg_keys=[\"QCD\", \"TT\", \"ST\", \"V+Jets\", \"Hbb\"],\n",
    "        selection=selection,\n",
    "        cutstr=cutstr,\n",
    "        show=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall LP SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "sel, cf = utils.make_selection(\n",
    "    selection_regions[\"lpsf\"].cuts, events_dict, bb_masks, prev_cutflow=cutflow\n",
    ")\n",
    "\n",
    "sf_table = OrderedDict()\n",
    "\n",
    "for sig_key in tqdm(res_sig_keys):\n",
    "    systematics[sig_key] = {}\n",
    "    # calculate only for current year\n",
    "    events_dict[sig_key] = postprocessing.postprocess_lpsfs(events_dict[sig_key])\n",
    "    lp_sf, unc, uncs = postprocessing.get_lpsf(events_dict[sig_key], sel[sig_key])\n",
    "    # print(f\"BDT LP Scale Factor for {sig_key}: {lp_sf:.2f} ± {unc:.2f}\")\n",
    "    # print(uncs)\n",
    "\n",
    "    systematics[sig_key][\"lp_sf\"] = lp_sf\n",
    "    systematics[sig_key][\"lp_sf_unc\"] = unc / lp_sf\n",
    "\n",
    "    sf_table[sig_key] = {\"SF\": f\"{lp_sf:.2f} ± {unc:.2f}\", **uncs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_df = pd.DataFrame(index=nonres_sig_keys + res_sig_keys)\n",
    "\n",
    "for key in sf_table[sig_key]:\n",
    "    sf_df[key] = [sf_table[skey][key] for skey in nonres_sig_keys + res_sig_keys]\n",
    "\n",
    "sf_df.to_clipboard()\n",
    "sf_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_regions = postprocessing.get_res_selection_regions(\"2017\", txbb_wp=\"HP\", thww_wp=0.8)\n",
    "del selection_regions[\"fail\"], selection_regions[\"failBlinded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = postprocessing.get_templates(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    year,\n",
    "    # nonres_sig_keys + res_sig_keys[:10],\n",
    "    res_sig_keys,\n",
    "    selection_regions,\n",
    "    res_shape_vars[:1],\n",
    "    systematics,\n",
    "    templates_dir,\n",
    "    bg_keys=[\"QCD\", \"TT\", \"V+Jets\", \"Diboson\", \"Hbb\"],\n",
    "    plot_dir=f\"{plot_dir}/templates/\",\n",
    "    prev_cutflow=cutflow,\n",
    "    # sig_splits=sig_splits[:2],\n",
    "    weight_shifts={},\n",
    "    jshift=\"\",\n",
    "    plot_shifts=False,\n",
    "    pass_ylim=70,\n",
    "    fail_ylim=40000,\n",
    "    blind_pass=True,\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_templates(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    args.year,\n",
    "    sig_keys,\n",
    "    selection_regions,\n",
    "    shape_vars,\n",
    "    systematics,\n",
    "    template_dir,\n",
    "    bg_keys=bg_keys,\n",
    "    plot_dir=plot_dir,\n",
    "    prev_cutflow=cutflow,\n",
    "    # sig_splits=sig_splits,\n",
    "    weight_shifts=weight_shifts,\n",
    "    jshift=jshift,\n",
    "    blind_pass=True if args.resonant else False,\n",
    "    show=False,\n",
    "    plot_shifts=args.plot_shifts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {}\n",
    "\n",
    "for jshift in [\"\"] + jec_shifts + jmsr_shifts:\n",
    "    print(jshift)\n",
    "    ttemps, tsyst = postprocessing.get_templates(\n",
    "        events_dict,\n",
    "        bb_masks,\n",
    "        year,\n",
    "        nonres_sig_keys + res_sig_keys,\n",
    "        res_selection_regions[year],\n",
    "        res_shape_vars,\n",
    "        bg_keys=[\"QCD\", \"TT\", \"V+Jets\"],\n",
    "        plot_dir=plot_dir if jshift == \"\" else \"\",\n",
    "        prev_cutflow=cutflow,\n",
    "        sig_splits=sig_splits,\n",
    "        weight_shifts=postprocessing.weight_shifts,\n",
    "        jshift=jshift,\n",
    "        pass_ylim=7,\n",
    "        fail_ylim=40000,\n",
    "        blind_pass=True,\n",
    "        show=False,\n",
    "        plot_shifts=False,\n",
    "    )\n",
    "\n",
    "    templates = {**templates, **ttemps}\n",
    "    if jshift == \"\":\n",
    "        systematics[year] = tsyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{templates_dir}/{year}_templates.pkl\", \"wb\") as f:\n",
    "    pickle.dump(templates, f)\n",
    "\n",
    "with open(f\"{templates_dir}/systematics.json\", \"w\") as f:\n",
    "    json.dump(systematics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"templates/Apr10//2017_templates.pkl\", \"rb\") as f:\n",
    "    templates = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(templates[\"pass\"].axes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.hist2ds(\n",
    "    templates,\n",
    "    f\"{plot_dir}/templates/hists2d/\",\n",
    "    regions=[\"pass\", \"fail\", \"passBlinded\", \"failBlinded\"],\n",
    "    region_labels=selection_regions_label,\n",
    "    samples=[\"Data\", \"TT\", \"V+Jets\", \"X[3000]->H(bb)Y[190](VV)\"],\n",
    "    # fail_zlim=5e3,\n",
    "    # pass_zlim=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_dict = {}\n",
    "\n",
    "for year in years:\n",
    "    with open(f\"templates/{date}/{year}_templates.pkl\", \"rb\") as f:\n",
    "        templates_dict[year] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = []\n",
    "for year in years:\n",
    "    with open(f\"templates/Apr7//{year}_templates.pkl\", \"rb\") as f:\n",
    "        templates.append(pickle.load(f))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15adc7883e707560d0d9727709639b8fe3f3cff1f197d2d643742923ff23a29c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
