{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import plotting\n",
    "import postprocessing\n",
    "import corrections\n",
    "\n",
    "from utils import CUT_MAX_VAL\n",
    "from hh_vars import (\n",
    "    years,\n",
    "    data_key,\n",
    "    qcd_key,\n",
    "    bg_keys,\n",
    "    samples,\n",
    "    nonres_sig_keys,\n",
    "    res_samples,\n",
    "    res_sig_keys,\n",
    "    txbb_wps,\n",
    "    jec_shifts,\n",
    "    jmsr_shifts,\n",
    ")\n",
    "from postprocessing import (\n",
    "    res_shape_vars,\n",
    "    res_selection_regions,\n",
    "    selection_regions_label,\n",
    "    # selection_regions_year,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle, json\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "from hist import Hist\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from inspect import cleandoc\n",
    "import warnings\n",
    "\n",
    "# ignore these because they don't seem to apply\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mps = [\n",
    "    (1000, 125),\n",
    "    (1400, 125),\n",
    "    (1400, 150),\n",
    "    (1800, 125),\n",
    "    (1800, 150),\n",
    "    (1800, 190),\n",
    "    (2200, 125),\n",
    "    (2200, 150),\n",
    "    (2200, 190),\n",
    "    (2200, 250),\n",
    "    (3000, 125),\n",
    "    (3000, 150),\n",
    "    (3000, 190),\n",
    "    (3000, 250),\n",
    "    (3000, 350),\n",
    "]\n",
    "\n",
    "for mX, mY in res_mps:\n",
    "    res_samples[\n",
    "        f\"X[{mX}]->H(bb)Y[{mY}](VV)\"\n",
    "    ] = f\"NMSSM_XToYH_MX{mX}_MY{mY}_HTo2bYTo2W_hadronicDecay\"\n",
    "\n",
    "res_sig_keys = list(res_samples.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_split_points = [\n",
    "    [\n",
    "        (1000, 125),\n",
    "        (1400, 125),\n",
    "        (1800, 125),\n",
    "        (2200, 125),\n",
    "        (3000, 125),\n",
    "    ],\n",
    "    [\n",
    "        (1400, 150),\n",
    "        (1800, 150),\n",
    "        (1800, 190),\n",
    "        (2200, 150),\n",
    "        (2200, 190),\n",
    "        (2200, 250),\n",
    "    ],\n",
    "    [\n",
    "        (3000, 125),\n",
    "        (3000, 150),\n",
    "        (3000, 190),\n",
    "        (3000, 250),\n",
    "        (3000, 350),\n",
    "    ],\n",
    "]\n",
    "\n",
    "sig_splits = [\n",
    "    [\"HHbbVV\"] + [f\"X[{mX}]->H(bb)Y[{mY}](VV)\" for (mX, mY) in mps] for mps in sig_split_points\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = \"../../../\"\n",
    "samples_dir = f\"{MAIN_DIR}/../data/skimmer/Feb24\"\n",
    "signal_samples_dir = f\"{MAIN_DIR}/../data/skimmer/Mar10_2\"\n",
    "year = \"2017\"\n",
    "\n",
    "date = \"Apr4\"\n",
    "plot_dir = f\"../../../plots/PostProcessing/{date}/\"\n",
    "templates_dir = f\"templates/{date}/\"\n",
    "for i in range(len(sig_splits)):\n",
    "    _ = os.system(f\"mkdir -p {plot_dir}/ControlPlots/{year}/sigs{i}/\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/cutflows/\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/templates/wshifts\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/templates/jshifts\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/templates/hists2d\")\n",
    "_ = os.system(f\"mkdir -p {templates_dir}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both Jet's Regressed Mass above 50, electron veto\n",
    "filters = [\n",
    "    [\n",
    "        (\"('ak8FatJetParticleNetMass', '0')\", \">=\", 50),\n",
    "        (\"('ak8FatJetParticleNetMass', '1')\", \">=\", 50),\n",
    "        # (\"('nGoodElectrons', '0')\", \"==\", 0),\n",
    "    ],\n",
    "]\n",
    "systematics = {}\n",
    "\n",
    "# save cutflow as pandas table\n",
    "cutflow = pd.DataFrame(index=list(samples.keys()) + list(res_samples.keys()))\n",
    "\n",
    "# utils.remove_empty_parquets(samples_dir, year)\n",
    "events_dict = utils.load_samples(signal_samples_dir, res_samples, year, filters)\n",
    "events_dict |= utils.load_samples(samples_dir, samples, year, filters)\n",
    "\n",
    "utils.add_to_cutflow(events_dict, \"BDTPreselection\", \"weight\", cutflow)\n",
    "\n",
    "print(\"\")\n",
    "# print weighted sample yields\n",
    "for sample in events_dict:\n",
    "    tot_weight = np.sum(events_dict[sample][\"weight\"].values)\n",
    "    print(f\"Pre-selection {sample} yield: {tot_weight:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bins = np.arange(-20, 61, 5)\n",
    "plt.hist(events_dict[\"ST\"][\"weight\"], bins, histtype=\"step\", label=\"ST\")\n",
    "plt.hist(events_dict[\"TT\"][\"weight\"], bins, histtype=\"step\", label=\"TT\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"# Events\")\n",
    "plt.xlabel(\"Weights\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{plot_dir}/sttt_weights.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale factors and bb VV assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessing.apply_weights(events_dict, year, cutflow)\n",
    "bb_masks = postprocessing.bb_VV_assignment(events_dict)\n",
    "cutflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample, events in events_dict.items():\n",
    "    h4qvst = (events[\"ak8FatJetParTMD_probHWW3q\"] + events[\"ak8FatJetParTMD_probHWW4q\"]) / (\n",
    "        events[\"ak8FatJetParTMD_probHWW3q\"]\n",
    "        + events[\"ak8FatJetParTMD_probHWW4q\"]\n",
    "        + events[\"ak8FatJetParTMD_probQCD\"]\n",
    "        + events[\"ak8FatJetParTMD_probT\"]\n",
    "    )\n",
    "\n",
    "    events_dict[sample] = pd.concat(\n",
    "        [events, pd.concat([h4qvst], axis=1, keys=[\"ak8FatJetParTMD_THWWvsT\"])], axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {var: (bins, label)}\n",
    "control_plot_vars = {\n",
    "    # \"MET_pt\": ([50, 0, 300], r\"$p^{miss}_T$ (GeV)\"),\n",
    "    # \"DijetEta\": ([50, -8, 8], r\"$\\eta^{jj}$\"),\n",
    "    # \"DijetPt\": ([50, 0, 750], r\"$p_T^{jj}$ (GeV)\"),\n",
    "    \"DijetMass\": (\n",
    "        list(range(800, 1400, 100)) + [1400, 1600, 2000, 3000, 4400],\n",
    "        r\"$m^{jj}$ (GeV)\",\n",
    "    ),\n",
    "    # \"bbFatJetEta\": ([50, -2.4, 2.4], r\"$\\eta^{bb}$\"),\n",
    "    # \"bbFatJetPt\": ([50, 300, 1500], r\"$p^{bb}_T$ (GeV)\"),\n",
    "    # \"bbFatJetParticleNetMass\": ([40, 52.5, 252.5], r\"$m^{bb}_{reg}$ (GeV)\"),\n",
    "    # \"bbFatJetMsd\": ([50, 0, 300], r\"$m^{bb}_{msd}$ (GeV)\"),\n",
    "    # \"bbFatJetParticleNetMD_Txbb\": ([50, 0.8, 1], r\"$p^{bb}_{Txbb}$\"),\n",
    "    # \"VVFatJetEta\": ([50, -2.4, 2.4], r\"$\\eta^{VV}$\"),\n",
    "    # \"VVFatJetPt\": ([50, 300, 1500], r\"$p^{VV}_T$ (GeV)\"),\n",
    "    \"VVFatJetParticleNetMass\": (\n",
    "        list(range(50, 110, 10)) + list(range(110, 200, 15)) + [200, 220, 250],\n",
    "        r\"$m^{VV}_{reg}$ (GeV)\",\n",
    "    ),\n",
    "    # \"VVFatJetMsd\": ([50, 0, 300], r\"$m^{VV}_{msd}$ (GeV)\"),\n",
    "    # \"VVFatJetParticleNet_Th4q\": ([50, 0, 1], r\"Prob($H \\to 4q$) vs Prob(QCD) (Non-MD)\"),\n",
    "    # \"VVFatJetParTMD_THWW4q\": (\n",
    "    #     [50, 0, 1],\n",
    "    #     r\"Prob($H \\to VV \\to 4q$) vs Prob(QCD) (Mass-Decorrelated)\",\n",
    "    # ),\n",
    "    # \"VVFatJetParTMD_probT\": ([50, 0, 1], r\"Prob(Top) (Mass-Decorrelated)\"),\n",
    "    # \"VVFatJetParTMD_THWWvsT\": (\n",
    "    #     [50, 0, 1],\n",
    "    #     r\"Prob($H \\to VV \\to 4q$) vs Prob(QCD + Top) (Mass-Decorrelated)\",\n",
    "    # ),\n",
    "    # \"bbFatJetPtOverDijetPt\": ([50, 0, 40], r\"$p^{bb}_T / p_T^{jj}$\"),\n",
    "    # \"VVFatJetPtOverDijetPt\": ([50, 0, 40], r\"$p^{VV}_T / p_T^{jj}$\"),\n",
    "    # \"VVFatJetPtOverbbFatJetPt\": ([50, 0.4, 2.0], r\"$p^{VV}_T / p^{bb}_T$\"),\n",
    "    # \"nGoodMuons\": ([3, 0, 3], r\"# of Muons\"),\n",
    "    # \"nGoodElectrons\": ([3, 0, 3], r\"# of Electrons\"),\n",
    "    # \"nGoodJets\": ([5, 0, 5], r\"# of AK4 B-Jets\"),\n",
    "}\n",
    "\n",
    "hists = postprocessing.control_plots(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    nonres_sig_keys + res_sig_keys,\n",
    "    control_plot_vars,\n",
    "    f\"{plot_dir}/ControlPlots/{year}/\",\n",
    "    year,\n",
    "    sig_splits=sig_splits,\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall LP SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "sel, cf = utils.make_selection(\n",
    "    res_selection_regions[year][\"lpsf\"], events_dict, bb_masks, prev_cutflow=cutflow\n",
    ")\n",
    "\n",
    "sf_table = OrderedDict()\n",
    "\n",
    "for sig_key in tqdm(nonres_sig_keys + res_sig_keys):\n",
    "    systematics[sig_key] = {}\n",
    "    # calculate only for current year\n",
    "    events_dict[sig_key] = postprocessing.postprocess_lpsfs(events_dict[sig_key])\n",
    "    lp_sf, unc, uncs = postprocessing.get_lpsf(events_dict[sig_key], sel[sig_key])\n",
    "    # print(f\"BDT LP Scale Factor for {sig_key}: {lp_sf:.2f} ± {unc:.2f}\")\n",
    "    # print(uncs)\n",
    "\n",
    "    systematics[sig_key][\"lp_sf\"] = lp_sf\n",
    "    systematics[sig_key][\"lp_sf_unc\"] = unc / lp_sf\n",
    "\n",
    "    sf_table[sig_key] = {\"SF\": f\"{lp_sf:.2f} ± {unc:.2f}\", **uncs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_df = pd.DataFrame(index=nonres_sig_keys + res_sig_keys)\n",
    "\n",
    "for key in sf_table[sig_key]:\n",
    "    sf_df[key] = [sf_table[skey][key] for skey in nonres_sig_keys + res_sig_keys]\n",
    "\n",
    "sf_df.to_clipboard()\n",
    "sf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale signal by LP SF\n",
    "for sig_key in nonres_sig_keys + res_sig_keys:\n",
    "    for wkey in [\"finalWeight\", \"finalWeight_noTrigEffs\"]:\n",
    "        events_dict[sig_key][wkey] *= systematics[sig_key][\"lp_sf\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, tsysts = postprocessing.get_templates(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    year,\n",
    "    nonres_sig_keys + res_sig_keys,\n",
    "    res_selection_regions[year],\n",
    "    res_shape_vars,\n",
    "    bg_keys=[\"QCD\", \"TT\", \"V+Jets\"],\n",
    "    plot_dir=plot_dir,\n",
    "    prev_cutflow=cutflow,\n",
    "    sig_splits=sig_splits,\n",
    "    weight_shifts={},\n",
    "    jshift=\"\",\n",
    "    plot_shifts=False,\n",
    "    pass_ylim=7,\n",
    "    fail_ylim=40000,\n",
    "    blind_pass=True,\n",
    "    show=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {}\n",
    "\n",
    "for jshift in [\"\"] + jec_shifts + jmsr_shifts:\n",
    "    print(jshift)\n",
    "    ttemps, tsyst = postprocessing.get_templates(\n",
    "        events_dict,\n",
    "        bb_masks,\n",
    "        year,\n",
    "        nonres_sig_keys + res_sig_keys,\n",
    "        res_selection_regions[year],\n",
    "        res_shape_vars,\n",
    "        bg_keys=[\"QCD\", \"TT\", \"V+Jets\"],\n",
    "        plot_dir=plot_dir if jshift == \"\" else \"\",\n",
    "        prev_cutflow=cutflow,\n",
    "        sig_splits=sig_splits,\n",
    "        weight_shifts=postprocessing.weight_shifts,\n",
    "        jshift=jshift,\n",
    "        pass_ylim=7,\n",
    "        fail_ylim=40000,\n",
    "        blind_pass=True,\n",
    "        show=False,\n",
    "        plot_shifts=False,\n",
    "    )\n",
    "\n",
    "    templates = {**templates, **ttemps}\n",
    "    if jshift == \"\":\n",
    "        systematics[year] = tsyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{templates_dir}/{year}_templates.pkl\", \"wb\") as f:\n",
    "    pickle.dump(templates, f)\n",
    "\n",
    "with open(f\"{templates_dir}/systematics.json\", \"w\") as f:\n",
    "    json.dump(systematics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{templates_dir}/{year}_templates.pkl\", \"rb\") as f:\n",
    "    templates = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.hist2ds(\n",
    "    templates,\n",
    "    f\"{plot_dir}/templates/hists2d/\",\n",
    "    regions=[\"pass\", \"fail\", \"passBlinded\", \"failBlinded\"],\n",
    "    region_labels=selection_regions_label,\n",
    "    samples=[\"Data\", \"TT\", \"V+Jets\", \"X[3000]->H(bb)Y[190](VV)\"],\n",
    "    # fail_zlim=5e3,\n",
    "    # pass_zlim=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_dict = {}\n",
    "\n",
    "for year in years:\n",
    "    with open(f\"templates/{date}/{year}_templates.pkl\", \"rb\") as f:\n",
    "        templates_dict[year] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = []\n",
    "for year in years:\n",
    "    with open(f\"templates/Apr7//{year}_templates.pkl\", \"rb\") as f:\n",
    "        templates.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15adc7883e707560d0d9727709639b8fe3f3cff1f197d2d643742923ff23a29c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
