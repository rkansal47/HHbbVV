{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotting\n",
    "import postprocessing\n",
    "import utils\n",
    "from hh_vars import data_key\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "\n",
    "# ignore these because they don't seem to apply\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import mplhep as hep\n",
    "from PyPDF2 import PdfMerger\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "hep.style.use(\"CMS\")\n",
    "formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_powerlimits((-3, 3))\n",
    "plt.rcParams.update({\"font.size\": 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = \"../../../plots/ttsfs/24Feb29_update_lps\"\n",
    "\n",
    "import os\n",
    "\n",
    "_ = os.system(f\"mkdir -p {plot_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {\n",
    "    \"QCD\": \"QCD\",\n",
    "    # \"Single Top\": \"ST\",\n",
    "    \"Top\": [\"TTToSemiLeptonic\", \"ST\"],\n",
    "    \"TTbar\": [\"TTTo2L2Nu\", \"TTToHadronic\"],\n",
    "    \"W+Jets\": \"WJets\",\n",
    "    \"Diboson\": [\"WW\", \"WZ\", \"ZZ\"],\n",
    "    \"Data\": \"SingleMuon\",\n",
    "}\n",
    "\n",
    "top_matched_key = \"TT Top Matched\"\n",
    "\n",
    "data_dir = \"../../../../data/ttsfs/24Feb28_update_lp/\"\n",
    "year = \"2018\"\n",
    "\n",
    "# filters = [(\"('ak8FatJetPt', '0')\", \">=\", 500)]\n",
    "filters = None\n",
    "\n",
    "events_dict = postprocessing.load_samples(data_dir, samples, year, hem_cleaning=False)\n",
    "\n",
    "cutflow = pd.DataFrame(index=list(samples.keys()))\n",
    "utils.add_to_cutflow(events_dict, \"Selection\", \"weight\", cutflow)\n",
    "cutflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_pickles(f\"{data_dir}/{year}/TTToSemiLeptonic/pickles\", year, \"TTToSemiLeptonic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_pickles(f\"{data_dir}/{year}/SingleMuon_Run2018C/pickles\", year, \"SingleMuon_Run2018D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_pickles(f\"{data_dir}/{year}/SingleMuon_Run2018D/pickles\", year, \"SingleMuon_Run2018D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9006700 / 10030532"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_pre = 0\n",
    "tot_hem = 0\n",
    "for run in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "    cf = utils.get_pickles(\n",
    "        f\"{data_dir}/{year}/SingleMuon_Run2018{run}/pickles\", year, f\"SingleMuon_Run2018{run}\"\n",
    "    )[\"cutflow\"]\n",
    "    tot_pre += cf[\"ak4_jet\"]\n",
    "    tot_hem += cf[\"hem_cleaning\"]\n",
    "\n",
    "print(tot_hem / tot_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3127 / 3774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "679 / 796"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = 0\n",
    "# for sample, events in events_dict.items():\n",
    "#     if sample != \"Data\":\n",
    "#         total += events[\"weight\"].sum().values[0]\n",
    "\n",
    "# print(f\"Total MC: {total}\")\n",
    "\n",
    "# sf = events[\"weight\"].sum().values[0] / total\n",
    "# for sample, events in events_dict.items():\n",
    "#     if sample != \"Data\":\n",
    "#         events[\"weight\"] *= sf\n",
    "\n",
    "# total = 0\n",
    "# for sample, events in events_dict.items():\n",
    "#     if sample != \"Data\":\n",
    "#         total += events[\"weight\"].sum().values[0]\n",
    "\n",
    "# print(f\"New Total MC: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_dict[top_matched_key] = events_dict[\"Top\"].loc[events_dict[\"Top\"][\"top_matched\"][0] == 1]\n",
    "events_dict[\"TT W Matched\"] = events_dict[\"Top\"].loc[events_dict[\"Top\"][\"w_matched\"][0] == 1]\n",
    "events_dict[\"TT Unmatched\"] = pd.concat(\n",
    "    [events_dict[\"TTbar\"], events_dict[\"Top\"].loc[events_dict[\"Top\"][\"unmatched\"][0] == 1]]\n",
    ")\n",
    "# del events_dict[\"Top\"]\n",
    "# del events_dict[\"TTbar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize scale factors to average to 1\n",
    "for key in [\n",
    "    \"lp_sf\",\n",
    "    \"lp_sf_lnN\",\n",
    "    \"lp_sf_sys_down\",\n",
    "    \"lp_sf_sys_up\",\n",
    "    \"lp_sf_pt_extrap_vars\",\n",
    "    \"lp_sfs_bl_ratio\",\n",
    "]:\n",
    "    # cut off at 10\n",
    "    events_dict[top_matched_key].loc[:, key] = np.clip(\n",
    "        events_dict[top_matched_key].loc[:, key].values, 0.1, 10\n",
    "    )\n",
    "    if key == \"lp_sfs_bl_ratio\":\n",
    "        mean_lp_sfs = np.mean(\n",
    "            np.nan_to_num(\n",
    "                events_dict[top_matched_key][key][0] * events_dict[top_matched_key][\"lp_sf_lnN\"][0]\n",
    "            ),\n",
    "            axis=0,\n",
    "        )\n",
    "    else:\n",
    "        mean_lp_sfs = np.mean(np.nan_to_num(events_dict[top_matched_key][key]), axis=0)\n",
    "\n",
    "    events_dict[top_matched_key].loc[:, key] = (\n",
    "        np.nan_to_num(events_dict[top_matched_key].loc[:, key]) / mean_lp_sfs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 24})\n",
    "plt.figure(figsize=(12, 12))\n",
    "_ = plt.hist(\n",
    "    events_dict[top_matched_key][\"lp_sf\"][10].values,\n",
    "    np.logspace(-4, 2, 101, base=10),\n",
    "    histtype=\"step\",\n",
    ")\n",
    "plt.xscale(\"log\")\n",
    "# plt.yscale(\"log\")\n",
    "plt.xlabel(\"LP SF\")\n",
    "plt.title(\"Scale factor distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in events_dict:\n",
    "    events_dict[key] = events_dict[key][events_dict[key][\"ak8FatJetPt\"][0] >= 500]\n",
    "    events_dict[key] = events_dict[key][events_dict[key][\"ak8FatJetMsd\"][0] >= 125]\n",
    "    events_dict[key] = events_dict[key][events_dict[key][\"ak8FatJetMsd\"][0] <= 225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = events_dict[top_matched_key]\n",
    "sj_matching_unc = (\n",
    "    (np.sum(events[\"lp_sf_unmatched_quarks\"]) / (len(events) * 3))\n",
    "    # OR of double matched and boundary quarks\n",
    "    # >0.1 to avoid floating point errors\n",
    "    + (\n",
    "        np.sum((events[\"lp_sf_double_matched_event\"] + events[\"lp_sf_boundary_quarks\"]) > 0.1)\n",
    "        / (len(events))\n",
    "    )\n",
    ").values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_matching_unc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples = [\n",
    "    \"QCD\",\n",
    "    \"Diboson\",\n",
    "    # \"Single Top\",\n",
    "    \"W+Jets\",\n",
    "    \"TT Unmatched\",\n",
    "    \"TT W Matched\",\n",
    "    top_matched_key,\n",
    "]\n",
    "\n",
    "bg_colours = {\n",
    "    \"QCD\": \"lightblue\",\n",
    "    \"Single Top\": \"darkblue\",\n",
    "    \"TT Unmatched\": \"darkgreen\",\n",
    "    \"TT W Matched\": \"green\",\n",
    "    \"TT Top Matched\": \"orange\",\n",
    "    \"W+Jets\": \"darkred\",\n",
    "    \"Diboson\": \"red\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {var: (bins, label)}\n",
    "plot_vars = {\n",
    "    \"ak8FatJetMsd\": ([20, 125, 225], r\"$m_{SD}$ (GeV)\"),\n",
    "    # \"ak8FatJetParticleNetMass\": ([30, 50, 200], r\"$m_{reg}$ (GeV)\"),\n",
    "    # \"ak8FatJetPt\": ([30, 0, 1200], r\"$p_T$ (GeV)\"),\n",
    "    # \"MET_pt\": ([30, 0, 200], r\"MET (GeV)\"),\n",
    "    # \"ak8FatJetnPFCands\": ([20, 0, 120], r\"# of PF Candidates\"),\n",
    "    # \"ak8FatJetParticleNet_Th4q\": ([20, 0.6, 1], r\"ParticleNet $T_{H4q}$ Non-MD\"),\n",
    "    \"ak8FatJetParTMD_THWW4q\": ([20, 0.2, 1], r\"ParT $T_{HWW4q}$ MD\"),\n",
    "    # \"tau21\": ([20, 0.04, 0.8], r\"$\\tau_{21}$\"),\n",
    "    # \"tau32\": ([20, 0.2, 1], r\"$\\tau_{32}$\"),\n",
    "    # \"tau43\": ([20, 0.42, 1], r\"$\\tau_{43}$\"),\n",
    "    # \"tau42\": ([20, 0, 1], r\"$\\tau_{42}$\"),\n",
    "    # \"tau41\": ([20, 0, 1], r\"$\\tau_{41}$\"),\n",
    "}\n",
    "\n",
    "pre_hists = {}\n",
    "\n",
    "for var, (bins, label) in plot_vars.items():\n",
    "    if var not in pre_hists:\n",
    "        pre_hists[var] = utils.singleVarHistNoMask(\n",
    "            events_dict, var, bins, label, weight_key=\"weight\"\n",
    "        )\n",
    "\n",
    "merger_pre_plots = PdfMerger()\n",
    "\n",
    "for var, var_hist in pre_hists.items():\n",
    "    name = f\"{plot_dir}/pre_{var}.pdf\"\n",
    "    plotting.ratioLinePlot(\n",
    "        var_hist,\n",
    "        plot_samples,\n",
    "        year,\n",
    "        # bg_err=None,\n",
    "        name=name,\n",
    "        bg_colours=bg_colours,\n",
    "        # bg_order=plot_samples,\n",
    "        # ratio_ylims=[0.6, 1.3],\n",
    "    )\n",
    "    merger_pre_plots.append(name)\n",
    "\n",
    "merger_pre_plots.write(f\"{plot_dir}/PrePlots.pdf\")\n",
    "merger_pre_plots.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_hists = {}\n",
    "post_hists_err = {}\n",
    "uncs_dict = {}\n",
    "\n",
    "events = events_dict[top_matched_key]\n",
    "\n",
    "for var, (bins, label) in plot_vars.items():\n",
    "    # if var not in post_hists:\n",
    "    toy_hists = []\n",
    "    for i in range(events[\"lp_sf\"].shape[1]):\n",
    "        toy_hists.append(\n",
    "            np.histogram(\n",
    "                events[var][0].values.squeeze(),\n",
    "                np.linspace(*bins[1:], bins[0] + 1),\n",
    "                weights=events[\"weight\"][0].values * events[\"lp_sf\"][i].values,\n",
    "            )[0]\n",
    "        )\n",
    "\n",
    "    sys_up_down = []\n",
    "    for key in [\"lp_sf_sys_up\", \"lp_sf_sys_down\"]:\n",
    "        sys_up_down.append(\n",
    "            np.histogram(\n",
    "                events[var][0].values.squeeze(),\n",
    "                np.linspace(*bins[1:], bins[0] + 1),\n",
    "                weights=events[\"weight\"][0].values * events[key][0].values,\n",
    "            )[0]\n",
    "        )\n",
    "\n",
    "    nom_vals = toy_hists[0]  # first column are nominal values\n",
    "\n",
    "    pt_toy_hists = []\n",
    "    for i in range(events[\"lp_sf_pt_extrap_vars\"].shape[1]):\n",
    "        pt_toy_hists.append(\n",
    "            np.histogram(\n",
    "                events[var][0].values.squeeze(),\n",
    "                np.linspace(*bins[1:], bins[0] + 1),\n",
    "                weights=events[\"weight\"][0].values * events[\"lp_sf_pt_extrap_vars\"][i].values,\n",
    "            )[0]\n",
    "        )\n",
    "\n",
    "    b_ratio_hist = np.histogram(\n",
    "        events[var][0].values.squeeze(),\n",
    "        np.linspace(*bins[1:], bins[0] + 1),\n",
    "        weights=events[\"weight\"][0].values\n",
    "        * events[\"lp_sfs_bl_ratio\"][0].values\n",
    "        * events[\"lp_sf_lnN\"][0].values,\n",
    "    )[0]\n",
    "\n",
    "    uncs = {\n",
    "        \"stat_unc\": np.minimum(nom_vals, np.std(toy_hists[1:], axis=0)),  # cap at 100% unc\n",
    "        \"syst_rat_unc\": np.minimum(nom_vals, (np.abs(sys_up_down[0] - sys_up_down[1])) / 2),\n",
    "        \"syst_sjm_unc\": nom_vals * sj_matching_unc,\n",
    "        \"syst_sjpt_unc\": np.minimum(nom_vals, np.std(pt_toy_hists, axis=0)),\n",
    "        \"syst_b_unc\": np.abs(1 - (b_ratio_hist / nom_vals)) * nom_vals,\n",
    "    }\n",
    "\n",
    "    uncs_dict[var] = uncs\n",
    "\n",
    "    unc = np.linalg.norm(list(uncs.values()), axis=0)\n",
    "\n",
    "    thist = deepcopy(pre_hists[var])\n",
    "    top_matched_key_index = np.where(np.array(list(thist.axes[0])) == top_matched_key)[0][0]\n",
    "    thist.view(flow=False)[top_matched_key_index, :].value = nom_vals\n",
    "    post_hists[var] = thist\n",
    "    post_hists_err[var] = unc\n",
    "\n",
    "\n",
    "merger_post_plots = PdfMerger()\n",
    "\n",
    "for var, var_hist in post_hists.items():\n",
    "    name = f\"{plot_dir}/post_{var}.pdf\"\n",
    "    plotting.ratioLinePlot(\n",
    "        var_hist,\n",
    "        plot_samples,\n",
    "        year,\n",
    "        bg_colours=bg_colours,\n",
    "        bg_err=post_hists_err[var],\n",
    "        name=name,\n",
    "    )\n",
    "    merger_post_plots.append(name)\n",
    "\n",
    "merger_post_plots.write(f\"{plot_dir}/PostPlots.pdf\")\n",
    "merger_post_plots.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post LnN Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_lnN_hists = {}\n",
    "post_lnN_hists_err = {}\n",
    "uncs_lnN_dict = {}\n",
    "\n",
    "events = events_dict[top_matched_key]\n",
    "\n",
    "for var, (bins, label) in plot_vars.items():\n",
    "    if var not in post_lnN_hists:\n",
    "        toy_hists = []\n",
    "        for i in range(events[\"lp_sf_lnN\"].shape[1]):\n",
    "            toy_hists.append(\n",
    "                np.histogram(\n",
    "                    events[var][0].values.squeeze(),\n",
    "                    np.linspace(*bins[1:], bins[0] + 1),\n",
    "                    weights=events[\"weight\"][0].values * events[\"lp_sf_lnN\"][i].values,\n",
    "                )[0]\n",
    "            )\n",
    "\n",
    "        sys_up_down = []\n",
    "        for key in [\"lp_sf_sys_up\", \"lp_sf_sys_down\"]:\n",
    "            sys_up_down.append(\n",
    "                np.histogram(\n",
    "                    events[var][0].values.squeeze(),\n",
    "                    np.linspace(*bins[1:], bins[0] + 1),\n",
    "                    weights=events[\"weight\"][0].values * events[key][0].values,\n",
    "                )[0]\n",
    "            )\n",
    "\n",
    "        nom_vals = toy_hists[0]  # first column are nominal values\n",
    "\n",
    "        pt_toy_hists = []\n",
    "        for i in range(events[\"lp_sf_pt_extrap_vars\"].shape[1]):\n",
    "            pt_toy_hists.append(\n",
    "                np.histogram(\n",
    "                    events[var][0].values.squeeze(),\n",
    "                    np.linspace(*bins[1:], bins[0] + 1),\n",
    "                    weights=events[\"weight\"][0].values * events[\"lp_sf_pt_extrap_vars\"][i].values,\n",
    "                )[0]\n",
    "            )\n",
    "\n",
    "        b_ratio_hist = np.histogram(\n",
    "            events[var][0].values.squeeze(),\n",
    "            np.linspace(*bins[1:], bins[0] + 1),\n",
    "            weights=events[\"weight\"][0].values\n",
    "            * events[\"lp_sfs_bl_ratio\"][0].values\n",
    "            * events[\"lp_sf_lnN\"][0].values,\n",
    "        )[0]\n",
    "\n",
    "        uncs = {\n",
    "            \"stat_unc\": np.minimum(nom_vals, np.std(toy_hists[1:], axis=0)),  # cap at 100% unc\n",
    "            \"syst_rat_unc\": np.minimum(nom_vals, (np.abs(sys_up_down[0] - sys_up_down[1])) / 2),\n",
    "            \"syst_sjm_unc\": nom_vals * sj_matching_unc,\n",
    "            \"syst_sjpt_unc\": np.minimum(nom_vals, np.std(pt_toy_hists, axis=0)),\n",
    "            \"syst_b_unc\": np.abs(1 - (b_ratio_hist / nom_vals)) * nom_vals,\n",
    "        }\n",
    "\n",
    "        uncs_lnN_dict[var] = uncs\n",
    "\n",
    "        unc = np.linalg.norm(list(uncs.values()), axis=0)\n",
    "\n",
    "        thist = deepcopy(pre_hists[var])\n",
    "        top_matched_key_index = np.where(np.array(list(thist.axes[0])) == top_matched_key)[0][0]\n",
    "        thist.view(flow=False)[top_matched_key_index, :].value = nom_vals\n",
    "        post_lnN_hists[var] = thist\n",
    "\n",
    "        post_lnN_hists_err[var] = unc\n",
    "\n",
    "\n",
    "merger_post_plots = PdfMerger()\n",
    "\n",
    "for var, var_hist in post_lnN_hists.items():\n",
    "    name = f\"{plot_dir}/postlnN_{var}.pdf\"\n",
    "    plotting.ratioLinePlot(\n",
    "        var_hist,\n",
    "        plot_samples,\n",
    "        year,\n",
    "        bg_colours=bg_colours,\n",
    "        bg_err=post_lnN_hists_err[var],\n",
    "        name=name,\n",
    "    )\n",
    "    merger_post_plots.append(name)\n",
    "\n",
    "merger_post_plots.write(f\"{plot_dir}/PostLnNPlots.pdf\")\n",
    "merger_post_plots.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binn = -1\n",
    "tvar = \"ak8FatJetParTMD_THWW4q\"\n",
    "pre_vals = pre_hists[tvar].view(flow=False)[top_matched_key_index, :].value\n",
    "nom_vals = post_hists[tvar].view(flow=False)[top_matched_key_index, :].value\n",
    "unc = post_hists_err[tvar]\n",
    "print(\"SF: \", nom_vals[binn] / pre_vals[binn])\n",
    "print(\"Uncs: \", {key: val[binn] / nom_vals[binn] * 100 for key, val in uncs_dict[tvar].items()})\n",
    "print(\"Combined: \", unc[binn] / nom_vals[binn] * 100)\n",
    "print(\"Abs: \", unc[binn] / pre_vals[binn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binn = -1\n",
    "tvar = \"ak8FatJetParTMD_THWW4q\"\n",
    "pre_vals = pre_hists[tvar].view(flow=False)[top_matched_key_index, :].value\n",
    "nom_vals = post_lnN_hists[tvar].view(flow=False)[top_matched_key_index, :].value\n",
    "unc = post_lnN_hists_err[tvar]\n",
    "print(\"SF: \", nom_vals[binn] / pre_vals[binn])\n",
    "print(\"Uncs: \", {key: val[binn] / nom_vals[binn] * 100 for key, val in uncs_lnN_dict[tvar].items()})\n",
    "print(\"Combined: \", unc[binn] / nom_vals[binn] * 100)\n",
    "print(\"Abs: \", unc[binn] / pre_vals[binn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vals = pre_hists[tvar][\"Data\", ...].values()\n",
    "pre_MC_vals = (\n",
    "    pre_hists[tvar][sum, :].values()\n",
    "    - data_vals\n",
    "    # - pre_hists[tvar][\"TTbar\", :].values()\n",
    "    # - pre_hists[tvar][\"TTSL\", :].values()\n",
    ")\n",
    "post_lnN_MC_vals = (\n",
    "    post_lnN_hists[tvar][sum, :].values()\n",
    "    - data_vals\n",
    "    # - post_lnN_hists[tvar][\"TTbar\", :].values()\n",
    "    # - post_lnN_hists[tvar][\"TTSL\", :].values()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chisquare(mc, data):\n",
    "    return np.sum(np.square(data - mc) / data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = 5\n",
    "print(\"Pre chi2:\", chisquare(pre_MC_vals[-lb:], data_vals[-lb:]))\n",
    "print(\"Post chi2:\", chisquare(post_lnN_MC_vals[-lb:], data_vals[-lb:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"QCD\",\n",
    "\"Diboson\",\n",
    "\"Single Top\",\n",
    "\"W+Jets\",\n",
    "\"TT Unmatched\",\n",
    "\"TT W Matched\",\n",
    "top_matched_key,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_lnN_hists[tvar][\"Data\", :].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    post_lnN_hists[tvar][sum, :].values()\n",
    "    - post_lnN_hists[tvar][\"Data\", :].values()\n",
    "    - post_lnN_hists[tvar][\"TTbar\", :].values()\n",
    "    - post_lnN_hists[tvar][\"TTSL\", :].values()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvar = \"ak8FatJetParTMD_THWW4q\"\n",
    "\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# hists = pre_hists[tvar]\n",
    "# bg_tot = np.sum(hists[plot_samples, :].values(), axis=0)\n",
    "# mcdata_ratio = (bg_tot + 1e-5) / hists[data_key, :].values()\n",
    "# _ = plt.hist(mcdata_ratio - 1, np.linspace(-0.5, 0.5, 10), histtype='step')\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "hists = post_hists[tvar]\n",
    "bg_tot = np.sum(hists[plot_samples, :].values(), axis=0)\n",
    "data_tot = hists[data_key, :].values()\n",
    "unc = post_hists_err[tvar]\n",
    "mcdata_ratio = (bg_tot) / data_tot\n",
    "_ = plt.hist(((bg_tot - data_tot) / (unc))[10:], np.linspace(-6.5, 4.5, 23), histtype=\"step\")\n",
    "plt.xlabel(\"(MC - Data) / Unc.\")\n",
    "plt.savefig(f\"{plot_dir}/pull_hist.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.ratioLinePlot(\n",
    "    post_hists[tvar],\n",
    "    plot_samples,\n",
    "    year,\n",
    "    bg_err=post_hists_err[tvar],\n",
    "    name=f\"{plot_dir}/post_ak8FatJetParTMD_THWW4q_pulls.pdf\",\n",
    "    pulls=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_dict = {}\n",
    "\n",
    "for key in events_dict:\n",
    "    cut_dict[key] = events_dict[key][events_dict[key][\"tau42\"][0] <= 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {var: (bins, label)}\n",
    "plot_vars = {\n",
    "    \"ak8FatJetParTMD_THWW4q\": ([20, 0.6, 1], r\"ParT $T_{HWW4q}$ MD\"),\n",
    "}\n",
    "\n",
    "pre_hists_cut = {}\n",
    "\n",
    "for var, (bins, label) in plot_vars.items():\n",
    "    if var not in pre_hists_cut:\n",
    "        pre_hists_cut[var] = utils.singleVarHistNoMask(\n",
    "            cut_dict, var, bins, label, weight_key=\"weight\"\n",
    "        )\n",
    "\n",
    "merger_pre_plots = PdfFileMerger()\n",
    "\n",
    "for var, var_hist in pre_hists_cut.items():\n",
    "    name = f\"{plot_dir}/pre_{var}_tau42_cut.pdf\"\n",
    "    plotting.ratioLinePlot(\n",
    "        var_hist,\n",
    "        plot_samples,\n",
    "        year,\n",
    "        bg_err=None,\n",
    "        name=name,\n",
    "    )\n",
    "    merger_pre_plots.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_lnN_cut_hists = {}\n",
    "post_lnN_cut_hists_err = {}\n",
    "uncs_lnN_cut_dict = {}\n",
    "\n",
    "events = cut_dict[top_matched_key]\n",
    "\n",
    "for var, (bins, label) in plot_vars.items():\n",
    "    if var not in post_lnN_cut_hists:\n",
    "        toy_hists = []\n",
    "        for i in range(events[\"lp_sf_lnN\"].shape[1]):\n",
    "            toy_hists.append(\n",
    "                np.histogram(\n",
    "                    events[var][0].values.squeeze(),\n",
    "                    np.linspace(*bins[1:], bins[0] + 1),\n",
    "                    weights=events[\"weight\"][0].values * events[\"lp_sf_lnN\"][i].values,\n",
    "                )[0]\n",
    "            )\n",
    "\n",
    "        sys_up_down = []\n",
    "        for key in [\"lp_sf_sys_up\", \"lp_sf_sys_down\"]:\n",
    "            sys_up_down.append(\n",
    "                np.histogram(\n",
    "                    events[var][0].values.squeeze(),\n",
    "                    np.linspace(*bins[1:], bins[0] + 1),\n",
    "                    weights=events[\"weight\"][0].values * events[key][0].values,\n",
    "                )[0]\n",
    "            )\n",
    "\n",
    "        nom_vals = toy_hists[0]  # first column are nominal values\n",
    "\n",
    "        uncs = {\n",
    "            \"stat_unc\": np.minimum(nom_vals, np.std(toy_hists[1:], axis=0)),  # cap at 100% unc\n",
    "            \"syst_rat_unc\": np.minimum(nom_vals, (np.abs(sys_up_down[0] - sys_up_down[1])) / 2),\n",
    "            \"syst_sjm_unc\": nom_vals * sj_matching_unc,\n",
    "            \"syst_sjpt_unc\": nom_vals * sj_pt_unc,\n",
    "        }\n",
    "\n",
    "        uncs_lnN_cut_dict[var] = uncs\n",
    "\n",
    "        unc = np.linalg.norm(list(uncs.values()), axis=0)\n",
    "\n",
    "        thist = deepcopy(pre_hists[var])\n",
    "        top_matched_key_index = np.where(np.array(list(thist.axes[0])) == top_matched_key)[0][0]\n",
    "        thist.view(flow=False)[top_matched_key_index, :].value = nom_vals\n",
    "        post_lnN_cut_hists[var] = thist\n",
    "\n",
    "        post_lnN_cut_hists_err[var] = unc\n",
    "\n",
    "\n",
    "merger_post_plots = PdfFileMerger()\n",
    "\n",
    "for var, var_hist in post_lnN_cut_hists.items():\n",
    "    name = f\"{plot_dir}/postlnN_{var}_cut.pdf\"\n",
    "    plotting.ratioLinePlot(\n",
    "        var_hist,\n",
    "        plot_samples,\n",
    "        year,\n",
    "        bg_err=post_lnN_cut_hists_err[var],\n",
    "        name=name,\n",
    "    )\n",
    "    merger_post_plots.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_hist = utils.singleVarHistNoMask(\n",
    "    events_dict, \"ak8FatJetMass\", [20, 125, 225], r\"$m_{SD}$\", weight_key=\"weight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.ratioHistPlot(\n",
    "    mass_hist,\n",
    "    [\"QCD\", \"Diboson\", \"Single Top\", \"W+Jets\", \"TT Unmatched\", \"TT W Matched\", top_matched_key],\n",
    "    f\"{plot_dir}/\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('python310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31a7b1cb5f073f7a7d37b3db504c6954ce2b88e0f82e412b65ad0b5f2dd17394"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
