{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import plotting\n",
    "import postprocessing\n",
    "import corrections\n",
    "\n",
    "from utils import CUT_MAX_VAL\n",
    "from hh_vars import years, sig_key, data_key, qcd_key, bg_keys, samples, txbb_wps\n",
    "from postprocessing import (\n",
    "    shape_var,\n",
    "    shape_bins,\n",
    "    blind_window,\n",
    "    selection_regions,\n",
    "    selection_regions_label,\n",
    "    # selection_regions_year,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "from hist import Hist\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from inspect import cleandoc\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "hep.style.use(\"CMS\")\n",
    "formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_powerlimits((-3, 3))\n",
    "plt.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "# ignore these because they don't seem to apply\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = \"../../../\"\n",
    "samples_dir = f\"{MAIN_DIR}/../data/skimmer/Feb20\"\n",
    "signal_samples_dir = f\"{MAIN_DIR}/../data/skimmer/Feb20\"\n",
    "year = \"2017\"\n",
    "\n",
    "plot_dir = \"../../../plots/PostProcessing/Feb21\"\n",
    "templates_dir = \"templates/Feb21/\"\n",
    "_ = os.system(f\"mkdir -p {plot_dir}\")\n",
    "_ = os.system(f\"mkdir -p {templates_dir}\")\n",
    "\n",
    "systematics = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = None\n",
    "\n",
    "# save cutflow as pandas table\n",
    "cutflow = pd.DataFrame(index=list(samples.keys()))\n",
    "\n",
    "# utils.remove_empty_parquets(samples_dir, year)\n",
    "events_dict = utils.load_samples(signal_samples_dir, {sig_key: samples[sig_key]}, year, filters)\n",
    "events_dict |= utils.load_samples(\n",
    "    samples_dir, {k: samples[k] for k in samples.keys() - [sig_key]}, year, filters\n",
    ")\n",
    "\n",
    "utils.add_to_cutflow(events_dict, \"BDTPreselection\", \"weight\", cutflow)\n",
    "\n",
    "# print weighted sample yields\n",
    "for sample in events_dict:\n",
    "    tot_weight = np.sum(events_dict[sample][\"weight\"].values)\n",
    "    print(f\"Pre-selection {sample} yield: {tot_weight:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale factors and bb VV assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessing.apply_weights(events_dict, year, cutflow)\n",
    "bb_masks = postprocessing.bb_VV_assignment(events_dict)\n",
    "events_dict[sig_key] = postprocessing.postprocess_lpsfs(events_dict[sig_key])\n",
    "cutflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessing.load_bdt_preds(\n",
    "    events_dict, year, samples_dir, list(samples.keys()), jec_jmsr_shifts=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall BDT SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel, cf = utils.make_selection(\n",
    "    selection_regions[year][\"BDTOnly\"], events_dict, bb_masks, prev_cutflow=cutflow\n",
    ")\n",
    "lp_sf, unc, uncs = postprocessing.get_lpsf(events_dict[sig_key], sel[sig_key])\n",
    "print(f\"BDT Scale Factor: {lp_sf:.2f} Â± {unc:.2f}\")\n",
    "print(uncs)\n",
    "systematics[\"lp_sf_unc\"] = unc / lp_sf\n",
    "cf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_shifts = {\n",
    "    \"pileup\": [sig_key] + bg_keys,\n",
    "    \"PDFalphaS\": [sig_key],\n",
    "    \"ISRPartonShower\": [sig_key, \"V+Jets\"],\n",
    "    \"FSRPartonShower\": [sig_key, \"V+Jets\"],\n",
    "}\n",
    "\n",
    "weight_labels = {\n",
    "    \"pileup\": \"Pileup\",\n",
    "    \"PDFalphaS\": \"PDF\",\n",
    "    \"ISRPartonShower\": \"ISR Parton Shower\",\n",
    "    \"FSRPartonShower\": \"FSR Parton Shower\",\n",
    "}\n",
    "\n",
    "# Check for 0 weights - would be an issue for weight shifts\n",
    "print(\n",
    "    \"Any 0 weights:\",\n",
    "    np.any(\n",
    "        [\n",
    "            np.any(events[\"weight_nonorm\"] == 0)\n",
    "            for key, events in events_dict.items()\n",
    "            if key != data_key\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_cutflow = cutflow\n",
    "weight_key = \"finalWeight\"\n",
    "cutstr = \"\"\n",
    "var = shape_var[0]\n",
    "show = True\n",
    "\n",
    "for label, region in selection_regions[year].items():\n",
    "    # print(region)\n",
    "    pass_region = label.startswith(\"pass\")\n",
    "\n",
    "    if region == \"BDTOnly\":\n",
    "        continue\n",
    "\n",
    "    # if not pass_region:\n",
    "    #     continue\n",
    "\n",
    "    sel, cf = utils.make_selection(region, events_dict, bb_masks, prev_cutflow=prev_cutflow)\n",
    "\n",
    "    # ParticleNetMD Txbb SFs\n",
    "    sig_events = deepcopy(events_dict[sig_key][sel[sig_key]])\n",
    "    sig_bb_mask = bb_masks[sig_key][sel[sig_key]]\n",
    "    if pass_region:\n",
    "        corrections.apply_txbb_sfs(sig_events, sig_bb_mask, year, weight_key)\n",
    "\n",
    "    # set up samples\n",
    "    hist_samples = list(events_dict.keys())\n",
    "    for shift in [\"down\", \"up\"]:\n",
    "        if pass_region:\n",
    "            hist_samples.append(f\"{sig_key}_txbb_{shift}\")\n",
    "\n",
    "        for wshift, wsamples in weight_shifts.items():\n",
    "            for wsample in wsamples:\n",
    "                hist_samples.append(f\"{wsample}_{wshift}_{shift}\")\n",
    "\n",
    "    h = (\n",
    "        Hist.new.StrCat(hist_samples, name=\"Sample\")\n",
    "        .Reg(*shape_bins, name=var, label=shape_var[1])\n",
    "        .Weight()\n",
    "    )\n",
    "\n",
    "    for sample in events_dict:\n",
    "        # print(sample)\n",
    "        events = sig_events if sample == sig_key else events_dict[sample][sel[sample]]\n",
    "\n",
    "        bb_mask = bb_masks[sample][sel[sample]]\n",
    "        fill_data = {var: utils.get_feat(events, var, bb_mask)}\n",
    "        weight = events[weight_key].values.squeeze()\n",
    "        h.fill(Sample=sample, **fill_data, weight=weight)\n",
    "\n",
    "        # add weight variations\n",
    "        for wshift, wsamples in weight_shifts.items():\n",
    "            if sample in wsamples:\n",
    "                # print(wshift)\n",
    "                for skey, shift in [(\"Down\", \"down\"), (\"Up\", \"up\")]:\n",
    "                    # reweight based on diff between up/down and nominal weights\n",
    "                    sweight = (\n",
    "                        weight\n",
    "                        * (\n",
    "                            events[f\"weight_{wshift}{skey}\"][0] / events[\"weight_nonorm\"]\n",
    "                        ).values.squeeze()\n",
    "                    )\n",
    "                    # print(weight)\n",
    "                    # print(sweight)\n",
    "                    # print(events[f\"weight_{wshift}{skey}\"][0])\n",
    "                    # print(events[\"weight_nonorm\"])\n",
    "                    h.fill(Sample=f\"{sample}_{wshift}_{shift}\", **fill_data, weight=sweight)\n",
    "\n",
    "    if pass_region:\n",
    "        # blind Higgs mass window in pass region in data\n",
    "        utils.blindBins(h, blind_window, data_key)\n",
    "\n",
    "    if pass_region:\n",
    "        # ParticleNetMD Txbb SFs\n",
    "        fill_data = {var: utils.get_feat(sig_events, var, sig_bb_mask)}\n",
    "        for shift in [\"down\", \"up\"]:\n",
    "            h.fill(\n",
    "                Sample=f\"{sig_key}_txbb_{shift}\",\n",
    "                **fill_data,\n",
    "                weight=sig_events[f\"{weight_key}_txbb_{shift}\"],\n",
    "            )\n",
    "\n",
    "    sig_scale = utils.getSignalPlotScaleFactor(events_dict, selection=sel)\n",
    "\n",
    "    if plot_dir != \"\":\n",
    "        plot_params = {\"hists\": h, \"bg_keys\": bg_keys, \"sig_scale\": sig_scale / 2, \"show\": show}\n",
    "        plotting.ratioHistPlot(\n",
    "            **plot_params,\n",
    "            title=f\"{selection_regions_label[label]} Region Pre-Fit Shapes\",\n",
    "            name=f\"{plot_dir}/{cutstr}{label}_region_bb_mass.pdf\",\n",
    "        )\n",
    "\n",
    "        for wshift, wsamples in weight_shifts.items():\n",
    "            wlabel = weight_labels[wshift]\n",
    "\n",
    "            if wsamples == [sig_key]:\n",
    "                plotting.ratioHistPlot(\n",
    "                    **plot_params,\n",
    "                    sig_err=wshift,\n",
    "                    title=f\"{selection_regions_label[label]} Region {wlabel} Unc. Shapes\",\n",
    "                    name=f\"{plot_dir}/{cutstr}{label}_region_bb_mass_{wshift}.pdf\",\n",
    "                )\n",
    "            else:\n",
    "                for skey, shift in [(\"Down\", \"down\"), (\"Up\", \"up\")]:\n",
    "                    plotting.ratioHistPlot(\n",
    "                        **plot_params,\n",
    "                        variation=(wshift, shift, wsamples),\n",
    "                        title=f\"{selection_regions_label[label]} Region {wlabel} Unc. {skey} Shapes\",\n",
    "                        name=f\"{plot_dir}/{cutstr}{label}_region_bb_mass_{wshift}_{shift}.pdf\",\n",
    "                    )\n",
    "\n",
    "        if pass_region:\n",
    "            plotting.ratioHistPlot(\n",
    "                **plot_params,\n",
    "                sig_err=\"txbb\",\n",
    "                title=rf\"{selection_regions_label[label]} Region $T_{{Xbb}}$ Shapes\",\n",
    "                name=f\"{plot_dir}/{cutstr}{label}_region_bb_mass_txbb.pdf\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15adc7883e707560d0d9727709639b8fe3f3cff1f197d2d643742923ff23a29c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
