{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import plotting\n",
    "import postprocessing\n",
    "import corrections\n",
    "from collections import OrderedDict\n",
    "\n",
    "from utils import CUT_MAX_VAL\n",
    "from hh_vars import (\n",
    "    years,\n",
    "    data_key,\n",
    "    qcd_key,\n",
    "    bg_keys,\n",
    "    samples,\n",
    "    nonres_sig_keys,\n",
    "    nonres_samples,\n",
    "    txbb_wps,\n",
    "    jec_shifts,\n",
    "    jmsr_shifts,\n",
    ")\n",
    "from postprocessing import nonres_shape_vars\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "from hist import Hist\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from inspect import cleandoc\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "hep.style.use(\"CMS\")\n",
    "formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_powerlimits((-3, 3))\n",
    "plt.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "# ignore these because they don't seem to apply\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = \"../../../\"\n",
    "samples_dir = f\"{MAIN_DIR}/../data/skimmer/Feb24\"\n",
    "signal_samples_dir = f\"{MAIN_DIR}/../data/skimmer/Jun10\"\n",
    "bdt_preds_dir = f\"{MAIN_DIR}/../data/skimmer/Feb24/23_05_12_multiclass_rem_feats_3/inferences/\"\n",
    "# samples_dir = \"/eos/uscms/store/user/rkansal/bbVV/skimmer/Feb24/\"\n",
    "# signal_samples_dir = \"/eos/uscms/store/user/cmantill/bbVV/skimmer/Jun10/\"\n",
    "# bdt_data_dir = \"/eos/uscms/store/user/cmantill/bbVV/skimmer/Jun10/bdt_data/\"\n",
    "year = \"2018\"\n",
    "\n",
    "date = \"23Aug21\"\n",
    "plot_dir = f\"../../../plots/PostProcessing/{date}/\"\n",
    "templates_dir = f\"templates/{date}\"\n",
    "_ = os.system(f\"mkdir -p {plot_dir}\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/cutflows/\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/ControlPlots/{year}/\")\n",
    "# _ = os.system(f\"mkdir -p {plot_dir}/templates/\")\n",
    "# _ = os.system(f\"mkdir -p {plot_dir}/templates/wshifts\")\n",
    "# _ = os.system(f\"mkdir -p {plot_dir}/templates/jshifts\")\n",
    "# _ = os.system(f\"mkdir -p {templates_dir}\")\n",
    "\n",
    "selection_regions = postprocessing.get_nonres_selection_regions(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{bdt_preds_dir}/{year}/sample_order.txt\", \"r\") as f:\n",
    "    BDT_sample_order = list(eval(f.read()).keys())\n",
    "\n",
    "for key in nonres_sig_keys.copy():\n",
    "    if key not in BDT_sample_order:\n",
    "        del nonres_samples[key]\n",
    "        nonres_sig_keys.remove(key)\n",
    "\n",
    "for key in bg_keys.copy():\n",
    "    if key not in BDT_sample_order:\n",
    "        del samples[key]\n",
    "        bg_keys.remove(key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = postprocessing.new_filters\n",
    "systematics = {year: {}}\n",
    "\n",
    "# save cutflow as pandas table\n",
    "cutflow = pd.DataFrame(index=list(samples.keys()) + list(nonres_samples.keys()))\n",
    "\n",
    "# utils.remove_empty_parquets(samples_dir, year)\n",
    "\n",
    "# no HEM cleaning for now because it wasn't done for BDT samples\n",
    "events_dict = utils.load_samples(\n",
    "    signal_samples_dir, nonres_samples, year, filters, hem_cleaning=False\n",
    ")\n",
    "events_dict |= utils.load_samples(samples_dir, samples, year, filters, hem_cleaning=False)\n",
    "\n",
    "utils.add_to_cutflow(events_dict, \"BDTPreselection\", \"weight\", cutflow)\n",
    "\n",
    "print(\"\")\n",
    "# print weighted sample yields\n",
    "for sample in events_dict:\n",
    "    tot_weight = np.sum(events_dict[sample][\"weight\"].values)\n",
    "    print(f\"Pre-selection {sample} yield: {tot_weight:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale factors and bb VV assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessing.apply_weights(events_dict, year, cutflow)\n",
    "bb_masks = postprocessing.bb_VV_assignment(events_dict)\n",
    "# events_dict[sig_key] = postprocessing.postprocess_lpsfs(events_dict[sig_key])\n",
    "cutflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessing.load_bdt_preds(events_dict, year, bdt_preds_dir, jec_jmsr_shifts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {var: (bins, label)}\n",
    "control_plot_vars = {\n",
    "    # \"MET_pt\": ([50, 0, 300], r\"$p^{miss}_T$ (GeV)\"),\n",
    "    # \"DijetEta\": ([50, -8, 8], r\"$\\eta^{jj}$\"),\n",
    "    # \"DijetPt\": ([50, 0, 750], r\"$p_T^{jj}$ (GeV)\"),\n",
    "    # \"DijetMass\": (\n",
    "    #     # list(range(800, 1400, 100)) + [1400, 1600, 2000, 3000, 4400],\n",
    "    #     [40, 600, 4500],\n",
    "    #     r\"$m^{jj}$ (GeV)\",\n",
    "    # ),\n",
    "    # \"bbFatJetEta\": ([50, -2.4, 2.4], r\"$\\eta^{bb}$\"),\n",
    "    # \"bbFatJetPt\": ([50, 300, 1500], r\"$p^{bb}_T$ (GeV)\"),\n",
    "    # \"bbFatJetParticleNetMass\": ([20, 50, 250], r\"$m^{bb}_{reg}$ (GeV)\"),\n",
    "    # \"bbFatJetMsd\": ([50, 0, 300], r\"$m^{bb}_{msd}$ (GeV)\"),\n",
    "    # \"bbFatJetParticleNetMD_Txbb\": ([50, 0.8, 1], r\"$T^{bb}_{Xbb}$\"),\n",
    "    # \"VVFatJetEta\": ([50, -2.4, 2.4], r\"$\\eta^{VV}$\"),\n",
    "    # \"VVFatJetPt\": ([50, 300, 1500], r\"$p^{VV}_T$ (GeV)\"),\n",
    "    # \"VVFatJetParticleNetMass\": (\n",
    "    #     # list(range(50, 110, 10)) + list(range(110, 200, 15)) + [200, 220, 250],\n",
    "    #     [20, 50, 250],\n",
    "    #     r\"$m^{VV}_{reg}$ (GeV)\",\n",
    "    # ),\n",
    "    # \"VVFatJetMsd\": ([40, 50, 250], r\"$m^{VV}_{msd}$ (GeV)\"),\n",
    "    # \"VVFatJetParticleNet_Th4q\": ([50, 0, 1], r\"Prob($H \\to 4q$) vs Prob(QCD) (Non-MD)\"),\n",
    "    # \"VVFatJetParTMD_THWW4q\": (\n",
    "    #     [50, 0, 1],\n",
    "    #     r\"Prob($H \\to VV \\to 4q$) vs Prob(QCD) (Mass-Decorrelated)\",\n",
    "    # ),\n",
    "    # \"VVFatJetParTMD_probT\": ([50, 0, 1], r\"Prob(Top) (Mass-Decorrelated)\"),\n",
    "    # \"VVFatJetParTMD_THWWvsT\": (\n",
    "    #     [50, 0, 1],\n",
    "    #     r\"$T^{VV}_{HWW}$\",\n",
    "    # ),\n",
    "    # \"bbFatJetPtOverDijetPt\": ([50, 0, 40], r\"$p^{bb}_T / p_T^{jj}$\"),\n",
    "    # \"VVFatJetPtOverDijetPt\": ([50, 0, 40], r\"$p^{VV}_T / p_T^{jj}$\"),\n",
    "    # \"VVFatJetPtOverbbFatJetPt\": ([50, 0.4, 2.0], r\"$p^{VV}_T / p^{bb}_T$\"),\n",
    "    # \"nGoodMuons\": ([3, 0, 3], r\"# of Muons\"),\n",
    "    # \"nGoodElectrons\": ([3, 0, 3], r\"# of Electrons\"),\n",
    "    # \"nGoodJets\": ([5, 0, 5], r\"# of AK4 B-Jets\"),\n",
    "    \"BDTScore\": ([50, 0, 1], r\"BDT Score\"),\n",
    "}\n",
    "\n",
    "hists = postprocessing.control_plots(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    [\"HHbbVV\", \"qqHH_CV_1_C2V_1_kl_1_HHbbVV\"],\n",
    "    control_plot_vars,\n",
    "    f\"{plot_dir}/ControlPlots/{year}/\",\n",
    "    year,\n",
    "    bg_keys=[\"QCD\", \"TT\", \"ST\", \"V+Jets\", \"Diboson\"],\n",
    "    # bg_keys=[\"QCD\", \"TT\", \"ST\", \"V+Jets\", \"Hbb\"],\n",
    "    sig_scale_dict={\"HHbbVV\": 2e5, \"qqHH_CV_1_C2V_1_kl_1_HHbbVV\": 2e6},\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts = [0.01, 0.1, 0.5, 0.9, 0.99]\n",
    "# bdtvars = [\"\", \"TT\", \"VJets\"]\n",
    "bdtvars = [\"\"]\n",
    "sig_scales = [1e5, 5e4, 2e4, 1e4, 2e3]\n",
    "\n",
    "# for ttcut in [0.01, 0.1, 0.5, 0.9, 0.99]:\n",
    "#     ttsel, _ = utils.make_selection({\"BDTScoreTT\": [ttcut, CUT_MAX_VAL]}, events_dict, bb_masks)\n",
    "#     cutstr = f\"tt{ttcut}\"\n",
    "\n",
    "#     hists = postprocessing.control_plots(\n",
    "#         events_dict,\n",
    "#         bb_masks,\n",
    "#         nonres_sig_keys,\n",
    "#         control_plot_vars,\n",
    "#         f\"{plot_dir}/ControlPlots/{year}/\",\n",
    "#         year,\n",
    "#         hists={},\n",
    "#         bg_keys=[\"QCD\", \"TT\", \"ST\", \"V+Jets\", \"Diboson\"],\n",
    "#         selection=ttsel,\n",
    "#         cutstr=cutstr,\n",
    "#         show=True,\n",
    "#     )\n",
    "\n",
    "for var in bdtvars:\n",
    "    for i, cut in enumerate(cuts):\n",
    "        sel, _ = utils.make_selection({f\"BDTScore{var}\": [cut, CUT_MAX_VAL]}, events_dict, bb_masks)\n",
    "        cutstr = f\"bdt{var}{cut}\"\n",
    "        sig_scale = sig_scales[i]\n",
    "\n",
    "        hists = postprocessing.control_plots(\n",
    "            events_dict,\n",
    "            bb_masks,\n",
    "            nonres_sig_keys,\n",
    "            control_plot_vars,\n",
    "            f\"{plot_dir}/ControlPlots/{year}/\",\n",
    "            year,\n",
    "            hists={},\n",
    "            bg_keys=[\"QCD\", \"TT\", \"ST\", \"V+Jets\", \"Diboson\"],\n",
    "            selection=sel,\n",
    "            cutstr=cutstr,\n",
    "            sig_scale_dict={\"HHbbVV\": sig_scale},\n",
    "            combine_pdf=False,\n",
    "            show=True,\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall BDT SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonres_sig_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessing.lpsfs(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    nonres_sig_keys,\n",
    "    nonres_samples,\n",
    "    cutflow,\n",
    "    selection_regions[\"lpsf\"],\n",
    "    systematics,\n",
    "    all_years=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = events_dict[\"HHbbVV\"]\n",
    "bb_mask = bb_masks[\"HHbbVV\"]\n",
    "weight = events[\"finalWeight\"].values.squeeze()\n",
    "weight_lp = weight * events[\"VV_lp_sf_nom\"].values.squeeze()\n",
    "weight_lp_sys_up = weight * events[\"VV_lp_sf_sys_up\"].values.squeeze()\n",
    "weight_lp_sys_down = weight * events[\"VV_lp_sf_sys_down\"].values.squeeze()\n",
    "\n",
    "plt.hist(\n",
    "    utils.get_feat(events, \"bbFatJetPt\", bb_mask),\n",
    "    np.linspace(250, 1200, 31),\n",
    "    weights=weight,\n",
    "    histtype=\"step\",\n",
    "    label=\"Pre-LP\",\n",
    ")\n",
    "plt.hist(\n",
    "    utils.get_feat(events, \"bbFatJetPt\", bb_mask),\n",
    "    np.linspace(250, 1200, 31),\n",
    "    weights=weight_lp,\n",
    "    histtype=\"step\",\n",
    "    label=\"Post-LP\",\n",
    ")\n",
    "plt.title(\"2018 HHbbVV\")\n",
    "plt.xlabel(r\"$p_T^{VV}$ (GeV)\")\n",
    "plt.ylabel(\"Events\")\n",
    "# plt.hist(utils.get_feat(events, \"VVFatJetPt\", bb_mask), np.linspace(250, 2000, 31), weights=weight_lp_sys_up, histtype=\"step\", label=\"Post-LP Sys Up\")\n",
    "# plt.hist(utils.get_feat(events, \"VVFatJetPt\", bb_mask), np.linspace(250, 2000, 31), weights=weight_lp_sys_down, histtype=\"step\", label=\"Post-LP Sys Down\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(events_dict[\"HHbbVV\"].columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, tsysts = postprocessing.get_templates(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    year,\n",
    "    nonres_sig_keys,\n",
    "    selection_regions,\n",
    "    nonres_shape_vars,\n",
    "    systematics,\n",
    "    bg_keys=bg_keys,\n",
    "    plot_dir=f\"{plot_dir}/templates\",\n",
    "    prev_cutflow=cutflow,\n",
    "    weight_shifts={},\n",
    "    jshift=\"\",\n",
    "    plot_shifts=False,\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {}\n",
    "\n",
    "for jshift in [\"\"] + jec_shifts + jmsr_shifts:\n",
    "    print(jshift)\n",
    "    ttemps, tsyst = postprocessing.get_templates(\n",
    "        events_dict,\n",
    "        bb_masks,\n",
    "        year,\n",
    "        selection_regions[year],\n",
    "        shape_var,\n",
    "        shape_bins,\n",
    "        blind_window,\n",
    "        plot_dir=plot_dir,\n",
    "        prev_cutflow=cutflow,\n",
    "        weight_shifts=postprocessing.weight_shifts,\n",
    "        jshift=jshift,\n",
    "        show=False,\n",
    "    )\n",
    "\n",
    "    templates = {**templates, **ttemps}\n",
    "    systematics = {**systematics, **tsyst}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_dict = {}\n",
    "\n",
    "for year in years:\n",
    "    with open(f\"templates/Feb28/{year}_templates.pkl\", \"rb\") as f:\n",
    "        templates_dict[year] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15adc7883e707560d0d9727709639b8fe3f3cff1f197d2d643742923ff23a29c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
