{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import plotting\n",
    "import postprocessing\n",
    "import corrections\n",
    "\n",
    "from utils import CUT_MAX_VAL\n",
    "from hh_vars import (\n",
    "    years,\n",
    "    data_key,\n",
    "    qcd_key,\n",
    "    bg_keys,\n",
    "    samples,\n",
    "    nonres_sig_keys,\n",
    "    # res_samples,\n",
    "    # res_sig_keys,\n",
    "    nonres_samples,\n",
    "    txbb_wps,\n",
    "    jec_shifts,\n",
    "    jmsr_shifts,\n",
    "    LUMI,\n",
    ")\n",
    "from postprocessing import res_shape_vars, new_filters, old_filters\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle, json\n",
    "import hist\n",
    "from hist import Hist\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from inspect import cleandoc\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_samples = OrderedDict()\n",
    "\n",
    "res_mps = [(900, 80), (1200, 190), (2000, 125), (3000, 250), (4000, 150)]\n",
    "\n",
    "for mX, mY in res_mps:\n",
    "    res_samples[f\"X[{mX}]->H(bb)Y[{mY}](VV)\"] = f\"NMSSM_XToYHTo2W2BTo4Q2B_MX-{mX}_MY-{mY}\"\n",
    "\n",
    "res_sig_keys = list(res_samples.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del nonres_samples[\"VBFHHbbVV\"]\n",
    "nonres_sig_keys = [\"HHbbVV\", \"VBFHHbbVV\"]\n",
    "nonres_samples = {key: nonres_samples[key] for key in nonres_sig_keys}\n",
    "\n",
    "bg_keys = [\"QCD\", \"TT\", \"ST\", \"V+Jets\", \"Diboson\"]\n",
    "samples = {key: samples[key] for key in [\"Data\"] + bg_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = \"../../../\"\n",
    "samples_dir = f\"{MAIN_DIR}/../data/skimmer/Feb24\"\n",
    "nonres_signal_samples_dir = f\"{MAIN_DIR}/../data/skimmer/Jun10\"\n",
    "res_signal_samples_dir = f\"{MAIN_DIR}/../data/skimmer/23Aug22_5xhy\"\n",
    "# samples_dir = \"/eos/uscms/store/user/rkansal/bbVV/skimmer/Feb24\"\n",
    "# nonres_signal_samples_dir = \"/eos/uscms/store/user/cmantill/bbVV/skimmer/Jun10/\"\n",
    "# res_signal_samples_dir = \"/eos/uscms/store/user/rkansal/bbVV/skimmer/Apr11/\"\n",
    "year = \"2018\"\n",
    "\n",
    "date = \"23Aug23\"\n",
    "plot_dir = f\"../../../plots/PostProcessing/{date}/\"\n",
    "templates_dir = f\"templates/{date}/\"\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/ControlPlots/{year}\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/cutflows\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/templates/wshifts\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/templates/jshifts\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/templates/hists2d\")\n",
    "_ = os.system(f\"mkdir -p {templates_dir}\")\n",
    "\n",
    "selection_regions = postprocessing.get_res_selection_regions(year)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 1430 events\n",
      "Loaded NMSSM_XToYHTo2W2BTo4Q2B_MX-900_MY-80              : 144441 entries\n",
      "Removing 1873 events\n",
      "Loaded NMSSM_XToYHTo2W2BTo4Q2B_MX-1200_MY-190            : 210988 entries\n",
      "Removing 2717 events\n",
      "Loaded NMSSM_XToYHTo2W2BTo4Q2B_MX-2000_MY-125            : 292440 entries\n",
      "Removing 2795 events\n",
      "Loaded NMSSM_XToYHTo2W2BTo4Q2B_MX-3000_MY-250            : 321055 entries\n",
      "Removing 2673 events\n",
      "Loaded NMSSM_XToYHTo2W2BTo4Q2B_MX-4000_MY-150            : 327318 entries\n",
      "Removing 2014 events\n",
      "Loaded GluGluToHHTobbVV_node_cHHH1                       : 188941 entries\n",
      "Removing 277 events\n",
      "Loaded VBF_HHTobbVV_CV_1_C2V_1_C3_1                      : 17539 entries\n",
      "Loaded JetHT_Run2018A                                    : 376541 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghav/Documents/CERN/hhbbww/HHbbVV/src/HHbbVV/postprocessing/utils.py:151: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead.\n",
      "  hem_cut = np.any((events[\"ak8FatJetEta\"] > -3.2) * (events[\"ak8FatJetEta\"] <-1.3) * (events[\"ak8FatJetPhi\"] > -1.57) * (events[\"ak8FatJetPhi\"] <-0.87 ), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 13922 events\n",
      "Loaded JetHT_Run2018D                                    : 833289 entries\n",
      "Removing 2895 events\n",
      "Loaded JetHT_Run2018C                                    : 171794 entries\n",
      "Loaded JetHT_Run2018B                                    : 175146 entries\n",
      "Removing 0 events\n",
      "Loaded QCD_HT300to500                                    : 23 entries\n",
      "Removing 0 events\n",
      "Loaded QCD_HT200to300                                    : 0 entries\n",
      "Removing 3351 events\n",
      "Loaded QCD_HT700to1000                                   : 197372 entries\n",
      "Removing 1762 events\n",
      "Loaded QCD_HT1000to1500                                  : 122855 entries\n",
      "Removing 455 events\n",
      "Loaded QCD_HT2000toInf                                   : 73168 entries\n",
      "Removing 1390 events\n",
      "Loaded QCD_HT1500to2000                                  : 134020 entries\n",
      "Removing 340 events\n",
      "Loaded QCD_HT500to700                                    : 18460 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghav/Documents/CERN/hhbbww/HHbbVV/src/HHbbVV/postprocessing/utils.py:163: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 7609 events\n",
      "Loaded TTToSemiLeptonic                                  : 557747 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghav/Documents/CERN/hhbbww/HHbbVV/src/HHbbVV/postprocessing/utils.py:163: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 10387 events\n",
      "Loaded TTToHadronic                                      : 749409 entries\n",
      "Removing 290 events\n",
      "Loaded ST_tW_top_5f_inclusiveDecays                      : 26038 entries\n",
      "Removing 197 events\n",
      "Loaded ST_tW_antitop_5f_inclusiveDecays                  : 19168 entries\n",
      "Removing 277 events\n",
      "Loaded ST_s-channel_4f_leptonDecays                      : 19853 entries\n",
      "Removing 643 events\n",
      "Loaded ST_t-channel_antitop_4f_InclusiveDecays           : 42693 entries\n",
      "Removing 0 events\n",
      "Loaded WJetsToQQ_HT-200to400                             : 0 entries\n",
      "Removing 0 events\n",
      "Loaded ZJetsToQQ_HT-200to400                             : 0 entries\n",
      "Removing 21 events\n",
      "Loaded ZJetsToQQ_HT-400to600                             : 685 entries\n",
      "Removing 2276 events\n",
      "Loaded WJetsToQQ_HT-800toInf                             : 133078 entries\n",
      "Removing 1559 events\n",
      "Loaded ZJetsToQQ_HT-600to800                             : 75028 entries\n",
      "Removing 563 events\n",
      "Loaded WJetsToQQ_HT-600to800                             : 25485 entries\n",
      "Removing 4971 events\n",
      "Loaded ZJetsToQQ_HT-800toInf                             : 294481 entries\n",
      "Removing 6 events\n",
      "Loaded WJetsToQQ_HT-400to600                             : 213 entries\n",
      "Removing 13 events\n",
      "Loaded WW                                                : 583 entries\n",
      "Removing 17 events\n",
      "Loaded ZZ                                                : 949 entries\n",
      "Removing 42 events\n",
      "Loaded WZ                                                : 2247 entries\n",
      "\n",
      "Pre-selection X[900]->H(bb)Y[80](VV) yield: 21.71\n",
      "Pre-selection X[1200]->H(bb)Y[190](VV) yield: 33.48\n",
      "Pre-selection X[2000]->H(bb)Y[125](VV) yield: 43.99\n",
      "Pre-selection X[3000]->H(bb)Y[250](VV) yield: 48.29\n",
      "Pre-selection X[4000]->H(bb)Y[150](VV) yield: 49.21\n",
      "Pre-selection HHbbVV yield: 4.17\n",
      "Pre-selection VBFHHbbVV yield: 0.08\n",
      "Pre-selection Data yield: 1556770.00\n",
      "Pre-selection QCD yield: 3003204.29\n",
      "Pre-selection TT yield: 214598.05\n",
      "Pre-selection ST yield: 15007.66\n",
      "Pre-selection V+Jets yield: 84306.66\n",
      "Pre-selection Diboson yield: 1339.33\n"
     ]
    }
   ],
   "source": [
    "systematics = {year: {}}\n",
    "\n",
    "# save cutflow as pandas table\n",
    "cutflow = pd.DataFrame(index=list(samples.keys()) + list(res_samples.keys()))\n",
    "\n",
    "# utils.remove_empty_parquets(samples_dir, year)\n",
    "events_dict = utils.load_samples(res_signal_samples_dir, res_samples, year, new_filters)\n",
    "events_dict |= utils.load_samples(nonres_signal_samples_dir, nonres_samples, year, new_filters)\n",
    "events_dict |= utils.load_samples(samples_dir, samples, year, new_filters)\n",
    "\n",
    "utils.add_to_cutflow(events_dict, \"Preselection\", \"weight\", cutflow)\n",
    "\n",
    "print(\"\")\n",
    "# print weighted sample yields\n",
    "for sample in events_dict:\n",
    "    tot_weight = np.sum(events_dict[sample][\"weight\"].values)\n",
    "    print(f\"Pre-selection {sample} yield: {tot_weight:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higgs_samples = OrderedDict(\n",
    "    [\n",
    "        (\"Hbb\", \"*HToBB\"),\n",
    "        # (\"HWW\", (\"*HToWW\", \"*HToNonbb\")),\n",
    "        # (\"HH\", (\"VBF_HHTobbVV_CV_1_C2V_1_C3_1\", \"GluGluToHHTo4B_node_cHHH1_preUL\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "events_dict |= utils.load_samples(samples_dir, higgs_samples, year, filters)\n",
    "\n",
    "cutflow = pd.DataFrame(\n",
    "    index=list(samples.keys()) + list(res_samples.keys()) + list(higgs_samples.keys())\n",
    ")\n",
    "utils.add_to_cutflow(events_dict, \"Preselection\", \"weight\", cutflow)\n",
    "\n",
    "print(\"\")\n",
    "# print weighted sample yields\n",
    "for sample in events_dict:\n",
    "    tot_weight = np.sum(events_dict[sample][\"weight\"].values)\n",
    "    print(f\"Pre-selection {sample} yield: {tot_weight:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale factors and bb VV assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessing.apply_weights(events_dict, year, cutflow)\n",
    "bb_masks = postprocessing.bb_VV_assignment(events_dict)\n",
    "# postprocessing.derive_variables(events_dict)\n",
    "cutflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = list(events_dict.keys())\n",
    "weight_key = \"finalWeight\"\n",
    "\n",
    "control_plot_2d_vars = [\n",
    "    {\n",
    "        f\"{jet}FatJetPhi\": ([40, -3.5, 3.5], rf\"$\\varphi^{{{jet}}}$\"),\n",
    "        f\"{jet}FatJetEta\": ([40, -3, 3], rf\"$\\eta^{{{jet}}}$\"),\n",
    "    }\n",
    "    for jet in [\"bb\", \"VV\"]\n",
    "]\n",
    "\n",
    "hists2d = []\n",
    "\n",
    "for vars2d in control_plot_2d_vars:\n",
    "    h = Hist(\n",
    "        hist.axis.StrCategory(samples, name=\"Sample\"),\n",
    "        *[hist.axis.Regular(*bins, name=var, label=label) for var, (bins, label) in vars2d.items()],\n",
    "        storage=hist.storage.Weight(),\n",
    "    )\n",
    "\n",
    "    for sample in samples:\n",
    "        events = events_dict[sample]\n",
    "\n",
    "        fill_data = {var: utils.get_feat(events, var, bb_masks[sample]) for var in vars2d}\n",
    "        weight = events[weight_key].values.squeeze()\n",
    "\n",
    "        # if selection is not None:\n",
    "        #     sel = selection[sample]\n",
    "        #     fill_data[var] = fill_data[var][sel]\n",
    "        #     weight = weight[sel]\n",
    "\n",
    "        if len(weight):\n",
    "            h.fill(Sample=sample, **fill_data, weight=weight)\n",
    "\n",
    "    hists2d.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "\n",
    "plot_keys = [\"Data\", \"QCD\", \"TT\", \"HHbbVV\", \"X[3000]->H(bb)Y[250](VV)\"]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    len(plot_keys),\n",
    "    2,\n",
    "    figsize=(20, 8 * len(plot_keys)),\n",
    "    gridspec_kw={\"wspace\": 0.25, \"hspace\": 0.25},\n",
    ")\n",
    "\n",
    "for j, key in enumerate(plot_keys):\n",
    "    for i in range(2):\n",
    "        ax = axs[j][i]\n",
    "        hep.hist2dplot(hists2d[i][key, ...], cmap=\"turbo\", ax=ax)\n",
    "        hep.cms.label(\n",
    "            \"Work in Progress\", data=True, lumi=round(LUMI[year] * 1e-3), year=year, ax=ax\n",
    "        )\n",
    "        ax.set_title(key, y=1.07)\n",
    "        ax._children[0].colorbar.set_label(\"Events\")\n",
    "\n",
    "plt.savefig(f\"{plot_dir}/ControlPlots/{year}/HEM2d.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {var: (bins, label)}\n",
    "control_plot_vars = {\n",
    "    \"MET_pt\": ([40, 0, 320], r\"$p^{miss}_T$ (GeV)\"),\n",
    "    # \"DijetEta\": ([50, -8, 8], r\"$\\eta^{jj}$\"),\n",
    "    # \"DijetPt\": ([50, 0, 750], r\"$p_T^{jj}$ (GeV)\"),\n",
    "    # \"DijetMass\": ([50, 500, 3000], r\"$m^{jj}$ (GeV)\"),\n",
    "    \"bbFatJetPhi\": ([40, -3.5, 3.5], r\"$\\varphi^{bb}$\"),\n",
    "    \"bbFatJetEta\": ([40, -3, 3], r\"$\\eta^{bb}$\"),\n",
    "    \"bbFatJetPt\": ([40, 300, 2300], r\"$p^{bb}_T$ (GeV)\"),  # TODO: increase bin widths, x max\n",
    "    # \"bbFatJetParticleNetMass\": ([50, 0, 300], r\"$m^{bb}_{reg}$ (GeV)\"),\n",
    "    # \"bbFatJetMsd\": ([50, 0, 300], r\"$m^{bb}_{msd}$ (GeV)\"),\n",
    "    # \"bbFatJetParticleNetMD_Txbb\": ([50, 0.8, 1], r\"$p^{bb}_{Txbb}$\"),\n",
    "    \"VVFatJetPhi\": ([40, -3.5, 3.5], r\"$\\varphi^{VV}$\"),\n",
    "    \"VVFatJetEta\": ([40, -3, 3], r\"$\\eta^{VV}$\"),\n",
    "    \"VVFatJetPt\": ([40, 300, 2300], r\"$p^{VV}_T$ (GeV)\"),\n",
    "    # \"VVFatJetParticleNetMass\": ([50, 0, 300], r\"$m^{VV}_{reg}$ (GeV)\"),\n",
    "    # \"VVFatJetMsd\": ([50, 0, 300], r\"$m^{VV}_{msd}$ (GeV)\"),\n",
    "    # \"VVFatJetParticleNet_Th4q\": ([50, 0, 1], r\"Prob($H \\to 4q$) vs Prob(QCD) (Non-MD)\"),\n",
    "    # \"VVFatJetParTMD_THWW4q\": (\n",
    "    #     [50, 0, 1],\n",
    "    #     r\"Prob($H \\to VV \\to 4q$) vs Prob(QCD) (Mass-Decorrelated)\",\n",
    "    # ),\n",
    "    # \"VVFatJetParTMD_probT\": ([50, 0, 1], r\"Prob(Top) (Mass-Decorrelated)\"),\n",
    "    # \"bbFatJetPtOverDijetPt\": ([50, 0, 40], r\"$p^{bb}_T / p_T^{jj}$\"),\n",
    "    # \"VVFatJetPtOverDijetPt\": ([50, 0, 40], r\"$p^{VV}_T / p_T^{jj}$\"),\n",
    "    # \"VVFatJetPtOverbbFatJetPt\": ([50, 0.4, 2.0], r\"$p^{VV}_T / p^{bb}_T$\"),\n",
    "    # \"nGoodMuons\": ([3, 0, 3], r\"# of Muons\"),\n",
    "    # \"nGoodElectrons\": ([3, 0, 3], r\"# of Electrons\"),\n",
    "    # \"nGoodJets\": ([5, 0, 5], r\"# of AK4 B-Jets\"),\n",
    "    # \"BDTScore\": ([50, 0, 1], r\"BDT Score\"),\n",
    "}\n",
    "\n",
    "hists = postprocessing.control_plots(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    nonres_sig_keys + res_sig_keys,\n",
    "    control_plot_vars,\n",
    "    f\"{plot_dir}/ControlPlots/{year}/\",\n",
    "    year,\n",
    "    bg_keys=bg_keys,\n",
    "    sig_scale_dict={\"HHbbVV\": 1e5, \"VBFHHbbVV\": 2e6} | {key: 2e4 for key in res_sig_keys},\n",
    "    # bg_keys=[\"QCD\", \"TT\", \"ST\", \"V+Jets\", \"Hbb\"],\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection, _ = utils.make_selection(\n",
    "    {\n",
    "        \"VVFatJetParTMD_THWWvsT\": [0.8, CUT_MAX_VAL],\n",
    "        \"bbFatJetParticleNetMD_Txbb\": [0.98, CUT_MAX_VAL],\n",
    "        \"bbFatJetParticleNetMass\": [110, 145],\n",
    "    },\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    ")\n",
    "cutstr = f\"pass_noveto\"\n",
    "\n",
    "postprocessing.control_plots(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    nonres_sig_keys + res_sig_keys,\n",
    "    control_plot_vars,\n",
    "    f\"{plot_dir}/ControlPlots/{year}/\",\n",
    "    year,\n",
    "    sig_splits=sig_splits[:1],\n",
    "    hists={},\n",
    "    # bg_keys=bg_keys + list(higgs_samples.keys()),\n",
    "    # bg_keys=[\"QCD\", \"TT\", \"ST\", \"V+Jets\", \"Hbb\"],\n",
    "    bg_keys=[\"QCD\", \"TT\", \"ST\", \"V+Jets\"],\n",
    "    sig_scale_dict={key: 10 for key in nonres_sig_keys + res_sig_keys},\n",
    "    selection=selection,\n",
    "    cutstr=cutstr,\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sb1, sb2 in [[0, 300], [75, 180], [92.5, 162.5]]:\n",
    "    selection, _ = utils.make_selection(\n",
    "        {\n",
    "            \"VVFatJetParTMD_THWWvsT\": [0.8, CUT_MAX_VAL],\n",
    "            \"bbFatJetParticleNetMD_Txbb\": [0.98, CUT_MAX_VAL],\n",
    "            \"bbFatJetParticleNetMass\": [[sb1, 110], [145, sb2]],\n",
    "        },\n",
    "        events_dict,\n",
    "        bb_masks,\n",
    "    )\n",
    "    cutstr = f\"sidebands_{sb1}_{sb2}\"\n",
    "\n",
    "    postprocessing.control_plots(\n",
    "        events_dict,\n",
    "        bb_masks,\n",
    "        nonres_sig_keys + res_sig_keys,\n",
    "        control_plot_vars,\n",
    "        f\"{plot_dir}/ControlPlots/{year}/\",\n",
    "        year,\n",
    "        sig_splits=sig_splits,\n",
    "        hists={},\n",
    "        # bg_keys=bg_keys + list(higgs_samples.keys()),\n",
    "        bg_keys=[\"QCD\", \"TT\", \"ST\", \"V+Jets\", \"Hbb\"],\n",
    "        selection=selection,\n",
    "        cutstr=cutstr,\n",
    "        show=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall LP SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "sel, cf = utils.make_selection(\n",
    "    selection_regions[\"lpsf\"].cuts, events_dict, bb_masks, prev_cutflow=cutflow\n",
    ")\n",
    "\n",
    "sf_table = OrderedDict()\n",
    "\n",
    "for sig_key in tqdm(res_sig_keys):\n",
    "    systematics[sig_key] = {}\n",
    "    # calculate only for current year\n",
    "    events_dict[sig_key] = postprocessing.postprocess_lpsfs(events_dict[sig_key])\n",
    "    lp_sf, unc, uncs = postprocessing.get_lpsf(events_dict[sig_key], sel[sig_key])\n",
    "    # print(f\"BDT LP Scale Factor for {sig_key}: {lp_sf:.2f} ± {unc:.2f}\")\n",
    "    # print(uncs)\n",
    "\n",
    "    systematics[sig_key][\"lp_sf\"] = lp_sf\n",
    "    systematics[sig_key][\"lp_sf_unc\"] = unc / lp_sf\n",
    "\n",
    "    sf_table[sig_key] = {\"SF\": f\"{lp_sf:.2f} ± {unc:.2f}\", **uncs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_df = pd.DataFrame(index=nonres_sig_keys + res_sig_keys)\n",
    "\n",
    "for key in sf_table[sig_key]:\n",
    "    sf_df[key] = [sf_table[skey][key] for skey in nonres_sig_keys + res_sig_keys]\n",
    "\n",
    "sf_df.to_clipboard()\n",
    "sf_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_regions = postprocessing.get_res_selection_regions(\"2017\", txbb_wp=\"HP\", thww_wp=0.8)\n",
    "del selection_regions[\"fail\"], selection_regions[\"failBlinded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = postprocessing.get_templates(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    year,\n",
    "    # nonres_sig_keys + res_sig_keys[:10],\n",
    "    res_sig_keys,\n",
    "    selection_regions,\n",
    "    res_shape_vars[:1],\n",
    "    systematics,\n",
    "    templates_dir,\n",
    "    bg_keys=[\"QCD\", \"TT\", \"V+Jets\", \"Diboson\", \"Hbb\"],\n",
    "    plot_dir=f\"{plot_dir}/templates/\",\n",
    "    prev_cutflow=cutflow,\n",
    "    # sig_splits=sig_splits[:2],\n",
    "    weight_shifts={},\n",
    "    jshift=\"\",\n",
    "    plot_shifts=False,\n",
    "    pass_ylim=70,\n",
    "    fail_ylim=40000,\n",
    "    blind_pass=True,\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_templates(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    args.year,\n",
    "    sig_keys,\n",
    "    selection_regions,\n",
    "    shape_vars,\n",
    "    systematics,\n",
    "    template_dir,\n",
    "    bg_keys=bg_keys,\n",
    "    plot_dir=plot_dir,\n",
    "    prev_cutflow=cutflow,\n",
    "    # sig_splits=sig_splits,\n",
    "    weight_shifts=weight_shifts,\n",
    "    jshift=jshift,\n",
    "    blind_pass=True if args.resonant else False,\n",
    "    show=False,\n",
    "    plot_shifts=args.plot_shifts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {}\n",
    "\n",
    "for jshift in [\"\"] + jec_shifts + jmsr_shifts:\n",
    "    print(jshift)\n",
    "    ttemps, tsyst = postprocessing.get_templates(\n",
    "        events_dict,\n",
    "        bb_masks,\n",
    "        year,\n",
    "        nonres_sig_keys + res_sig_keys,\n",
    "        res_selection_regions[year],\n",
    "        res_shape_vars,\n",
    "        bg_keys=[\"QCD\", \"TT\", \"V+Jets\"],\n",
    "        plot_dir=plot_dir if jshift == \"\" else \"\",\n",
    "        prev_cutflow=cutflow,\n",
    "        sig_splits=sig_splits,\n",
    "        weight_shifts=postprocessing.weight_shifts,\n",
    "        jshift=jshift,\n",
    "        pass_ylim=7,\n",
    "        fail_ylim=40000,\n",
    "        blind_pass=True,\n",
    "        show=False,\n",
    "        plot_shifts=False,\n",
    "    )\n",
    "\n",
    "    templates = {**templates, **ttemps}\n",
    "    if jshift == \"\":\n",
    "        systematics[year] = tsyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{templates_dir}/{year}_templates.pkl\", \"wb\") as f:\n",
    "    pickle.dump(templates, f)\n",
    "\n",
    "with open(f\"{templates_dir}/systematics.json\", \"w\") as f:\n",
    "    json.dump(systematics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"templates/Apr10//2017_templates.pkl\", \"rb\") as f:\n",
    "    templates = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(templates[\"pass\"].axes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.hist2ds(\n",
    "    templates,\n",
    "    f\"{plot_dir}/templates/hists2d/\",\n",
    "    regions=[\"pass\", \"fail\", \"passBlinded\", \"failBlinded\"],\n",
    "    region_labels=selection_regions_label,\n",
    "    samples=[\"Data\", \"TT\", \"V+Jets\", \"X[3000]->H(bb)Y[190](VV)\"],\n",
    "    # fail_zlim=5e3,\n",
    "    # pass_zlim=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_dict = {}\n",
    "\n",
    "for year in years:\n",
    "    with open(f\"templates/{date}/{year}_templates.pkl\", \"rb\") as f:\n",
    "        templates_dict[year] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = []\n",
    "for year in years:\n",
    "    with open(f\"templates/Apr7//{year}_templates.pkl\", \"rb\") as f:\n",
    "        templates.append(pickle.load(f))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15adc7883e707560d0d9727709639b8fe3f3cff1f197d2d643742923ff23a29c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
