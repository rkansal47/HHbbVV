{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import plotting\n",
    "import postprocessing\n",
    "import corrections\n",
    "from collections import OrderedDict\n",
    "\n",
    "from utils import CUT_MAX_VAL, ShapeVar\n",
    "from hh_vars import (\n",
    "    years,\n",
    "    data_key,\n",
    "    qcd_key,\n",
    "    bg_keys,\n",
    "    samples,\n",
    "    nonres_sig_keys,\n",
    "    nonres_samples,\n",
    "    txbb_wps,\n",
    "    jec_shifts,\n",
    "    jmsr_shifts,\n",
    ")\n",
    "from postprocessing import nonres_shape_vars, Region\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# from pandas.errors import SettingWithCopyWarning\n",
    "from hist import Hist\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from inspect import cleandoc\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "hep.style.use(\"CMS\")\n",
    "formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_powerlimits((-3, 3))\n",
    "plt.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "# ignore these because they don't seem to apply\n",
    "# warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = \"../../../\"\n",
    "samples_dir = f\"{MAIN_DIR}/../data/skimmer/anava/Test\"\n",
    "samples_dir = '/home/users/annava/projects/HHbbVV/src/HHbbVV/VBF_binder/data'\n",
    "# samples_dir = \"/eos/uscms/store/user/anava/bbVV/skimmer/Test/\"\n",
    "year = \"2017\"\n",
    "\n",
    "date = \"23Sep2\"\n",
    "plot_dir = f\"../../../plots/PostProcessing/{date}/\"\n",
    "plot_dir = '/home/users/annava/projects/HHbbVV/src/HHbbVV/VBF_binder/vbf_tests_output'\n",
    "templates_dir = f\"templates/{date}\"\n",
    "_ = os.system(f\"mkdir -p {plot_dir}\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/cutflows/\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/ControlPlots/{year}/\")\n",
    "_ = os.system(f\"mkdir -p {plot_dir}/templates/\")\n",
    "# _ = os.system(f\"mkdir -p {plot_dir}/templates/wshifts\")\n",
    "# _ = os.system(f\"mkdir -p {plot_dir}/templates/jshifts\")\n",
    "# _ = os.system(f\"mkdir -p {templates_dir}\")\n",
    "print(plot_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = postprocessing.new_filters\n",
    "systematics = {year: {}}\n",
    "\n",
    "# save cutflow as pandas table\n",
    "cutflow = pd.DataFrame(index=list(samples.keys()) + list(nonres_samples.keys()))\n",
    "\n",
    "# utils.remove_empty_parquets(samples_dir, year)\n",
    "events_dict = utils.load_samples(samples_dir, nonres_samples, year, filters)\n",
    "events_dict |= utils.load_samples(samples_dir, samples, year, filters)\n",
    "\n",
    "utils.add_to_cutflow(events_dict, \"Preselection\", \"weight\", cutflow)\n",
    "\n",
    "cutflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale factors and bb VV assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessing.apply_weights(events_dict, year, cutflow)\n",
    "bb_masks = postprocessing.bb_VV_assignment(events_dict)\n",
    "# events_dict[sig_key] = postprocessing.postprocess_lpsfs(events_dict[sig_key])\n",
    "cutflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {var: (bins, label)}\n",
    "control_plot_vars = [\n",
    "    # ShapeVar(var=\"MET_pt\", label=r\"$p^{miss}_T$ (GeV)\", bins=[50, 0, 300]),\n",
    "    # ShapeVar(var=\"DijetEta\", label=r\"$\\eta^{jj}$\", bins=[30, -8, 8]),\n",
    "    # ShapeVar(var=\"DijetPt\", label=r\"$p_T^{jj}$ (GeV)\", bins=[30, 0, 750]),\n",
    "    ShapeVar(var=\"DijetMass\", label=r\"$m^{jj}$ (GeV)\", bins=[30, 600, 4000]),\n",
    "    # ShapeVar(var=\"bbFatJetEta\", label=r\"$\\eta^{bb}$\", bins=[30, -2.4, 2.4]),\n",
    "    ShapeVar(var=\"bbFatJetPt\", label=r\"$p^{bb}_T$ (GeV)\", bins=[30, 300, 1500], significance_dir=\"right\"),\n",
    "    ShapeVar(var=\"bbFatJetParticleNetMass\", label=r\"$m^{bb}_{reg}$ (GeV)\", bins=[20, 50, 250], significance_dir=\"bin\"),\n",
    "    # ShapeVar(var=\"bbFatJetMsd\", label=r\"$m^{bb}_{msd}$ (GeV)\", bins=[50, 0, 300]),\n",
    "    # ShapeVar(var=\"bbFatJetParticleNetMD_Txbb\", label=r\"$T^{bb}_{Xbb}$\", bins=[50, 0.8, 1]),\n",
    "    # ShapeVar(var=\"VVFatJetEta\", label=r\"$\\eta^{VV}$\", bins=[30, -2.4, 2.4]),\n",
    "    # ShapeVar(var=\"VVFatJetPt\", label=r\"$p^{VV}_T$ (GeV)\", bins=[30, 300, 1500]),\n",
    "    # ShapeVar(var=\"VVParticleNetMass\", label=r\"$m^{VV}_{reg}$ (GeV)\", bins=[20, 50, 250]),\n",
    "    # ShapeVar(var=\"VVFatJetMsd\", label=r\"$m^{VV}_{msd}$ (GeV)\", bins=[40, 50, 250]),\n",
    "    # ShapeVar(var=\"VVFatJetParticleNet_Th4q\", label=r\"Prob($H \\to 4q$) vs Prob(QCD) (Non-MD)\", bins=[50, 0, 1]),\n",
    "    # ShapeVar(var=\"VVFatJetParTMD_THWW4q\", label=r\"Prob($H \\to VV \\to 4q$) vs Prob(QCD) (Mass-Decorrelated)\", bins=[50, 0, 1]),\n",
    "    # ShapeVar(var=\"VVFatJetParTMD_probT\", label=r\"Prob(Top) (Mass-Decorrelated)\", bins=[50, 0, 1]),\n",
    "    # ShapeVar(var=\"VVFatJetParTMD_THWWvsT\", label=r\"$T^{VV}_{HWW}$\", bins=[50, 0, 1]),\n",
    "    # ShapeVar(var=\"bbFatJetPtOverDijetPt\", label=r\"$p^{bb}_T / p_T^{jj}$\", bins=[50, 0, 40]),\n",
    "    # ShapeVar(var=\"VVFatJetPtOverDijetPt\", label=r\"$p^{VV}_T / p_T^{jj}$\", bins=[50, 0, 40]),\n",
    "    # ShapeVar(var=\"VVFatJetPtOverbbFatJetPt\", label=r\"$p^{VV}_T / p^{bb}_T$\", bins=[50, 0.4, 2.0]),\n",
    "    # ShapeVar(var=\"nGoodMuons\", label=r\"# of Muons\", bins=[3, 0, 3]),\n",
    "    # ShapeVar(var=\"nGoodElectrons\", label=r\"# of Electrons\", bins=[3, 0, 3]),\n",
    "    # ShapeVar(var=\"nGoodJets\", label=r\"# of AK4 B-Jets\", bins=[5, 0, 5]),\n",
    "    # ShapeVar(var=\"BDTScore\", label=r\"BDT Score\", bins=[50, 0, 1]),\n",
    "]\n",
    "\n",
    "hists = postprocessing.control_plots(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    [\"HHbbVV\", \"VBFHHbbVV\", \"qqHH_CV_1_C2V_0_kl_1_HHbbVV\", \"qqHH_CV_1_C2V_2_kl_1_HHbbVV\"],\n",
    "    control_plot_vars,\n",
    "    f\"{plot_dir}/ControlPlots/{year}/\",\n",
    "    year,\n",
    "    bg_keys=bg_keys,\n",
    "    # bg_keys=[\"QCD\", \"TT\", \"ST\", \"V+Jets\", \"Hbb\"],\n",
    "    sig_scale_dict={\n",
    "        \"HHbbVV\": 1e5,\n",
    "        \"VBFHHbbVV\": 2e5,\n",
    "        \"qqHH_CV_1_C2V_0_kl_1_HHbbVV\": 2e3,\n",
    "        \"qqHH_CV_1_C2V_2_kl_1_HHbbVV\": 2e3,\n",
    "    },\n",
    "    plot_significance=True,\n",
    "    show=True,\n",
    "    log=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add actual cuts here\n",
    "selection_regions = {\n",
    "    \"pass\": postprocessing.Region(\n",
    "        cuts={\n",
    "            \"bbFatJetParticleNetMD_Txbb\": [0.985, CUT_MAX_VAL],\n",
    "            ('nGoodVBFJets', 0): [2,40],\n",
    "            ('vbf_Mass_jj', 0): [500,10000],\n",
    "            ('vbf_dEta_jj', 0): [4,10000],\n",
    "            'VVFatJetParticleNet_Th4q': [0.9,1]\n",
    "            \n",
    "        },\n",
    "        label=\"Pass\",\n",
    "    ),\n",
    "    \"fail\": postprocessing.Region(\n",
    "        cuts={\n",
    "            \"bbFatJetParticleNetMD_Txbb\": [-CUT_MAX_VAL, 0.985],\n",
    "            ('nGoodVBFJets', 0): [2,40],\n",
    "            ('vbf_Mass_jj', 0): [500,10000],\n",
    "            ('vbf_dEta_jj', 0): [4,10000],\n",
    "            'VVFatJetParticleNet_Th4q': [0.9,1]\n",
    "        },\n",
    "        label=\"Fail\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "# variable to plot\n",
    "shape_vars = [\n",
    "    postprocessing.ShapeVar(\n",
    "        \"bbFatJetParticleNetMass\",\n",
    "        r\"$m^{bb}_\\mathrm{Reg}$ (GeV)\",\n",
    "        [20, 50, 250],\n",
    "        reg=True,\n",
    "        blind_window=[100, 150],\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "t = postprocessing.get_templates(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    year,\n",
    "    nonres_sig_keys,\n",
    "    selection_regions,\n",
    "    shape_vars,\n",
    "    systematics,\n",
    "    bg_keys=bg_keys,\n",
    "    plot_sig_keys=[\n",
    "        \"HHbbVV\",\n",
    "        \"VBFHHbbVV\",\n",
    "        \"qqHH_CV_1_C2V_0_kl_1_HHbbVV\",\n",
    "        \"qqHH_CV_1_C2V_2_kl_1_HHbbVV\",\n",
    "    ],\n",
    "    sig_scale_dict={\n",
    "        \"HHbbVV\": 1e4,\n",
    "        \"VBFHHbbVV\": 1e5,\n",
    "        \"qqHH_CV_1_C2V_0_kl_1_HHbbVV\": 2e2,\n",
    "        \"qqHH_CV_1_C2V_2_kl_1_HHbbVV\": 2e2,\n",
    "    },\n",
    "    plot_dir=f\"{plot_dir}/templates\",\n",
    "    prev_cutflow=cutflow,\n",
    "    weight_shifts={},\n",
    "    jshift=\"\",\n",
    "    plot_shifts=False,\n",
    "    lpsfs=False,\n",
    "    show=True,\n",
    ")\n",
    "cutflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we extracted the data used in datacard (get_templates() prints out the cutflow.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable to plot\n",
    "shape_vars = [\n",
    "    postprocessing.ShapeVar(\n",
    "        \"bbFatJetParticleNetMass\",\n",
    "        r\"$m^{bb}_\\mathrm{Reg}$ (GeV)\",\n",
    "        [20, 50, 250],\n",
    "        reg=True,\n",
    "        blind_window=[100, 150],\n",
    "    ),\n",
    "]\n",
    "# A \n",
    "\n",
    "\n",
    "# first we will do 0 to 115 mass cut pass and fail region. then we do 145 to 100000 pass and fail. the sums give (C,D)\n",
    "# then we do one of 115 to 145 pass and fail (A,B)and we record each of the homies.\n",
    "selection_regions_control1 = {\n",
    "    \"pass\": postprocessing.Region(\n",
    "        cuts={\n",
    "            \"bbFatJetParticleNetMD_Txbb\": [0.985, CUT_MAX_VAL],\n",
    "            ('nGoodVBFJets', 0): [2,40],\n",
    "            ('vbf_Mass_jj', 0): [400,10000],\n",
    "            ('vbf_dEta_jj', 0): [3,10000],\n",
    "            'VVFatJetParticleNet_Th4q': [0.9,1],\n",
    "            \"bbFatJetParticleNetMass\": [145,100000],\n",
    "        },\n",
    "        label=\"Pass\",\n",
    "    ),\n",
    "    \"fail\": postprocessing.Region(\n",
    "        cuts={\n",
    "            \"bbFatJetParticleNetMD_Txbb\": [-CUT_MAX_VAL, 0.985],\n",
    "            ('nGoodVBFJets', 0): [2,40],\n",
    "            ('vbf_Mass_jj', 0): [400,10000],\n",
    "            ('vbf_dEta_jj', 0): [3,10000],\n",
    "            'VVFatJetParticleNet_Th4q': [0.9,1],\n",
    "            \"bbFatJetParticleNetMass\": [145,100000],\n",
    "        },\n",
    "        label=\"Fail\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "selection_regions_control2 = {\n",
    "    \"pass\": postprocessing.Region(\n",
    "        cuts={\n",
    "            \"bbFatJetParticleNetMD_Txbb\": [0.985, CUT_MAX_VAL],\n",
    "            ('nGoodVBFJets', 0): [2,40],\n",
    "            ('vbf_Mass_jj', 0): [400,10000],\n",
    "            ('vbf_dEta_jj', 0): [3,10000],\n",
    "            'VVFatJetParticleNet_Th4q': [0.9,1],\n",
    "            \"bbFatJetParticleNetMass\": [0,115],\n",
    "        },\n",
    "        label=\"Pass\",\n",
    "    ),\n",
    "    \"fail\": postprocessing.Region(\n",
    "        cuts={\n",
    "            \"bbFatJetParticleNetMD_Txbb\": [-CUT_MAX_VAL, 0.985],\n",
    "            ('nGoodVBFJets', 0): [2,40],\n",
    "            ('vbf_Mass_jj', 0): [400,10000],\n",
    "            ('vbf_dEta_jj', 0): [3,10000],\n",
    "            'VVFatJetParticleNet_Th4q': [0.9,1],\n",
    "            \"bbFatJetParticleNetMass\": [0,115],\n",
    "        },\n",
    "        label=\"Fail\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "selection_regions_signal = {\n",
    "    \"pass\": postprocessing.Region(\n",
    "        cuts={\n",
    "            \"bbFatJetParticleNetMD_Txbb\": [0.985, CUT_MAX_VAL],\n",
    "            ('nGoodVBFJets', 0): [2,40],\n",
    "            ('vbf_Mass_jj', 0): [400,10000],\n",
    "            ('vbf_dEta_jj', 0): [3,10000],\n",
    "            'VVFatJetParticleNet_Th4q': [0.9,1],\n",
    "            \"bbFatJetParticleNetMass\": [115,145],\n",
    "        },\n",
    "        label=\"Pass\",\n",
    "    ),\n",
    "    \"fail\": postprocessing.Region(\n",
    "        cuts={\n",
    "            \"bbFatJetParticleNetMD_Txbb\": [-CUT_MAX_VAL, 0.985],\n",
    "            ('nGoodVBFJets', 0): [2,40],\n",
    "            ('vbf_Mass_jj', 0): [400,10000],\n",
    "            ('vbf_dEta_jj', 0): [3,10000],\n",
    "            'VVFatJetParticleNet_Th4q': [0.9,1],\n",
    "            \"bbFatJetParticleNetMass\": [115,145],\n",
    "        },\n",
    "        label=\"Fail\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "t_signal = postprocessing.get_templates(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    year,\n",
    "    nonres_sig_keys,\n",
    "    selection_regions_signal,\n",
    "    shape_vars,\n",
    "    systematics,\n",
    "    bg_keys=bg_keys,\n",
    "    plot_sig_keys=[\n",
    "        \"HHbbVV\",\n",
    "        \"VBFHHbbVV\",\n",
    "        \"qqHH_CV_1_C2V_0_kl_1_HHbbVV\",\n",
    "        \"qqHH_CV_1_C2V_2_kl_1_HHbbVV\",\n",
    "    ],\n",
    "    sig_scale_dict={\n",
    "        \"HHbbVV\": 1e4,\n",
    "        \"VBFHHbbVV\": 1e5,\n",
    "        \"qqHH_CV_1_C2V_0_kl_1_HHbbVV\": 2e2,\n",
    "        \"qqHH_CV_1_C2V_2_kl_1_HHbbVV\": 2e2,\n",
    "    },\n",
    "    plot_dir=f\"{plot_dir}/templates\",\n",
    "    prev_cutflow=cutflow,\n",
    "    weight_shifts={},\n",
    "    jshift=\"\",\n",
    "    plot_shifts=False,\n",
    "    lpsfs=False,\n",
    "    show=True,\n",
    ")\n",
    "\n",
    "t_control1 = postprocessing.get_templates(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    year,\n",
    "    nonres_sig_keys,\n",
    "    selection_regions_control1,\n",
    "    shape_vars,\n",
    "    systematics,\n",
    "    bg_keys=bg_keys,\n",
    "    plot_sig_keys=[\n",
    "        \"HHbbVV\",\n",
    "        \"VBFHHbbVV\",\n",
    "        \"qqHH_CV_1_C2V_0_kl_1_HHbbVV\",\n",
    "        \"qqHH_CV_1_C2V_2_kl_1_HHbbVV\",\n",
    "    ],\n",
    "    sig_scale_dict={\n",
    "        \"HHbbVV\": 1e4,\n",
    "        \"VBFHHbbVV\": 1e5,\n",
    "        \"qqHH_CV_1_C2V_0_kl_1_HHbbVV\": 2e2,\n",
    "        \"qqHH_CV_1_C2V_2_kl_1_HHbbVV\": 2e2,\n",
    "    },\n",
    "    plot_dir=f\"{plot_dir}/templates\",\n",
    "    prev_cutflow=cutflow,\n",
    "    weight_shifts={},\n",
    "    jshift=\"\",\n",
    "    plot_shifts=False,\n",
    "    lpsfs=False,\n",
    "    show=False,\n",
    ")\n",
    "\n",
    "\n",
    "t_control2 = postprocessing.get_templates(\n",
    "    events_dict,\n",
    "    bb_masks,\n",
    "    year,\n",
    "    nonres_sig_keys,\n",
    "    selection_regions_control2,\n",
    "    shape_vars,\n",
    "    systematics,\n",
    "    bg_keys=bg_keys,\n",
    "    plot_sig_keys=[\n",
    "        \"HHbbVV\",\n",
    "        \"VBFHHbbVV\",\n",
    "        \"qqHH_CV_1_C2V_0_kl_1_HHbbVV\",\n",
    "        \"qqHH_CV_1_C2V_2_kl_1_HHbbVV\",\n",
    "    ],\n",
    "    sig_scale_dict={\n",
    "        \"HHbbVV\": 1e4,\n",
    "        \"VBFHHbbVV\": 1e5,\n",
    "        \"qqHH_CV_1_C2V_0_kl_1_HHbbVV\": 2e2,\n",
    "        \"qqHH_CV_1_C2V_2_kl_1_HHbbVV\": 2e2,\n",
    "    },\n",
    "    plot_dir=f\"{plot_dir}/templates\",\n",
    "    prev_cutflow=cutflow,\n",
    "    weight_shifts={},\n",
    "    jshift=\"\",\n",
    "    plot_shifts=False,\n",
    "    lpsfs=False,\n",
    "    show=False,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories =  ['HHbbVV', 'ggHH_kl_2p45_kt_1_HHbbVV', 'ggHH_kl_5_kt_1_HHbbVV', 'ggHH_kl_0_kt_1_HHbbVV', 'VBFHHbbVV', 'qqHH_CV_1_C2V_0_kl_1_HHbbVV', 'qqHH_CV_1p5_C2V_1_kl_1_HHbbVV', \n",
    "               'qqHH_CV_1_C2V_1_kl_2_HHbbVV', 'qqHH_CV_1_C2V_2_kl_1_HHbbVV', 'qqHH_CV_1_C2V_1_kl_0_HHbbVV', 'qqHH_CV_0p5_C2V_1_kl_1_HHbbVV', 'QCD', 'TT', 'ST', 'V+Jets', 'Diboson', \n",
    "               'ggFHbb', 'VBFHbb', 'ZHbb', 'WHbb', 'ggZHbb', 'ttHbb', 'Data', 'HHbbVV_txbb_down', 'ggHH_kl_2p45_kt_1_HHbbVV_txbb_down', 'ggHH_kl_5_kt_1_HHbbVV_txbb_down', 'ggHH_kl_0_kt_1_HHbbVV_txbb_down', \n",
    "               'VBFHHbbVV_txbb_down', 'qqHH_CV_1_C2V_0_kl_1_HHbbVV_txbb_down', 'qqHH_CV_1p5_C2V_1_kl_1_HHbbVV_txbb_down', 'qqHH_CV_1_C2V_1_kl_2_HHbbVV_txbb_down', 'qqHH_CV_1_C2V_2_kl_1_HHbbVV_txbb_down', \n",
    "               'qqHH_CV_1_C2V_1_kl_0_HHbbVV_txbb_down', 'qqHH_CV_0p5_C2V_1_kl_1_HHbbVV_txbb_down', 'HHbbVV_txbb_up', 'ggHH_kl_2p45_kt_1_HHbbVV_txbb_up', 'ggHH_kl_5_kt_1_HHbbVV_txbb_up', 'ggHH_kl_0_kt_1_HHbbVV_txbb_up', \n",
    "               'VBFHHbbVV_txbb_up', 'qqHH_CV_1_C2V_0_kl_1_HHbbVV_txbb_up', 'qqHH_CV_1p5_C2V_1_kl_1_HHbbVV_txbb_up', 'qqHH_CV_1_C2V_1_kl_2_HHbbVV_txbb_up', 'qqHH_CV_1_C2V_2_kl_1_HHbbVV_txbb_up', \n",
    "               'qqHH_CV_1_C2V_1_kl_0_HHbbVV_txbb_up', 'qqHH_CV_0p5_C2V_1_kl_1_HHbbVV_txbb_up']\n",
    "hhbbvv_index = categories.index('HHbbVV')\n",
    "index = categories.index('Data')\n",
    "\n",
    "\n",
    "\n",
    "# Assuming you have the Hist objects as hist_pass and hist_fail\n",
    "hist_pass = t_signal['pass']\n",
    "hist_fail = t_signal['fail']\n",
    "\n",
    "hist_pass_values = hist_pass.values()\n",
    "hist_fail_values = hist_fail.values()\n",
    "\n",
    "\n",
    "hhbbvv_values_pass = hist_pass_values[index]\n",
    "hhbbvv_values_fail = hist_fail_values[index]\n",
    "\n",
    "\n",
    "print(type(hist_pass.values()))\n",
    "#print(hist_pass.values())\n",
    "print(dir(hist_pass))\n",
    "\n",
    "total_events_pass = np.sum(hhbbvv_values_pass)\n",
    "total_events_fail = np.sum(hhbbvv_values_fail)\n",
    "\n",
    "print(f\"Total number of 'HHbbVV' events in 'pass' histogram: {total_events_pass}\") # 0.023298 \n",
    "print(f\"Total number of 'HHbbVV' events in 'fail' histogram: {total_events_fail}\") # 0.019126\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets_of_interest = ['VBFHHbbVV', 'qqHH_CV_1_C2V_2_kl_1_HHbbVV', 'qqHH_CV_1_C2V_0_kl_1_HHbbVV', 'Data']\n",
    "abcd_regions = {}\n",
    "categories =  ['HHbbVV', 'ggHH_kl_2p45_kt_1_HHbbVV', 'ggHH_kl_5_kt_1_HHbbVV', 'ggHH_kl_0_kt_1_HHbbVV', 'VBFHHbbVV', 'qqHH_CV_1_C2V_0_kl_1_HHbbVV', 'qqHH_CV_1p5_C2V_1_kl_1_HHbbVV', \n",
    "               'qqHH_CV_1_C2V_1_kl_2_HHbbVV', 'qqHH_CV_1_C2V_2_kl_1_HHbbVV', 'qqHH_CV_1_C2V_1_kl_0_HHbbVV', 'qqHH_CV_0p5_C2V_1_kl_1_HHbbVV', 'QCD', 'TT', 'ST', 'V+Jets', 'Diboson', \n",
    "               'ggFHbb', 'VBFHbb', 'ZHbb', 'WHbb', 'ggZHbb', 'ttHbb', 'Data', 'HHbbVV_txbb_down', 'ggHH_kl_2p45_kt_1_HHbbVV_txbb_down', 'ggHH_kl_5_kt_1_HHbbVV_txbb_down', 'ggHH_kl_0_kt_1_HHbbVV_txbb_down', \n",
    "               'VBFHHbbVV_txbb_down', 'qqHH_CV_1_C2V_0_kl_1_HHbbVV_txbb_down', 'qqHH_CV_1p5_C2V_1_kl_1_HHbbVV_txbb_down', 'qqHH_CV_1_C2V_1_kl_2_HHbbVV_txbb_down', 'qqHH_CV_1_C2V_2_kl_1_HHbbVV_txbb_down', \n",
    "               'qqHH_CV_1_C2V_1_kl_0_HHbbVV_txbb_down', 'qqHH_CV_0p5_C2V_1_kl_1_HHbbVV_txbb_down', 'HHbbVV_txbb_up', 'ggHH_kl_2p45_kt_1_HHbbVV_txbb_up', 'ggHH_kl_5_kt_1_HHbbVV_txbb_up', 'ggHH_kl_0_kt_1_HHbbVV_txbb_up', \n",
    "               'VBFHHbbVV_txbb_up', 'qqHH_CV_1_C2V_0_kl_1_HHbbVV_txbb_up', 'qqHH_CV_1p5_C2V_1_kl_1_HHbbVV_txbb_up', 'qqHH_CV_1_C2V_1_kl_2_HHbbVV_txbb_up', 'qqHH_CV_1_C2V_2_kl_1_HHbbVV_txbb_up', \n",
    "               'qqHH_CV_1_C2V_1_kl_0_HHbbVV_txbb_up', 'qqHH_CV_0p5_C2V_1_kl_1_HHbbVV_txbb_up']\n",
    "\n",
    "\n",
    "# Loop through each dataset of interest\n",
    "for dataset in datasets_of_interest:\n",
    "    # Find the index in the categories list\n",
    "    dataset_index = categories.index(dataset)\n",
    "    \n",
    "    # Initialize a sub-dictionary to hold the results for this dataset\n",
    "    abcd_regions[dataset] = {}\n",
    "    \n",
    "    # Loop through 'pass' and 'fail'\n",
    "    for pass_fail in ['pass', 'fail']:\n",
    "        # Extract the number of events from each template (two for control since it is disjointed)\n",
    "        hist_values_signal = t_signal[pass_fail].values()\n",
    "        total_events_signal = np.sum(hist_values_signal[dataset_index])\n",
    "        \n",
    "        hist_values_control1 = t_control1[pass_fail].values()\n",
    "        total_events_control1 = np.sum(hist_values_control1[dataset_index])\n",
    "        \n",
    "        hist_values_control2 = t_control2[pass_fail].values()\n",
    "        total_events_control2 = np.sum(hist_values_control2[dataset_index])\n",
    "        \n",
    "        total_events_control = total_events_control1 + total_events_control2\n",
    "        \n",
    "        abcd_regions[dataset][f\"signal_{pass_fail}\"] = total_events_signal\n",
    "        abcd_regions[dataset][f\"control_{pass_fail}\"] = total_events_control\n",
    "\n",
    "\n",
    "abcd_regions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datacard(data_values, signal_values):\n",
    "    \"\"\"Generate a datacard string based on the given values.\"\"\"\n",
    "    return f\"\"\"imax 4\n",
    "jmax 1\n",
    "kmax *\n",
    "shapes * * FAKE\n",
    "---------------\n",
    "---------------\n",
    "bin \t chA \t chB \t chC \t chD\n",
    "observation \t   {data_values['signal_pass']} \t  {data_values['signal_fail']} \t {data_values['control_pass']} \t {data_values['control_fail']}\n",
    "------------------------------\n",
    "bin \t chA \t chA \t chB \t chB \t chC \t chC \t chD \t chD\n",
    "process \t sig\t bkg \t sig\t bkg \t sig\t bkg \t sig\t bkg\n",
    "process \t 0\t 1\t 0\t 1\t 0\t 1\t 0\t 1\n",
    "rate\t {signal_values['signal_pass']} \t 1 \t {signal_values['signal_fail']} \t 1 \t {signal_values['control_pass']} \t 1 \t {signal_values['control_fail']} \t 1\n",
    "------------------------------\n",
    "single_A    rateParam       chA     bkg      (@0*@1/@2)                    single_B,single_C,single_D\n",
    "single_B    rateParam       chB     bkg     {data_values['signal_fail']}\n",
    "single_C    rateParam       chC     bkg     {data_values['control_pass']}\n",
    "single_D    rateParam       chD     bkg     {data_values['control_fail']}\n",
    "norm rateParam * sig 1\n",
    "single_lumi \t lnN \t 1.2\t -  \t 1.2\t -  \t 1.2\t -  \t 1.2\t -  \n",
    "\"\"\"\n",
    "\n",
    "# Extract Data values\n",
    "data_values = abcd_regions['Data']\n",
    "\n",
    "# Loop through each signal and generate a datacard\n",
    "for dataset in datasets_of_interest:\n",
    "    if dataset == 'Data':  # Skip 'Data'\n",
    "        continue\n",
    "    signal_values = abcd_regions[dataset]\n",
    "    datacard_text = generate_datacard(data_values, signal_values)\n",
    "    \n",
    "    # Save to a text file\n",
    "    filename = f\"/home/users/annava/CMSSW_12_3_4/src/HiggsAnalysis/CombinedLimit/datacards/datacard_{dataset}.txt\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(datacard_text)\n",
    "        \n",
    "    print(f\"Datacard for {dataset} has been saved as {filename}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15adc7883e707560d0d9727709639b8fe3f3cff1f197d2d643742923ff23a29c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
