{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"/home/users/annava/projects/HHbbVV/src/HHbbVV/postprocessing/\")\n",
    "from collections import OrderedDict\n",
    "import utils\n",
    "import postprocessing\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "hep.style.use(\"CMS\")\n",
    "formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_powerlimits((-3, 3))\n",
    "plt.rcParams.update({\"font.size\": 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonres_samples = OrderedDict(\n",
    "    [\n",
    "        (\"HHbbVV\", \"GluGluToHHTobbVV_node_cHHH1\"),\n",
    "        (\"ggHH_kl_2p45_kt_1_HHbbVV\", \"GluGluToHHTobbVV_node_cHHH2p45\"),\n",
    "        (\"ggHH_kl_5_kt_1_HHbbVV\", \"GluGluToHHTobbVV_node_cHHH5\"),\n",
    "        (\"ggHH_kl_0_kt_1_HHbbVV\", \"GluGluToHHTobbVV_node_cHHH0\"),\n",
    "        (\"qqHH_CV_1_C2V_1_kl_1_HHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_1_C3_1\"),\n",
    "        (\"VBFHHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_1_C3_1\"),\n",
    "        (\"qqHH_CV_1_C2V_0_kl_1_HHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_0_C3_1\"),\n",
    "        (\"qqHH_CV_1p5_C2V_1_kl_1_HHbbVV\", \"VBF_HHTobbVV_CV_1_5_C2V_1_C3_1\"),\n",
    "        (\"qqHH_CV_1_C2V_1_kl_2_HHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_1_C3_2\"),\n",
    "        (\"qqHH_CV_1_C2V_2_kl_1_HHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_2_C3_1\"),\n",
    "        (\"qqHH_CV_1_C2V_1_kl_0_HHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_1_C3_0\"),\n",
    "        (\"qqHH_CV_0p5_C2V_1_kl_1_HHbbVV\", \"VBF_HHTobbVV_CV_0_5_C2V_1_C3_1\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "samples = OrderedDict(\n",
    "    [\n",
    "        (\"QCD\", \"QCD\"),\n",
    "        (\"TT\", \"TT\"),\n",
    "        (\"ST\", \"ST\"),\n",
    "        (\"V+Jets\", (\"WJets\", \"ZJets\")),\n",
    "        (\"Diboson\", (\"WW\", \"WZ\", \"ZZ\")),\n",
    "        # TODO: break this down into production modes for combination!!!!\n",
    "        # https://gitlab.cern.ch/hh/naming-conventions#single-h-backgrounds\n",
    "        (\"Hbb\", \"*HToBB\"),\n",
    "        (\"HWW\", (\"*HToWW\", \"*HToNonbb\")),\n",
    "        (\"HH\", (\"GluGluToHHTo4B_node_cHHH1_preUL\")),\n",
    "        (\"Data\", \"JetHT\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "samples2 = OrderedDict(\n",
    "    [\n",
    "        (\"QCD\", \"QCD\"),\n",
    "        (\"TT\", \"TT\"),\n",
    "        (\"ST\", \"ST\"),\n",
    "        (\"V+Jets\", (\"WJets\", \"ZJets\")),\n",
    "        (\"Diboson\", (\"WW\", \"WZ\", \"ZZ\")),\n",
    "        # TODO: break this down into production modes for combination!!!!\n",
    "        # https://gitlab.cern.ch/hh/naming-conventions#single-h-backgrounds\n",
    "        (\"Hbb\", \"*HToBB\"),\n",
    "        (\"HWW\", (\"*HToWW\", \"*HToNonbb\")),\n",
    "        (\"VBFHHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_1_C3_1\"),\n",
    "        (\"Data\", \"JetHT\"),\n",
    "        (\"qqHH_CV_1_C2V_0_kl_1_HHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_0_C3_1\"),\n",
    "        (\"qqHH_CV_1p5_C2V_1_kl_1_HHbbVV\", \"VBF_HHTobbVV_CV_1_5_C2V_1_C3_1\"),\n",
    "        (\"qqHH_CV_1_C2V_1_kl_2_HHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_1_C3_2\"),\n",
    "        (\"qqHH_CV_1_C2V_2_kl_1_HHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_2_C3_1\"),\n",
    "        (\"qqHH_CV_1_C2V_1_kl_0_HHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_1_C3_0\"),\n",
    "        (\"qqHH_CV_0p5_C2V_1_kl_1_HHbbVV\", \"VBF_HHTobbVV_CV_0_5_C2V_1_C3_1\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "single_dataset_test = {\"VBFHHbbVV\": \"VBF_HHTobbVV_CV_1_C2V_1_C3_1\"}\n",
    "events_dict = utils.load_samples(\n",
    "    data_dir=\"/home/users/annava/projects/HHbbVV/src/HHbbVV/VBF_binder/data/\",\n",
    "    samples=samples2,\n",
    "    year=\"2017\",\n",
    ")\n",
    "postprocessing.apply_weights(events_dict, year=\"2017\", cutflow=None, qcd_sf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events_dict[\"QCD\"].columns.tolist())\n",
    "print(events_dict.keys())\n",
    "print(events_dict[\"QCD\"][(\"ak8FatJetParticleNetMass\", 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes appropriate scale factor for each signal file\n",
    "def compute_individual_scale_factors(events_dict, S_list):\n",
    "    total_background_weight = 0\n",
    "\n",
    "    # Calculate the total background weight\n",
    "    for dataset, dataframe in events_dict.items():\n",
    "        if dataset not in S_list:\n",
    "            total_weight = np.sum(dataframe[\"finalWeight\"])\n",
    "            total_background_weight += total_weight\n",
    "\n",
    "    # Calculate individual scale factors for each signal dataset\n",
    "    scale_factors = []\n",
    "    for dataset in S_list:\n",
    "        total_signal_weight = np.sum(events_dict[dataset][\"finalWeight\"])\n",
    "\n",
    "        if total_signal_weight == 0:\n",
    "            scale_factor = 0\n",
    "        else:\n",
    "            scale_factor = total_background_weight / total_signal_weight / 10\n",
    "            n = np.floor(np.log10(scale_factor))  # Find the order of magnitude\n",
    "            scale_factor = 10 ** (n + 1) if scale_factor >= 10**n * 5 else 10**n\n",
    "\n",
    "        scale_factors.append(scale_factor)\n",
    "\n",
    "    return scale_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_cut_histogram(\n",
    "    combined_data,\n",
    "    S_list,\n",
    "    signal_sf,\n",
    "    xlabel,\n",
    "    column_name,\n",
    "    xrange,\n",
    "    title=\"Histogram MC signal and background\",\n",
    "    cuts={},\n",
    "):\n",
    "    jj_mass_cut = cuts.get(\"jj_mass_cut\", 500)\n",
    "    jj_eta_cut = cuts.get(\"jj_eta_cut\", 4.0)\n",
    "    j_eta_cut = cuts.get(\"j_eta_cut\", 1.5)\n",
    "    Hbb_Txbb_cut = cuts.get(\"Hbb_Txbb_cut\", 0.8)\n",
    "    HVV_Th4q_cut = cuts.get(\"HVV_Th4q_cut\", 0.0)\n",
    "\n",
    "    signal_data = []\n",
    "    signal_weights = []\n",
    "    background_data = []\n",
    "    background_weights = []\n",
    "    background_labels = []\n",
    "\n",
    "    for dataset, dataframe in combined_data.items():\n",
    "        # Computing variables of interest and masks based on them\n",
    "        Hbb_mask = (\n",
    "            dataframe[(\"ak8FatJetParticleNetMD_Txbb\", 0)]\n",
    "            > dataframe[(\"ak8FatJetParticleNetMD_Txbb\", 1)]\n",
    "        )\n",
    "        Hbb_Txbb_values = np.where(\n",
    "            Hbb_mask,\n",
    "            dataframe[(\"ak8FatJetParticleNetMD_Txbb\", 0)],\n",
    "            dataframe[(\"ak8FatJetParticleNetMD_Txbb\", 1)],\n",
    "        )\n",
    "        HVV_Th4q_values = np.where(\n",
    "            ~Hbb_mask,\n",
    "            dataframe[(\"ak8FatJetParticleNet_Th4q\", 0)],\n",
    "            dataframe[(\"ak8FatJetParticleNet_Th4q\", 1)],\n",
    "        )\n",
    "\n",
    "        mask = (\n",
    "            (dataframe[(\"nGoodMuons\", 0)] == 0)\n",
    "            & (dataframe[(\"nGoodElectrons\", 0)] == 0)\n",
    "            & (dataframe[(\"nGoodVBFJets\", 0)] >= 2)\n",
    "            & (dataframe[(\"nGoodJets\", 0)] == 0)\n",
    "            & (dataframe[(\"vbf_Mass_jj\", 0)] > jj_mass_cut)\n",
    "            & (dataframe[(\"vbf_dEta_jj\", 0)] > jj_eta_cut)\n",
    "            & (np.abs(dataframe[(\"vbfeta\", 0)]) > j_eta_cut)\n",
    "            & (np.abs(dataframe[(\"vbfeta\", 1)]) > j_eta_cut)\n",
    "            & (Hbb_Txbb_values >= Hbb_Txbb_cut)\n",
    "            & (HVV_Th4q_values >= HVV_Th4q_cut)\n",
    "        )\n",
    "        # column_data = df[('bbFatJetPtOverDijetPt', 0)].values * df[('DijetPt', 0)].values\n",
    "        # Mass: ('ak8FatJetMass', 0), ('ak8FatJetMass', 1) or ('ak8FatJetParticleNetMass', 0), ('ak8FatJetParticleNetMass', 1)\n",
    "        df = dataframe[mask]\n",
    "        if column_name == \"mass\":\n",
    "            column_data = np.where(\n",
    "                Hbb_mask,\n",
    "                dataframe[(\"ak8FatJetParticleNetMass\", 0)],\n",
    "                dataframe[(\"ak8FatJetParticleNetMass\", 1)],\n",
    "            )\n",
    "            column_data = column_data[mask]\n",
    "        elif column_name == \"Hbb_Txbb\":\n",
    "            column_data = Hbb_Txbb_values\n",
    "            column_data = column_data[mask]\n",
    "        elif column_name == \"HVV_Th4q\":\n",
    "            column_data = HVV_Th4q_values\n",
    "            column_data = column_data[mask]\n",
    "        else:\n",
    "            column_data = df[column_name].values\n",
    "\n",
    "        total_weight = df[\"finalWeight\"]\n",
    "\n",
    "        if dataset in S_list:\n",
    "            i = S_list.index(dataset)\n",
    "            column_weights = signal_sf[i] * total_weight\n",
    "            signal_data.append(column_data)\n",
    "            signal_weights.append(column_weights)\n",
    "        else:\n",
    "            column_weights = total_weight\n",
    "            background_data.append(column_data)\n",
    "            background_weights.append(column_weights)\n",
    "            background_labels.append(dataset)\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        2, 1, figsize=(12, 10), gridspec_kw={\"height_ratios\": [3, 1]}, sharex=True\n",
    "    )\n",
    "    bins = np.linspace(xrange[0], xrange[1], 100)\n",
    "\n",
    "    ax[0].hist(\n",
    "        background_data,\n",
    "        bins=bins,\n",
    "        weights=background_weights,\n",
    "        stacked=True,\n",
    "        label=background_labels,\n",
    "    )\n",
    "\n",
    "    for data, weight, label, sf in zip(signal_data, signal_weights, S_list, signal_sf):\n",
    "        if np.sum(weight) > 0:\n",
    "            mean_value = np.average(data, weights=weight)\n",
    "            ax[0].axvline(mean_value, color=\"grey\", linestyle=\"--\", linewidth=1)\n",
    "            ax[0].hist(\n",
    "                data,\n",
    "                bins=bins,\n",
    "                weights=weight,\n",
    "                histtype=\"step\",\n",
    "                label=f\"{sf}x {label}\",\n",
    "                linewidth=1.5,\n",
    "            )\n",
    "\n",
    "    ax[0].set_ylabel(\"Expected # events\")\n",
    "    ax[0].set_title(title)\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Calculating and plotting significance for each signal dataset\n",
    "    for data, weight, label, sf in zip(signal_data, signal_weights, S_list, signal_sf):\n",
    "        hist_signal, _ = np.histogram(data, bins=bins, weights=weight)\n",
    "        hist_background, bins = np.histogram(\n",
    "            np.concatenate(background_data), bins=bins, weights=np.concatenate(background_weights)\n",
    "        )\n",
    "        significance = np.where(hist_background > 0, hist_signal / np.sqrt(hist_background) / sf, 0)\n",
    "        # Calculate overall significance and round to two significant figures\n",
    "        overall_significance = (\n",
    "            np.sum(weight) / sf / np.sqrt(np.sum(np.concatenate(background_weights)))\n",
    "        )\n",
    "        n = np.floor(np.log10(overall_significance))\n",
    "        overall_significance = np.round(overall_significance, -int(n - 1))\n",
    "\n",
    "        # Convert to scientific notation\n",
    "        overall_significance_sci = \"{:e}\".format(overall_significance)\n",
    "        ax[1].step(\n",
    "            bins[:-1],\n",
    "            sf * significance,\n",
    "            where=\"mid\",\n",
    "            label=f\"Significance {sf}x{label}: {overall_significance_sci}\",\n",
    "        )\n",
    "\n",
    "    ax[1].set_xlabel(xlabel)\n",
    "    ax[1].set_ylabel(\"$S / \\sqrt{B}$\")\n",
    "    ax[1].set_title(\"Significance\")\n",
    "    ax[1].legend()\n",
    "\n",
    "    ax[0].set_xlim(xrange)\n",
    "    ax[1].set_xlim(xrange)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print out the individual significance\n",
    "    significances = []\n",
    "    for data, weight, label, sf in zip(signal_data, signal_weights, S_list, signal_sf):\n",
    "        S = np.sum(weight) / sf\n",
    "        B = np.sum(np.concatenate(background_weights))\n",
    "        print(f\"Significance for {label}: {S/np.sqrt(B)} {S} {B}\")\n",
    "        significances.append(S / np.sqrt(B))\n",
    "\n",
    "    return significances\n",
    "\n",
    "\n",
    "S_list = [\"VBFHHbbVV\", \"qqHH_CV_1_C2V_0_kl_1_HHbbVV\", \"qqHH_CV_1_C2V_2_kl_1_HHbbVV\"]\n",
    "scale_factors = compute_individual_scale_factors(\n",
    "    events_dict, S_list\n",
    ")  # notice that scale factor is based on pre-cuts (thus we can still compare visually)\n",
    "xlabel = \"Hbb ParNet $M$ (GeV)\"\n",
    "cuts = {\n",
    "    \"jj_mass_cut\": 0,\n",
    "    \"jj_eta_cut\": 3.5,\n",
    "    \"j_eta_cut\": 1,\n",
    "    \"Hbb_Txbb_cut\": 0.95,\n",
    "    \"HVV_Th4q_cut\": 0.9,\n",
    "}\n",
    "cuts = {\"jj_mass_cut\": 0, \"jj_eta_cut\": 0, \"j_eta_cut\": 0, \"Hbb_Txbb_cut\": 0, \"HVV_Th4q_cut\": 0}\n",
    "plot_cut_histogram(\n",
    "    events_dict,\n",
    "    S_list=S_list,\n",
    "    signal_sf=scale_factors,\n",
    "    xlabel=\"HVV_Th4q\",\n",
    "    column_name=\"mass\",\n",
    "    xrange=[0, 300],\n",
    "    cuts=cuts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_list = [\"VBFHHbbVV\", \"qqHH_CV_1_C2V_0_kl_1_HHbbVV\", \"qqHH_CV_1_C2V_2_kl_1_HHbbVV\"]\n",
    "xlabel = \"VBF-Jet $p_T$ (GeV)\"\n",
    "xlabel = \"Hbb Jet $p_T$ (GeV)\"\n",
    "xlabel = \"Hbb ParNet $M$ (GeV)\"\n",
    "col_name = (\"vbfpt\", 0)\n",
    "scale_factors = compute_individual_scale_factors(\n",
    "    events_dict, S_list\n",
    ")  # notice that scale factor is based on pre-cuts (thus we can still compare visually)\n",
    "cuts = {\n",
    "    \"jj_mass_cut\": 500,\n",
    "    \"jj_eta_cut\": 4.0,\n",
    "    \"j_eta_cut\": 1.5,\n",
    "    \"Hbb_Txbb_cut\": 0.95,\n",
    "    \"HVV_Th4q_cut\": 0.6,\n",
    "}\n",
    "# plot_cut_histogram(events_dict, S_list=S_list, signal_sf=scale_factors, xlabel=xlabel, column_name=col_name,xrange = [0,300],cuts= cuts)\n",
    "cuts = {\n",
    "    \"jj_mass_cut\": 500,\n",
    "    \"jj_eta_cut\": 6.0,\n",
    "    \"j_eta_cut\": 2.5,\n",
    "    \"Hbb_Txbb_cut\": 0.95,\n",
    "    \"HVV_Th4q_cut\": 0.6,\n",
    "}\n",
    "\n",
    "# plot_cut_histogram(events_dict, S_list=S_list, signal_sf=scale_factors, xlabel=xlabel, column_name=col_name,xrange = [0,300],cuts= cuts)\n",
    "cuts = {\"jj_mass_cut\": 0, \"jj_eta_cut\": 0, \"j_eta_cut\": 0, \"Hbb_Txbb_cut\": 0.0, \"HVV_Th4q_cut\": 0.0}\n",
    "\n",
    "\n",
    "# plot different cutting variables distributions before cuts to find reasonable values\n",
    "# (jj_mass_cut = 0 (+ 500) j_eta_cut = 1 (pm 1) jj_eta_cut = 3.5 (pm 1.5) Hbb_Txbb = 0.95 (+ 0.045) Hbb_Txbb = 0.9 (pm 0.09 ) # test out a grid of these in condor_outputs_tests notebook\n",
    "plot_cut_histogram(\n",
    "    events_dict,\n",
    "    S_list=S_list,\n",
    "    signal_sf=scale_factors,\n",
    "    xlabel=\"(vbf_Mass_jj, 0)\",\n",
    "    column_name=(\"vbf_Mass_jj\", 0),\n",
    "    xrange=[0, 1000],\n",
    "    cuts=cuts,\n",
    ")\n",
    "plot_cut_histogram(\n",
    "    events_dict,\n",
    "    S_list=S_list,\n",
    "    signal_sf=scale_factors,\n",
    "    xlabel=\"(vbfeta, 0)\",\n",
    "    column_name=(\"vbfeta\", 0),\n",
    "    xrange=[-4.5, 4.5],\n",
    "    cuts=cuts,\n",
    ")\n",
    "plot_cut_histogram(\n",
    "    events_dict,\n",
    "    S_list=S_list,\n",
    "    signal_sf=scale_factors,\n",
    "    xlabel=\"(vbf_dEta_jj, 0)\",\n",
    "    column_name=(\"vbf_dEta_jj\", 0),\n",
    "    xrange=[0, 8],\n",
    "    cuts=cuts,\n",
    ")\n",
    "plot_cut_histogram(\n",
    "    events_dict,\n",
    "    S_list=S_list,\n",
    "    signal_sf=scale_factors,\n",
    "    xlabel=\"Hbb_Txbb\",\n",
    "    column_name=\"Hbb_Txbb\",\n",
    "    xrange=[0.8, 1],\n",
    "    cuts=cuts,\n",
    ")\n",
    "plot_cut_histogram(\n",
    "    events_dict,\n",
    "    S_list=S_list,\n",
    "    signal_sf=scale_factors,\n",
    "    xlabel=\"HVV_Th4q\",\n",
    "    column_name=\"HVV_Th4q\",\n",
    "    xrange=[0.6, 1],\n",
    "    cuts=cuts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming plot_cut_histogram function is defined as before, with the additional 'title' and 'cuts' parameters\n",
    "# def plot_cut_histogram(combined_data, S_list, signal_sf, xlabel, column_name, xrange, title='Histogram MC signal and background', cuts={}):\n",
    "\n",
    "# Dummy combined_data, S_list, signal_sf, xlabel, column_name, and xrange for the example\n",
    "S_list = [\"VBFHHbbVV\", \"qqHH_CV_1_C2V_0_kl_1_HHbbVV\", \"qqHH_CV_1_C2V_2_kl_1_HHbbVV\"]\n",
    "xlabel = \"Hbb ParNet $M$ (GeV)\"\n",
    "column_name = (\"vbfpt\", 0)\n",
    "signal_sf = compute_individual_scale_factors(events_dict, S_list)  #\n",
    "xrange = [0, 300]  # Replace with your actual x-range\n",
    "\n",
    "# Define the cut parameters and their linspace ranges\n",
    "cut_parameters = {\n",
    "    \"jj_mass_cut\": np.linspace(0, 600, 5),\n",
    "    \"jj_eta_cut\": np.linspace(0, 5.0, 5),\n",
    "    \"j_eta_cut\": np.linspace(0, 4.0, 5),\n",
    "    \"Hbb_Txbb_cut\": np.linspace(0, 0.99, 5),\n",
    "    \"HVV_Th4q_cut\": np.linspace(0, 0.99, 5),\n",
    "}\n",
    "\n",
    "# Loop through each cut parameter and its linspace range\n",
    "for param, values in cut_parameters.items():\n",
    "    for value in values:\n",
    "        # Set only the current cut parameter to the linspace value, others to zero\n",
    "        cuts = {k: 0 for k in cut_parameters.keys()}\n",
    "        cuts[param] = value\n",
    "\n",
    "        # Call the plot function\n",
    "        title = f\"Histogram MC Signal and Background, Varying {param} at {value}\"\n",
    "        plot_cut_histogram(events_dict, S_list, signal_sf, xlabel, column_name, xrange, title, cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cut parameters and their linspace ranges\n",
    "cut_parameters = {\n",
    "    \"jj_mass_cut\": np.linspace(0, 1000, 20),\n",
    "    \"jj_eta_cut\": np.linspace(0, 8.0, 20),\n",
    "    \"j_eta_cut\": np.linspace(0, 4.0, 10),\n",
    "    \"Hbb_Txbb_cut\": np.linspace(0, 0.99, 20) ** 0.5,\n",
    "    \"HVV_Th4q_cut\": np.linspace(0, 0.99, 20) ** 0.5,\n",
    "}\n",
    "\n",
    "# To store the significances\n",
    "all_significances = {}\n",
    "\n",
    "# Loop through each cut parameter and its linspace range\n",
    "for param, values in cut_parameters.items():\n",
    "    all_significances[param] = {}\n",
    "\n",
    "    for signal in S_list:\n",
    "        all_significances[param][signal] = []\n",
    "\n",
    "    for value in values:\n",
    "        # Set only the current cut parameter to the linspace value, others to zero\n",
    "        cuts = {k: 0 for k in cut_parameters.keys()}\n",
    "        cuts[param] = value\n",
    "\n",
    "        # Call the plot function and get significances\n",
    "        title = f\"Histogram MC Signal and Background, Varying {param} at {value}\"\n",
    "        significances = plot_cut_histogram(\n",
    "            events_dict, S_list, signal_sf, xlabel, column_name, xrange, title, cuts\n",
    "        )\n",
    "\n",
    "        # Store the significances\n",
    "        for signal, sig in zip(S_list, significances):\n",
    "            all_significances[param][signal].append(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to round to the nearest power of 10\n",
    "def round_to_nearest_power_of_10(x):\n",
    "    n = np.floor(np.log10(x))  # Find the order of magnitude\n",
    "    return 10 ** (n + 1) if x >= 10**n * 5 else 10**n\n",
    "\n",
    "\n",
    "# Assuming the original scale factors are in signal_sf\n",
    "min_sf = min(signal_sf)\n",
    "adjusted_sf = [round_to_nearest_power_of_10(sf / min_sf) for sf in signal_sf]\n",
    "\n",
    "# Create plots\n",
    "for param, sig_dict in all_significances.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, (signal, sig_values) in enumerate(sig_dict.items()):\n",
    "        # Scale the significances using the appropriate adjusted scale factor\n",
    "        sf = adjusted_sf[i]  # Using the adjusted scale factors\n",
    "        scaled_sig_values = [sig * sf for sig in sig_values]\n",
    "\n",
    "        # Check to make sure the dimensions match before plotting\n",
    "        if len(cut_parameters[param]) != len(scaled_sig_values):\n",
    "            print(f\"Dimension mismatch for {signal}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        plt.plot(\n",
    "            cut_parameters[param],\n",
    "            scaled_sig_values,\n",
    "            label=f\"Scaled significance of {signal} (Scale factor: {sf})\",\n",
    "        )\n",
    "\n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel(\"Scaled Significance\")\n",
    "    plt.title(f\"Scaled Significance vs {param}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
