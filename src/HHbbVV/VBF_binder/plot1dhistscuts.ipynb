{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/users/annava/projects/HHbbVV/src/HHbbVV/postprocessing/\")\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import mplhep as hep\n",
    "import numpy as np\n",
    "import postprocessing\n",
    "import utils\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "hep.style.use(\"CMS\")\n",
    "formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_powerlimits((-3, 3))\n",
    "plt.rcParams.update({\"font.size\": 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonres_samples = OrderedDict(\n",
    "    [\n",
    "        (\"HHbbVV\", \"GluGluToHHTobbVV_node_cHHH1\"),\n",
    "        (\"ggHH_kl_2p45_kt_1_HHbbVV\", \"GluGluToHHTobbVV_node_cHHH2p45\"),\n",
    "        (\"ggHH_kl_5_kt_1_HHbbVV\", \"GluGluToHHTobbVV_node_cHHH5\"),\n",
    "        (\"ggHH_kl_0_kt_1_HHbbVV\", \"GluGluToHHTobbVV_node_cHHH0\"),\n",
    "        (\"qqHH_CV_1_C2V_1_kl_1_HHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_1_C3_1\"),\n",
    "        (\"VBFHHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_1_C3_1\"),\n",
    "        (\"qqHH_CV_1_C2V_0_kl_1_HHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_0_C3_1\"),\n",
    "        (\"qqHH_CV_1p5_C2V_1_kl_1_HHbbVV\", \"VBF_HHTobbVV_CV_1_5_C2V_1_C3_1\"),\n",
    "        (\"qqHH_CV_1_C2V_1_kl_2_HHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_1_C3_2\"),\n",
    "        (\"qqHH_CV_1_C2V_2_kl_1_HHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_2_C3_1\"),\n",
    "        (\"qqHH_CV_1_C2V_1_kl_0_HHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_1_C3_0\"),\n",
    "        (\"qqHH_CV_0p5_C2V_1_kl_1_HHbbVV\", \"VBF_HHTobbVV_CV_0_5_C2V_1_C3_1\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "samples = OrderedDict(\n",
    "    [\n",
    "        (\"QCD\", \"QCD\"),\n",
    "        (\"TT\", \"TT\"),\n",
    "        (\"ST\", \"ST\"),\n",
    "        (\"V+Jets\", (\"WJets\", \"ZJets\")),\n",
    "        (\"Diboson\", (\"WW\", \"WZ\", \"ZZ\")),\n",
    "        # TODO: break this down into production modes for combination!!!!\n",
    "        # https://gitlab.cern.ch/hh/naming-conventions#single-h-backgrounds\n",
    "        (\"Hbb\", \"*HToBB\"),\n",
    "        (\"HWW\", (\"*HToWW\", \"*HToNonbb\")),\n",
    "        (\"HH\", (\"GluGluToHHTo4B_node_cHHH1_preUL\")),\n",
    "        (\"Data\", \"JetHT\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "samples2 = OrderedDict(\n",
    "    [\n",
    "        (\"QCD\", \"QCD\"),\n",
    "        (\"TT\", \"TT\"),\n",
    "        (\"ST\", \"ST\"),\n",
    "        (\"V+Jets\", (\"WJets\", \"ZJets\")),\n",
    "        (\"Diboson\", (\"WW\", \"WZ\", \"ZZ\")),\n",
    "        # TODO: break this down into production modes for combination!!!!\n",
    "        # https://gitlab.cern.ch/hh/naming-conventions#single-h-backgrounds\n",
    "        (\"Hbb\", \"*HToBB\"),\n",
    "        (\"HWW\", (\"*HToWW\", \"*HToNonbb\")),\n",
    "        (\"VBFHHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_1_C3_1\"),\n",
    "        (\"Data\", \"JetHT\"),\n",
    "        (\"qqHH_CV_1_C2V_0_kl_1_HHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_0_C3_1\"),\n",
    "        (\"qqHH_CV_1p5_C2V_1_kl_1_HHbbVV\", \"VBF_HHTobbVV_CV_1_5_C2V_1_C3_1\"),\n",
    "        (\"qqHH_CV_1_C2V_1_kl_2_HHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_1_C3_2\"),\n",
    "        (\"qqHH_CV_1_C2V_2_kl_1_HHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_2_C3_1\"),\n",
    "        (\"qqHH_CV_1_C2V_1_kl_0_HHbbVV\", \"VBF_HHTobbVV_CV_1_C2V_1_C3_0\"),\n",
    "        (\"qqHH_CV_0p5_C2V_1_kl_1_HHbbVV\", \"VBF_HHTobbVV_CV_0_5_C2V_1_C3_1\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "single_dataset_test = {\"VBFHHbbVV\": \"VBF_HHTobbVV_CV_1_C2V_1_C3_1\"}\n",
    "events_dict = utils.load_samples(\n",
    "    data_dir=\"/home/users/annava/projects/HHbbVV/src/HHbbVV/VBF_binder/data/\",\n",
    "    samples=samples2,\n",
    "    year=\"2017\",\n",
    ")\n",
    "postprocessing.apply_weights(events_dict, year=\"2017\", cutflow=None, qcd_sf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events_dict[\"QCD\"].columns.tolist())\n",
    "print(events_dict.keys())\n",
    "print(events_dict[\"QCD\"][(\"ak8FatJetParticleNetMass\", 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes appropriate scale factor for each signal file\n",
    "def compute_individual_scale_factors(events_dict, S_list):\n",
    "    total_background_weight = 0\n",
    "\n",
    "    # Calculate the total background weight\n",
    "    for dataset, dataframe in events_dict.items():\n",
    "        if dataset not in S_list:\n",
    "            total_weight = np.sum(dataframe[\"finalWeight\"])\n",
    "            total_background_weight += total_weight\n",
    "\n",
    "    # Calculate individual scale factors for each signal dataset\n",
    "    scale_factors = []\n",
    "    for dataset in S_list:\n",
    "        total_signal_weight = np.sum(events_dict[dataset][\"finalWeight\"])\n",
    "\n",
    "        if total_signal_weight == 0:\n",
    "            scale_factor = 0\n",
    "        else:\n",
    "            scale_factor = total_background_weight / total_signal_weight / 10\n",
    "            n = np.floor(np.log10(scale_factor))  # Find the order of magnitude\n",
    "            scale_factor = 10 ** (n + 1) if scale_factor >= 10**n * 5 else 10**n\n",
    "\n",
    "        scale_factors.append(scale_factor)\n",
    "\n",
    "    return scale_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_cut_histogram(\n",
    "    combined_data,\n",
    "    S_list,\n",
    "    signal_sf,\n",
    "    xlabel,\n",
    "    column_name,\n",
    "    xrange,\n",
    "    title=\"Histogram MC signal and background\",\n",
    "    cuts={},\n",
    "):\n",
    "    jj_mass_cut = cuts.get(\"jj_mass_cut\", 500)\n",
    "    jj_eta_cut = cuts.get(\"jj_eta_cut\", 4.0)\n",
    "    j_eta_cut = cuts.get(\"j_eta_cut\", 1.5)\n",
    "    Hbb_Txbb_cut = cuts.get(\"Hbb_Txbb_cut\", 0.8)\n",
    "    HVV_Th4q_cut = cuts.get(\"HVV_Th4q_cut\", 0.0)\n",
    "\n",
    "    signal_data = []\n",
    "    signal_weights = []\n",
    "    background_data = []\n",
    "    background_weights = []\n",
    "    background_labels = []\n",
    "\n",
    "    for dataset, dataframe in combined_data.items():\n",
    "        # Computing variables of interest and masks based on them\n",
    "        Hbb_mask = (\n",
    "            dataframe[(\"ak8FatJetParticleNetMD_Txbb\", 0)]\n",
    "            > dataframe[(\"ak8FatJetParticleNetMD_Txbb\", 1)]\n",
    "        )\n",
    "        Hbb_Txbb_values = np.where(\n",
    "            Hbb_mask,\n",
    "            dataframe[(\"ak8FatJetParticleNetMD_Txbb\", 0)],\n",
    "            dataframe[(\"ak8FatJetParticleNetMD_Txbb\", 1)],\n",
    "        )\n",
    "        HVV_Th4q_values = np.where(\n",
    "            ~Hbb_mask,\n",
    "            dataframe[(\"ak8FatJetParticleNet_Th4q\", 0)],\n",
    "            dataframe[(\"ak8FatJetParticleNet_Th4q\", 1)],\n",
    "        )\n",
    "\n",
    "        mask = (\n",
    "            (dataframe[(\"nGoodMuons\", 0)] == 0)\n",
    "            & (dataframe[(\"nGoodElectrons\", 0)] == 0)\n",
    "            & (dataframe[(\"nGoodVBFJets\", 0)] >= 2)\n",
    "            & (dataframe[(\"nGoodJets\", 0)] == 0)\n",
    "            & (dataframe[(\"vbf_Mass_jj\", 0)] > jj_mass_cut)\n",
    "            & (dataframe[(\"vbf_dEta_jj\", 0)] > jj_eta_cut)\n",
    "            & (np.abs(dataframe[(\"vbfeta\", 0)]) > j_eta_cut)\n",
    "            & (np.abs(dataframe[(\"vbfeta\", 1)]) > j_eta_cut)\n",
    "            & (Hbb_Txbb_values >= Hbb_Txbb_cut)\n",
    "            & (HVV_Th4q_values >= HVV_Th4q_cut)\n",
    "        )\n",
    "        # column_data = df[('bbFatJetPtOverDijetPt', 0)].values * df[('DijetPt', 0)].values\n",
    "        # Mass: ('ak8FatJetMass', 0), ('ak8FatJetMass', 1) or ('ak8FatJetParticleNetMass', 0), ('ak8FatJetParticleNetMass', 1)\n",
    "        df = dataframe[mask]\n",
    "        if column_name == \"mass\":\n",
    "            column_data = np.where(\n",
    "                Hbb_mask,\n",
    "                dataframe[(\"ak8FatJetParticleNetMass\", 0)],\n",
    "                dataframe[(\"ak8FatJetParticleNetMass\", 1)],\n",
    "            )\n",
    "            column_data = column_data[mask]\n",
    "        elif column_name == \"Hbb_Txbb\":\n",
    "            column_data = Hbb_Txbb_values\n",
    "            column_data = column_data[mask]\n",
    "        elif column_name == \"HVV_Th4q\":\n",
    "            column_data = HVV_Th4q_values\n",
    "            column_data = column_data[mask]\n",
    "        else:\n",
    "            column_data = df[column_name].values\n",
    "\n",
    "        total_weight = df[\"finalWeight\"]\n",
    "\n",
    "        if dataset in S_list:\n",
    "            i = S_list.index(dataset)\n",
    "            column_weights = signal_sf[i] * total_weight\n",
    "            signal_data.append(column_data)\n",
    "            signal_weights.append(column_weights)\n",
    "        else:\n",
    "            column_weights = total_weight\n",
    "            background_data.append(column_data)\n",
    "            background_weights.append(column_weights)\n",
    "            background_labels.append(dataset)\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        2, 1, figsize=(12, 10), gridspec_kw={\"height_ratios\": [3, 1]}, sharex=True\n",
    "    )\n",
    "    bins = np.linspace(xrange[0], xrange[1], 100)\n",
    "\n",
    "    ax[0].hist(\n",
    "        background_data,\n",
    "        bins=bins,\n",
    "        weights=background_weights,\n",
    "        stacked=True,\n",
    "        label=background_labels,\n",
    "    )\n",
    "\n",
    "    for data, weight, label, sf in zip(signal_data, signal_weights, S_list, signal_sf):\n",
    "        if np.sum(weight) > 0:\n",
    "            mean_value = np.average(data, weights=weight)\n",
    "            ax[0].axvline(mean_value, color=\"grey\", linestyle=\"--\", linewidth=1)\n",
    "            ax[0].hist(\n",
    "                data,\n",
    "                bins=bins,\n",
    "                weights=weight,\n",
    "                histtype=\"step\",\n",
    "                label=f\"{sf}x {label}\",\n",
    "                linewidth=1.5,\n",
    "            )\n",
    "\n",
    "    ax[0].set_ylabel(\"Expected # events\")\n",
    "    ax[0].set_title(title)\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Calculating and plotting significance for each signal dataset\n",
    "    for data, weight, label, sf in zip(signal_data, signal_weights, S_list, signal_sf):\n",
    "        hist_signal, _ = np.histogram(data, bins=bins, weights=weight)\n",
    "        hist_background, bins = np.histogram(\n",
    "            np.concatenate(background_data), bins=bins, weights=np.concatenate(background_weights)\n",
    "        )\n",
    "        significance = np.where(hist_background > 0, hist_signal / np.sqrt(hist_background) / sf, 0)\n",
    "        # Calculate overall significance and round to two significant figures\n",
    "        overall_significance = (\n",
    "            np.sum(weight) / sf / np.sqrt(np.sum(np.concatenate(background_weights)))\n",
    "        )\n",
    "        n = np.floor(np.log10(overall_significance))\n",
    "        overall_significance = np.round(overall_significance, -int(n - 1))\n",
    "\n",
    "        # Convert to scientific notation\n",
    "        overall_significance_sci = f\"{overall_significance:e}\"\n",
    "        ax[1].step(\n",
    "            bins[:-1],\n",
    "            sf * significance,\n",
    "            where=\"mid\",\n",
    "            label=f\"Significance {sf}x{label}: {overall_significance_sci}\",\n",
    "        )\n",
    "\n",
    "    ax[1].set_xlabel(xlabel)\n",
    "    ax[1].set_ylabel(\"$S / \\sqrt{B}$\")\n",
    "    ax[1].set_title(\"Significance\")\n",
    "    ax[1].legend()\n",
    "\n",
    "    ax[0].set_xlim(xrange)\n",
    "    ax[1].set_xlim(xrange)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print out the individual significance\n",
    "    significances = []\n",
    "    for data, weight, label, sf in zip(signal_data, signal_weights, S_list, signal_sf):\n",
    "        S = np.sum(weight) / sf\n",
    "        B = np.sum(np.concatenate(background_weights))\n",
    "        print(f\"Significance for {label}: {S/np.sqrt(B)} {S} {B}\")\n",
    "        significances.append(S / np.sqrt(B))\n",
    "\n",
    "    return significances\n",
    "\n",
    "\n",
    "S_list = [\"VBFHHbbVV\", \"qqHH_CV_1_C2V_0_kl_1_HHbbVV\", \"qqHH_CV_1_C2V_2_kl_1_HHbbVV\"]\n",
    "scale_factors = compute_individual_scale_factors(\n",
    "    events_dict, S_list\n",
    ")  # notice that scale factor is based on pre-cuts (thus we can still compare visually)\n",
    "xlabel = \"Hbb ParNet $M$ (GeV)\"\n",
    "cuts = {\n",
    "    \"jj_mass_cut\": 0,\n",
    "    \"jj_eta_cut\": 3.5,\n",
    "    \"j_eta_cut\": 1,\n",
    "    \"Hbb_Txbb_cut\": 0.95,\n",
    "    \"HVV_Th4q_cut\": 0.9,\n",
    "}\n",
    "cuts = {\"jj_mass_cut\": 0, \"jj_eta_cut\": 0, \"j_eta_cut\": 0, \"Hbb_Txbb_cut\": 0, \"HVV_Th4q_cut\": 0}\n",
    "plot_cut_histogram(\n",
    "    events_dict,\n",
    "    S_list=S_list,\n",
    "    signal_sf=scale_factors,\n",
    "    xlabel=\"HVV_Th4q\",\n",
    "    column_name=\"mass\",\n",
    "    xrange=[0, 300],\n",
    "    cuts=cuts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_list = [\"VBFHHbbVV\", \"qqHH_CV_1_C2V_0_kl_1_HHbbVV\", \"qqHH_CV_1_C2V_2_kl_1_HHbbVV\"]\n",
    "xlabel = \"VBF-Jet $p_T$ (GeV)\"\n",
    "xlabel = \"Hbb Jet $p_T$ (GeV)\"\n",
    "xlabel = \"Hbb ParNet $M$ (GeV)\"\n",
    "col_name = (\"vbfpt\", 0)\n",
    "scale_factors = compute_individual_scale_factors(\n",
    "    events_dict, S_list\n",
    ")  # notice that scale factor is based on pre-cuts (thus we can still compare visually)\n",
    "cuts = {\n",
    "    \"jj_mass_cut\": 500,\n",
    "    \"jj_eta_cut\": 4.0,\n",
    "    \"j_eta_cut\": 1.5,\n",
    "    \"Hbb_Txbb_cut\": 0.95,\n",
    "    \"HVV_Th4q_cut\": 0.6,\n",
    "}\n",
    "# plot_cut_histogram(events_dict, S_list=S_list, signal_sf=scale_factors, xlabel=xlabel, column_name=col_name,xrange = [0,300],cuts= cuts)\n",
    "cuts = {\n",
    "    \"jj_mass_cut\": 500,\n",
    "    \"jj_eta_cut\": 6.0,\n",
    "    \"j_eta_cut\": 2.5,\n",
    "    \"Hbb_Txbb_cut\": 0.95,\n",
    "    \"HVV_Th4q_cut\": 0.6,\n",
    "}\n",
    "\n",
    "# plot_cut_histogram(events_dict, S_list=S_list, signal_sf=scale_factors, xlabel=xlabel, column_name=col_name,xrange = [0,300],cuts= cuts)\n",
    "cuts = {\"jj_mass_cut\": 0, \"jj_eta_cut\": 0, \"j_eta_cut\": 0, \"Hbb_Txbb_cut\": 0.0, \"HVV_Th4q_cut\": 0.0}\n",
    "\n",
    "\n",
    "# plot different cutting variables distributions before cuts to find reasonable values\n",
    "# (jj_mass_cut = 0 (+ 500) j_eta_cut = 1 (pm 1) jj_eta_cut = 3.5 (pm 1.5) Hbb_Txbb = 0.95 (+ 0.045) Hbb_Txbb = 0.9 (pm 0.09 ) # test out a grid of these in condor_outputs_tests notebook\n",
    "plot_cut_histogram(\n",
    "    events_dict,\n",
    "    S_list=S_list,\n",
    "    signal_sf=scale_factors,\n",
    "    xlabel=\"(vbf_Mass_jj, 0)\",\n",
    "    column_name=(\"vbf_Mass_jj\", 0),\n",
    "    xrange=[0, 1000],\n",
    "    cuts=cuts,\n",
    ")\n",
    "plot_cut_histogram(\n",
    "    events_dict,\n",
    "    S_list=S_list,\n",
    "    signal_sf=scale_factors,\n",
    "    xlabel=\"(vbfeta, 0)\",\n",
    "    column_name=(\"vbfeta\", 0),\n",
    "    xrange=[-4.5, 4.5],\n",
    "    cuts=cuts,\n",
    ")\n",
    "plot_cut_histogram(\n",
    "    events_dict,\n",
    "    S_list=S_list,\n",
    "    signal_sf=scale_factors,\n",
    "    xlabel=\"(vbf_dEta_jj, 0)\",\n",
    "    column_name=(\"vbf_dEta_jj\", 0),\n",
    "    xrange=[0, 8],\n",
    "    cuts=cuts,\n",
    ")\n",
    "plot_cut_histogram(\n",
    "    events_dict,\n",
    "    S_list=S_list,\n",
    "    signal_sf=scale_factors,\n",
    "    xlabel=\"Hbb_Txbb\",\n",
    "    column_name=\"Hbb_Txbb\",\n",
    "    xrange=[0.8, 1],\n",
    "    cuts=cuts,\n",
    ")\n",
    "plot_cut_histogram(\n",
    "    events_dict,\n",
    "    S_list=S_list,\n",
    "    signal_sf=scale_factors,\n",
    "    xlabel=\"HVV_Th4q\",\n",
    "    column_name=\"HVV_Th4q\",\n",
    "    xrange=[0.6, 1],\n",
    "    cuts=cuts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming plot_cut_histogram function is defined as before, with the additional 'title' and 'cuts' parameters\n",
    "# def plot_cut_histogram(combined_data, S_list, signal_sf, xlabel, column_name, xrange, title='Histogram MC signal and background', cuts={}):\n",
    "\n",
    "# Dummy combined_data, S_list, signal_sf, xlabel, column_name, and xrange for the example\n",
    "S_list = [\"VBFHHbbVV\", \"qqHH_CV_1_C2V_0_kl_1_HHbbVV\", \"qqHH_CV_1_C2V_2_kl_1_HHbbVV\"]\n",
    "xlabel = \"Hbb ParNet $M$ (GeV)\"\n",
    "column_name = (\"vbfpt\", 0)\n",
    "signal_sf = compute_individual_scale_factors(events_dict, S_list)  #\n",
    "xrange = [0, 300]  # Replace with your actual x-range\n",
    "\n",
    "# Define the cut parameters and their linspace ranges\n",
    "cut_parameters = {\n",
    "    \"jj_mass_cut\": np.linspace(0, 600, 5),\n",
    "    \"jj_eta_cut\": np.linspace(0, 5.0, 5),\n",
    "    \"j_eta_cut\": np.linspace(0, 4.0, 5),\n",
    "    \"Hbb_Txbb_cut\": np.linspace(0, 0.99, 5),\n",
    "    \"HVV_Th4q_cut\": np.linspace(0, 0.99, 5),\n",
    "}\n",
    "\n",
    "# Loop through each cut parameter and its linspace range\n",
    "for param, values in cut_parameters.items():\n",
    "    for value in values:\n",
    "        # Set only the current cut parameter to the linspace value, others to zero\n",
    "        cuts = {k: 0 for k in cut_parameters}\n",
    "        cuts[param] = value\n",
    "\n",
    "        # Call the plot function\n",
    "        title = f\"Histogram MC Signal and Background, Varying {param} at {value}\"\n",
    "        plot_cut_histogram(events_dict, S_list, signal_sf, xlabel, column_name, xrange, title, cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cut parameters and their linspace ranges\n",
    "cut_parameters = {\n",
    "    \"jj_mass_cut\": np.linspace(0, 1000, 20),\n",
    "    \"jj_eta_cut\": np.linspace(0, 8.0, 20),\n",
    "    \"j_eta_cut\": np.linspace(0, 4.0, 10),\n",
    "    \"Hbb_Txbb_cut\": np.linspace(0, 0.99, 20) ** 0.5,\n",
    "    \"HVV_Th4q_cut\": np.linspace(0, 0.99, 20) ** 0.5,\n",
    "}\n",
    "\n",
    "# To store the significances\n",
    "all_significances = {}\n",
    "\n",
    "# Loop through each cut parameter and its linspace range\n",
    "for param, values in cut_parameters.items():\n",
    "    all_significances[param] = {}\n",
    "\n",
    "    for signal in S_list:\n",
    "        all_significances[param][signal] = []\n",
    "\n",
    "    for value in values:\n",
    "        # Set only the current cut parameter to the linspace value, others to zero\n",
    "        cuts = {k: 0 for k in cut_parameters.keys()}\n",
    "        cuts[param] = value\n",
    "\n",
    "        # Call the plot function and get significances\n",
    "        title = f\"Histogram MC Signal and Background, Varying {param} at {value}\"\n",
    "        significances = plot_cut_histogram(\n",
    "            events_dict, S_list, signal_sf, xlabel, column_name, xrange, title, cuts\n",
    "        )\n",
    "\n",
    "        # Store the significances\n",
    "        for signal, sig in zip(S_list, significances):\n",
    "            all_significances[param][signal].append(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to round to the nearest power of 10\n",
    "def round_to_nearest_power_of_10(x):\n",
    "    n = np.floor(np.log10(x))  # Find the order of magnitude\n",
    "    return 10 ** (n + 1) if x >= 10**n * 5 else 10**n\n",
    "\n",
    "\n",
    "# Assuming the original scale factors are in signal_sf\n",
    "min_sf = min(signal_sf)\n",
    "adjusted_sf = [round_to_nearest_power_of_10(sf / min_sf) for sf in signal_sf]\n",
    "\n",
    "# Create plots\n",
    "for param, sig_dict in all_significances.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, (signal, sig_values) in enumerate(sig_dict.items()):\n",
    "        # Scale the significances using the appropriate adjusted scale factor\n",
    "        sf = adjusted_sf[i]  # Using the adjusted scale factors\n",
    "        scaled_sig_values = [sig * sf for sig in sig_values]\n",
    "\n",
    "        # Check to make sure the dimensions match before plotting\n",
    "        if len(cut_parameters[param]) != len(scaled_sig_values):\n",
    "            print(f\"Dimension mismatch for {signal}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        plt.plot(\n",
    "            cut_parameters[param],\n",
    "            scaled_sig_values,\n",
    "            label=f\"Scaled significance of {signal} (Scale factor: {sf})\",\n",
    "        )\n",
    "\n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel(\"Scaled Significance\")\n",
    "    plt.title(f\"Scaled Significance vs {param}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
