{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import awkward as ak\n",
    "from coffea import nanoevents\n",
    "from coffea.nanoevents.methods.base import NanoEventsArray\n",
    "from coffea.analysis_tools import Weights, PackedSelection\n",
    "from coffea.nanoevents.methods import nanoaod\n",
    "from coffea.nanoevents.methods import vector\n",
    "from coffea.lookup_tools.dense_lookup import dense_lookup\n",
    "\n",
    "ak.behavior.update(vector.behavior)\n",
    "\n",
    "import pickle, json, gzip\n",
    "import numpy as np\n",
    "\n",
    "from typing import Optional, List, Dict\n",
    "from copy import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "from matplotlib import colors\n",
    "\n",
    "from tqdm import tqdm\n",
    "# import fastjet\n",
    "\n",
    "# import jetnet\n",
    "\n",
    "import os\n",
    "\n",
    "# import corrections\n",
    "import correctionlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = \"../../../plots/ScaleFactors/Nov23\"\n",
    "_ = os.system(f\"mkdir -p {plot_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = nanoevents.NanoEventsFactory.from_root(\n",
    "    # \"/eos/uscms/store/user/lpcpfnano/cmantill/v2_3/2017/HH_gen/GluGluToHHTobbVV_node_cHHH1_TuneCP5_13TeV-powheg-pythia8/GluGluToHHTobbVV_node_cHHH1/221017_221918/0000/nano_mc2017_100.root\",\n",
    "    # \"/eos/uscms/store/user/lpcpfnano/drankin/v2_2/2017/TTbar/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/TTToSemiLeptonic_ext1/211112_132937/0000/nano_mc2017_100.root\",\n",
    "    \"../../../../data/nano_files/v2_3/2018/TTToSemiLeptonic/nano_mc2018_101.root\",\n",
    "    # \"root://cmsxrootd.fnal.gov///store/user/lpcpfnano/cmantill/v2_3/2018/TTbar/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/TTToSemiLeptonic/220808_151244/0000/nano_mc2018_1-196.root\",\n",
    "    schemaclass=nanoevents.NanoAODSchema,\n",
    ").events()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosted Top Pre-selection\n",
    "\n",
    "Based on selection in https://indico.cern.ch/event/1208247/#10-lund-plane-reweighting-for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_val(\n",
    "    arr: ak.Array,\n",
    "    target: int,\n",
    "    value: float,\n",
    "    axis: int = 0,\n",
    "    to_numpy: bool = True,\n",
    "    clip: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    pads awkward array up to ``target`` index along axis ``axis`` with value ``value``,\n",
    "    optionally converts to numpy array\n",
    "    \"\"\"\n",
    "    ret = ak.fill_none(ak.pad_none(arr, target, axis=axis, clip=clip), value, axis=axis)\n",
    "    return ret.to_numpy() if to_numpy else ret\n",
    "\n",
    "\n",
    "def add_selection(\n",
    "    name: str,\n",
    "    sel: np.ndarray,\n",
    "    selection: PackedSelection,\n",
    "    cutflow: dict = None,\n",
    "    isData: bool = False,\n",
    "    signGenWeights: ak.Array = None,\n",
    "):\n",
    "    \"\"\"adds selection to PackedSelection object and the cutflow dictionary\"\"\"\n",
    "    selection.add(name, sel)\n",
    "    if cutflow is not None:\n",
    "        cutflow[name] = (\n",
    "            np.sum(selection.all(*selection.names))\n",
    "            if isData\n",
    "            # add up sign of genWeights for MC\n",
    "            else np.sum(signGenWeights[selection.all(*selection.names)])\n",
    "        )\n",
    "\n",
    "\n",
    "presel_events = events\n",
    "# presel_events = events[preselection_cut]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isData = False\n",
    "signGenWeights = None if isData else np.sign(presel_events[\"genWeight\"])\n",
    "n_events = len(presel_events) if isData else int(np.sum(signGenWeights))\n",
    "selection = PackedSelection()\n",
    "\n",
    "cutflow = {}\n",
    "cutflow[\"presel\"] = len(presel_events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MU_PDGID = 13\n",
    "\n",
    "muon_selection = {\n",
    "    \"Id\": \"tight\",\n",
    "    \"pt\": 60,\n",
    "    \"eta\": 2.4,\n",
    "    \"miniPFRelIso_all\": 0.1,\n",
    "    \"dxy\": 0.2,\n",
    "    \"count\": 1,\n",
    "    \"delta_trigObj\": 0.15,\n",
    "}\n",
    "\n",
    "ak8_jet_selection = {\n",
    "    \"pt\": 200,\n",
    "    \"msd\": [50, 250],\n",
    "    \"eta\": 2.5,\n",
    "    \"delta_phi_muon\": 2,\n",
    "    \"jetId\": nanoaod.FatJet.TIGHT,\n",
    "}\n",
    "\n",
    "btagWPs = {\"2016APV\": 0.6001, \"2016\": 0.5847, \"2017\": 0.4506, \"2018\": 0.4168}\n",
    "\n",
    "ak4_jet_selection = {\n",
    "    \"pt\": 25,\n",
    "    \"eta\": 2.4,\n",
    "    \"delta_phi_muon\": 2,\n",
    "    \"jetId\": nanoaod.Jet.TIGHT,\n",
    "    \"puId\": 4,  # loose pileup ID\n",
    "    \"btagWP\": btagWPs,\n",
    "}\n",
    "\n",
    "met_selection = {\"pt\": 50}\n",
    "\n",
    "lepW_selection = {\"pt\": 100}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muon = events.Muon\n",
    "# 1024 - Mu50 trigger (https://algomez.web.cern.ch/algomez/testWeb/PFnano_content_v02.html#TrigObj)\n",
    "trigObj_muon = events.TrigObj[(events.TrigObj.id == MU_PDGID) * (events.TrigObj.filterBits >= 1024)]\n",
    "\n",
    "muon_selector = (\n",
    "    (muon[f\"{muon_selection['Id']}Id\"])\n",
    "    * (muon.pt > muon_selection[\"pt\"])\n",
    "    * (np.abs(muon.eta) < muon_selection[\"eta\"])\n",
    "    * (muon.miniPFRelIso_all < muon_selection[\"miniPFRelIso_all\"])\n",
    "    * (np.abs(muon.dxy) < muon_selection[\"dxy\"])\n",
    ")\n",
    "\n",
    "muon_selector = muon_selector * (\n",
    "    ak.count(events.Muon.pt[muon_selector], axis=1) == muon_selection[\"count\"]\n",
    ")\n",
    "muon = ak.pad_none(muon[muon_selector], 1, axis=1)[:, 0]\n",
    "\n",
    "muon_selector = ak.any(muon_selector, axis=1)\n",
    "muon_selector = muon_selector * ak.any(\n",
    "    np.abs(muon.delta_r(trigObj_muon)) <= muon_selection[\"delta_trigObj\"],\n",
    "    axis=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# met\n",
    "met = events.MET\n",
    "met_selection = met.pt >= met_selection[\"pt\"]\n",
    "\n",
    "# metfilters = np.ones(len(events), dtype=\"bool\")\n",
    "# metfilterkey = \"data\" if isData else \"mc\"\n",
    "# for mf in self.metfilters[year][metfilterkey]:\n",
    "#     if mf in events.Flag.fields:\n",
    "#         metfilters = metfilters & events.Flag[mf]\n",
    "\n",
    "add_selection(\"met\", met_selection * metfilters, *selection_args)\n",
    "\n",
    "# leptonic W selection\n",
    "# add_selection(\"lepW\", (met + muon).pt >= self.lepW_selection[\"pt\"], *selection_args)\n",
    "add_selection(\"lepW\", met.pt + muon.pt >= 100, *selection_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fatjets = events.FatJet  # CHANGE TO JEC JETS\n",
    "fatjets = corrections.get_jec_jets(events, \"2018\")\n",
    "num_jets = 1\n",
    "\n",
    "fatjet_selector = (\n",
    "    (fatjets.pt > ak8_jet_selection[\"pt\"])\n",
    "    # * (fatjets.msoftdrop > ak8_jet_selection[\"msd\"][0])\n",
    "    # * (fatjets.msoftdrop < ak8_jet_selection[\"msd\"][1])\n",
    "    * (np.abs(fatjets.eta) < ak8_jet_selection[\"eta\"])\n",
    "    # * (np.abs(fatjets.delta_phi(muon)) > ak8_jet_selection[\"delta_phi_muon\"])\n",
    "    * (fatjets.jetId > ak8_jet_selection[\"jetId\"])\n",
    ")\n",
    "\n",
    "leading_fatjets = ak.pad_none(fatjets[fatjet_selector], num_jets, axis=1)[:, :num_jets]\n",
    "fatjet_idx = ak.argmax(fatjet_selector, axis=1)  # gets first index which is true\n",
    "fatjet_selector = ak.any(fatjet_selector, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hem_region = {\"eta\": [-3.2, -1.3], \"phi\": [-0.87, -1.57]}\n",
    "hem_region_selector = (\n",
    "    (fatjets.eta > hem_region[\"eta\"][0])\n",
    "    * (fatjets.eta < hem_region[\"eta\"][1])\n",
    "    * (fatjets.phi > hem_region[\"phi\"][0])\n",
    "    * (fatjets.phi < hem_region[\"phi\"][1])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak4_jets = events.Jet\n",
    "# ak4_jets = ak.flatten(\n",
    "#     ak.pad_none(events.Jet[ak.argsort(events.Jet.btagDeepB, axis=1)[:, -1:]], 1, axis=1)\n",
    "# )\n",
    "\n",
    "ak4_jet_selector = (\n",
    "    (ak4_jets.jetId > ak4_jet_selection[\"jetId\"])\n",
    "    * (ak4_jets.puId >= ak4_jet_selection[\"puId\"])\n",
    "    * (ak4_jets.pt > ak4_jet_selection[\"pt\"])\n",
    "    * (np.abs(ak4_jets.eta) < ak4_jet_selection[\"eta\"])\n",
    "    * (np.abs(ak4_jets.delta_phi(muon)) < ak4_jet_selection[\"delta_phi_muon\"])\n",
    "    * (ak4_jets.btagDeepB > ak4_jet_selection[\"btagWP\"][\"2018\"])\n",
    ")\n",
    "\n",
    "ak4_jet_selector = ak.any(ak4_jet_selector, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = ak.fill_none(muon_selector * fatjet_selector * ak4_jet_selector, False)\n",
    "presel_events = events[select]\n",
    "leading_fatjets = leading_fatjets[select]\n",
    "fatjet_idx = fatjet_idx[select]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, gzip\n",
    "\n",
    "with gzip.open(corrections.get_pog_json(\"jec\", \"2017\"), \"r\") as fin:\n",
    "    jec = json.loads(fin.read().decode(\"utf-8\"))\n",
    "\n",
    "for corr in jec[\"corrections\"]:\n",
    "    print(corr[\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"../data/jec_compiled.pkl.gz\", \"rb\") as filehandler:\n",
    "    jmestuff = pickle.load(filehandler)\n",
    "\n",
    "jmestuff[\"jet_factory\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_PDGID = 1\n",
    "b_PDGID = 5\n",
    "g_PDGID = 21\n",
    "TOP_PDGID = 6\n",
    "\n",
    "ELE_PDGID = 11\n",
    "vELE_PDGID = 12\n",
    "MU_PDGID = 13\n",
    "vMU_PDGID = 14\n",
    "TAU_PDGID = 15\n",
    "vTAU_PDGID = 16\n",
    "\n",
    "Z_PDGID = 23\n",
    "W_PDGID = 24\n",
    "HIGGS_PDGID = 25\n",
    "\n",
    "b_PDGIDS = [511, 521, 523]\n",
    "\n",
    "GRAV_PDGID = 39\n",
    "\n",
    "GEN_FLAGS = [\"fromHardProcess\", \"isLastCopy\"]\n",
    "\n",
    "FILL_NONE_VALUE = -99999\n",
    "\n",
    "\n",
    "skim_vars = {\n",
    "    \"eta\": \"eta\",\n",
    "    \"phi\": \"phi\",\n",
    "    \"mass\": \"mass\",\n",
    "    \"pt\": \"pt\",\n",
    "}\n",
    "\n",
    "# finding the two gen tops\n",
    "presel_events = events[select]\n",
    "tops = presel_events.GenPart[\n",
    "    (abs(presel_events.GenPart.pdgId) == TOP_PDGID) * presel_events.GenPart.hasFlags(GEN_FLAGS)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaR = 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops_children = tops.distinctChildren\n",
    "tops_children = tops_children[tops_children.hasFlags(GEN_FLAGS)]\n",
    "ws = ak.flatten(tops_children[np.abs(tops_children.pdgId) == W_PDGID], axis=2)\n",
    "had_top_sel = np.all(np.abs(ws.children.pdgId) <= 5, axis=2)\n",
    "had_ws = ak.flatten(ws[had_top_sel])\n",
    "had_tops = ak.flatten(tops[had_top_sel])\n",
    "had_top_children = ak.flatten(tops_children[had_top_sel], axis=1)\n",
    "had_bs = had_top_children[np.abs(had_top_children.pdgId) == 5]\n",
    "# add_selection(\n",
    "#     \"hadronic bs\", np.any(had_bs.pdgId, axis=1), selection, cutflow, isData, signGenWeights\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "had_w_jet_match = ak.fill_none(\n",
    "    ak.all(had_ws.children.delta_r(leading_fatjets[:, 0]) < deltaR, axis=1), False\n",
    ")\n",
    "had_b_jet_match = ak.flatten(\n",
    "    pad_val(had_bs.delta_r(leading_fatjets[:, 0]) < deltaR, 1, False, axis=1, to_numpy=False)\n",
    ")\n",
    "merged_top_jet_match = had_w_jet_match * had_b_jet_match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "had_bs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "had_ws_children = had_ws.children\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_match_dict = {\n",
    "    \"top_matched\": had_w_jet_match * had_b_jet_match,\n",
    "    \"w_matched\": had_w_jet_match * ~had_b_jet_match,\n",
    "    \"unmatched\": ~had_w_jet_match,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering and Lund plane splittings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_top_events = presel_events[merged_top_jet_match]\n",
    "had_top_jets = merged_top_events.FatJet[:, 0]\n",
    "\n",
    "merged_ak8_pfcands = merged_top_events.FatJetPFCands\n",
    "merged_ak8_pfcands = merged_ak8_pfcands[\n",
    "    merged_ak8_pfcands.jetIdx == fatjet_idx[merged_top_jet_match]\n",
    "]\n",
    "merged_pfcands = merged_top_events.PFCands[merged_ak8_pfcands.pFCandsIdx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_pfcands_vector_ptetaphi = ak.Array(\n",
    "    [\n",
    "        [{kin_key: cand[kin_key] for kin_key in skim_vars} for cand in event_cands]\n",
    "        for event_cands in merged_pfcands\n",
    "    ],\n",
    "    with_name=\"PtEtaPhiMLorentzVector\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jet definitions\n",
    "dR = 0.8\n",
    "cadef = fastjet.JetDefinition(fastjet.cambridge_algorithm, dR)\n",
    "ktdef = fastjet.JetDefinition(fastjet.kt_algorithm, dR)\n",
    "\n",
    "num_prongs = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster first with kT\n",
    "kt_clustering = fastjet.ClusterSequence(merged_pfcands_vector_ptetaphi, ktdef)\n",
    "kt_subjets = kt_clustering.exclusive_jets(num_prongs)\n",
    "kt_subjets_pt = np.sqrt(kt_subjets.px**2 + kt_subjets.py**2)\n",
    "kt_subjet_consts = kt_clustering.exclusive_jets_constituents(3)\n",
    "\n",
    "# then re-cluster with CA\n",
    "# won't need to flatten once https://github.com/scikit-hep/fastjet/pull/145 is released\n",
    "ca_clustering = fastjet.ClusterSequence(ak.flatten(kt_subjet_consts, axis=1), cadef)\n",
    "lds = ak.flatten(ca_clustering.exclusive_jets_lund_declusterings(1), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kt_subjets_vec = ak.zip(\n",
    "    {\"x\": kt_subjets.px, \"y\": kt_subjets.py, \"z\": kt_subjets.pz, \"t\": kt_subjets.E},\n",
    "    with_name=\"LorentzVector\",\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subjet matching and pT extrapolation uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_dR = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_quarks = ak.concatenate(\n",
    "    [had_bs[merged_top_jet_match][:, :1], had_ws_children[merged_top_jet_match][:, :2]], axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_quarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_matched = []\n",
    "sj_matched_idx = []\n",
    "\n",
    "for i in range(num_prongs):\n",
    "    sj_q_dr = kt_subjets_vec.delta_r(gen_quarks[:, i])\n",
    "    sj_matched.append(ak.min(sj_q_dr, axis=1) <= matching_dR)\n",
    "    sj_matched_idx.append(ak.argmin(sj_q_dr, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_matched = np.array(sj_matched).T\n",
    "sj_matched_idx = np.array(sj_matched_idx).T\n",
    "\n",
    "sj_matched_idx_mask = np.copy(sj_matched_idx)\n",
    "sj_matched_idx_mask[~sj_matched] = -1\n",
    "double_matched_event = np.any(\n",
    "    [np.sum(sj_matched_idx_mask == i, axis=1) > 1 for i in range(3)], axis=0\n",
    ").astype(int)\n",
    "unmatched_quarks = np.sum(~sj_matched, axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calc SFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = uproot.open(\"../corrections/ratio_ktjets_nov7.root\")\n",
    "\n",
    "# 3D histogram: [subjet_pt, ln(0.8/Delta), ln(kT/GeV)]\n",
    "ratio_nom = f[\"ratio_nom\"].to_numpy()\n",
    "ratio_nom_errs = f[\"ratio_nom\"].errors()\n",
    "ratio_nom_edges = ratio_nom[1:]\n",
    "ratio_nom = ratio_nom[0]\n",
    "\n",
    "zero_vals = ratio_nom == 0\n",
    "ratio_nom[zero_vals] = 1\n",
    "ratio_nom_errs[zero_vals] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(ratio_nom[5].T[::-1], extent=[-1, 8, -5, 6.9], cmap=\"turbo\")\n",
    "plt.xlabel(r\"ln$(0.8/\\Delta)$\")\n",
    "plt.ylabel(r\"ln$(k_T/GeV)$\")\n",
    "_ = plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sf_toys = 100\n",
    "np.random.seed(42)\n",
    "rand_noise = np.random.normal(size=[n_sf_toys, *ratio_nom.shape])\n",
    "\n",
    "# produces array of shape ``[n_sf_toys, subjet_pt bins, ln(0.8/Delta) bins, ln(kT/GeV) bins]``\n",
    "ratio_nom_smeared = ratio_nom + (ratio_nom_errs * rand_noise)\n",
    "ratio_smeared_lookups = [\n",
    "    dense_lookup(ratio_nom_smeared[i], ratio_nom_edges) for i in range(n_sf_toys)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = (ratio_nom + ratio_nom_errs) / ratio_nom\n",
    "ratio_nom * np.power(kappa, rand_noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save offsets to recover awkward structure later\n",
    "ld_offsets = lds.kt.layout.offsets\n",
    "flat_logD = np.log(0.8 / ak.flatten(lds).Delta).to_numpy()\n",
    "flat_logkt = np.log(ak.flatten(lds).kt).to_numpy()\n",
    "# repeat subjet pt for each lund declustering\n",
    "flat_subjet_pt = np.repeat(ak.flatten(kt_subjets_pt), ak.count(lds.kt, axis=1)).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_vals = []\n",
    "# could be parallelised but not sure if memory / time trade-off is worth it\n",
    "for i, ratio_nom_lookup in enumerate(ratio_smeared_lookups):\n",
    "    ratio_nom_vals = ratio_nom_lookup(flat_subjet_pt, flat_logD, flat_logkt)\n",
    "    reshaped_ratio_nom_vals = ak.Array(\n",
    "        ak.layout.ListOffsetArray64(ld_offsets, ak.layout.NumpyArray(ratio_nom_vals))\n",
    "    )\n",
    "    sf_vals.append(\n",
    "        np.prod(ak.prod(reshaped_ratio_nom_vals, axis=1).to_numpy().reshape(-1, num_prongs), axis=1)\n",
    "    )\n",
    "\n",
    "sf_vals = np.array(sf_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old way of uncertainty calculation (not taking into account intra-jet correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save offsets to recover awkward structure later\n",
    "ld_offsets = lds.kt.layout.offsets\n",
    "flat_logD = np.log(0.8 / ak.flatten(lds).Delta).to_numpy()\n",
    "flat_logkt = np.log(ak.flatten(lds).kt).to_numpy()\n",
    "# repeat subjet pt for each lund declustering\n",
    "flat_subjet_pt = np.repeat(ak.flatten(kt_subjets_pt), ak.count(lds.kt, axis=1)).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_nom_vals = ratio_nom_lookup(flat_subjet_pt, flat_logD, flat_logkt)\n",
    "ratio_nom_rel_errs = np.nan_to_num(\n",
    "    (ratio_nom_errs_lookup(flat_subjet_pt, flat_logD, flat_logkt) / ratio_nom_vals) ** 2\n",
    ")\n",
    "\n",
    "reshaped_ratio_nom_vals = ak.Array(\n",
    "    ak.layout.ListOffsetArray64(ld_offsets, ak.layout.NumpyArray(ratio_nom_vals))\n",
    ")\n",
    "reshaped_ratio_nom_rel_errs = ak.Array(\n",
    "    ak.layout.ListOffsetArray64(ld_offsets, ak.layout.NumpyArray(ratio_nom_rel_errs))\n",
    ")\n",
    "\n",
    "sf_nom_vals = np.prod(\n",
    "    ak.prod(reshaped_ratio_nom_vals, axis=1).to_numpy().reshape(-1, num_prongs), axis=1\n",
    ")\n",
    "sf_nom_errs = (\n",
    "    np.sqrt(\n",
    "        np.sum(\n",
    "            ak.sum(reshaped_ratio_nom_rel_errs, axis=1).to_numpy().reshape(-1, num_prongs), axis=1\n",
    "        )\n",
    "    )\n",
    "    * sf_nom_vals\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_nom_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_nom_errs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ld_indices(vals, edges):\n",
    "    indices = []\n",
    "\n",
    "    for val, edge in zip(vals, edges):\n",
    "        indices.append(\n",
    "            np.clip(\n",
    "                np.searchsorted(edge, val, side=\"right\") - 1,\n",
    "                0,\n",
    "                len(edge) - 2,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lund plane bins\n",
    "inds = get_ld_indices((flat_subjet_pt, flat_logD, flat_logkt), ratio_nom_edges)\n",
    "# convert 3D indices to single scalar\n",
    "scalar_inds = np.ravel_multi_index(inds, ratio_nom.shape)\n",
    "reshaped_inds = ak.Array(ak.layout.ListOffsetArray64(ld_offsets, ak.layout.NumpyArray(scalar_inds)))\n",
    "# reshaped_inds = pad_val(reshaped_inds, 40, -1, axis=1, clip=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = 0\n",
    "for row in reshaped_inds:\n",
    "    _, counts = np.unique(row, return_counts=True)\n",
    "    dups += np.sum(counts - 1)\n",
    "\n",
    "print(f\"Fraction of duplicate splittings: {dups / len(flat_logD):.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15adc7883e707560d0d9727709639b8fe3f3cff1f197d2d643742923ff23a29c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
