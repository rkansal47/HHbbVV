{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import awkward as ak\n",
    "from coffea import nanoevents\n",
    "from coffea.nanoevents.methods.base import NanoEventsArray\n",
    "from coffea.analysis_tools import Weights, PackedSelection\n",
    "from coffea.nanoevents.methods import nanoaod\n",
    "from coffea.nanoevents.methods import vector\n",
    "from coffea.lookup_tools.dense_lookup import dense_lookup\n",
    "\n",
    "ak.behavior.update(vector.behavior)\n",
    "\n",
    "import pickle, json, gzip\n",
    "import numpy as np\n",
    "\n",
    "from typing import Optional, List, Dict\n",
    "from copy import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "from matplotlib import colors\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import fastjet\n",
    "\n",
    "# import jetnet\n",
    "\n",
    "import os\n",
    "\n",
    "import corrections\n",
    "import correctionlib\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = \"../../../plots/ScaleFactors/Nov23\"\n",
    "_ = os.system(f\"mkdir -p {plot_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = nanoevents.NanoEventsFactory.from_root(\n",
    "    # \"/eos/uscms/store/user/lpcpfnano/cmantill/v2_3/2017/HH_gen/GluGluToHHTobbVV_node_cHHH1_TuneCP5_13TeV-powheg-pythia8/GluGluToHHTobbVV_node_cHHH1/221017_221918/0000/nano_mc2017_100.root\",\n",
    "    \"/eos/uscms/store/user/lpcpfnano/drankin/v2_2/2017/TTbar/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/TTToSemiLeptonic_ext1/211112_132937/0000/nano_mc2017_100.root\",\n",
    "    # \"../../../../data/nano_files/v2_3/2018/TTToSemiLeptonic/nano_mc2018_101.root\",\n",
    "    # \"../../../../data/nano_files/v2_3/2018/QCD_HT700to1000/nano_mc2018_10.root\",\n",
    "    # \"root://cmsxrootd.fnal.gov///store/user/lpcpfnano/cmantill/v2_3/2018/TTbar/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/TTToSemiLeptonic/220808_151244/0000/nano_mc2018_1-196.root\",\n",
    "    schemaclass=nanoevents.NanoAODSchema,\n",
    ").events()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosted Top Pre-selection\n",
    "\n",
    "Based on selection in https://indico.cern.ch/event/1208247/#10-lund-plane-reweighting-for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_val(\n",
    "    arr: ak.Array,\n",
    "    target: int,\n",
    "    value: float,\n",
    "    axis: int = 0,\n",
    "    to_numpy: bool = True,\n",
    "    clip: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    pads awkward array up to ``target`` index along axis ``axis`` with value ``value``,\n",
    "    optionally converts to numpy array\n",
    "    \"\"\"\n",
    "    ret = ak.fill_none(ak.pad_none(arr, target, axis=axis, clip=clip), value, axis=axis)\n",
    "    return ret.to_numpy() if to_numpy else ret\n",
    "\n",
    "\n",
    "def add_selection(\n",
    "    name: str,\n",
    "    sel: np.ndarray,\n",
    "    selection: PackedSelection,\n",
    "    cutflow: dict = None,\n",
    "    isData: bool = False,\n",
    "    signGenWeights: ak.Array = None,\n",
    "):\n",
    "    \"\"\"adds selection to PackedSelection object and the cutflow dictionary\"\"\"\n",
    "    selection.add(name, sel)\n",
    "    if cutflow is not None:\n",
    "        cutflow[name] = (\n",
    "            np.sum(selection.all(*selection.names))\n",
    "            if isData\n",
    "            # add up sign of genWeights for MC\n",
    "            else np.sum(signGenWeights[selection.all(*selection.names)])\n",
    "        )\n",
    "\n",
    "\n",
    "presel_events = events\n",
    "# presel_events = events[preselection_cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isData = False\n",
    "signGenWeights = None if isData else np.sign(presel_events[\"genWeight\"])\n",
    "n_events = len(presel_events) if isData else int(np.sum(signGenWeights))\n",
    "selection = PackedSelection()\n",
    "weights = Weights(len(events), storeIndividual=True)\n",
    "year = \"2018\"\n",
    "\n",
    "cutflow = {}\n",
    "cutflow[\"presel\"] = len(presel_events)\n",
    "selection_args = (selection, cutflow, isData, signGenWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MU_PDGID = 13\n",
    "\n",
    "muon_selection = {\n",
    "    \"Id\": \"tight\",\n",
    "    \"pt\": 60,\n",
    "    \"eta\": 2.4,\n",
    "    \"miniPFRelIso_all\": 0.1,\n",
    "    \"dxy\": 0.2,\n",
    "    \"count\": 1,\n",
    "    \"delta_trigObj\": 0.15,\n",
    "}\n",
    "\n",
    "ak8_jet_selection = {\n",
    "    \"pt\": 200,\n",
    "    \"msd\": [50, 250],\n",
    "    \"eta\": 2.5,\n",
    "    \"delta_phi_muon\": 2,\n",
    "    \"jetId\": nanoaod.FatJet.TIGHT,\n",
    "}\n",
    "\n",
    "btagWPs = {\"2016APV\": 0.6001, \"2016\": 0.5847, \"2017\": 0.4506, \"2018\": 0.4168}\n",
    "\n",
    "ak4_jet_selection = {\n",
    "    \"pt\": 30,  # from JME-18-002\n",
    "    \"eta\": 2.4,\n",
    "    \"delta_phi_muon\": 2,\n",
    "    \"jetId\": \"tight\",\n",
    "    \"puId\": 4,  # loose pileup ID\n",
    "    \"btagWP\": btagWPs,\n",
    "    \"ht\": 250,\n",
    "    \"num\": 2,\n",
    "    \"closest_muon_dr\": 0.4,\n",
    "    \"closest_muon_ptrel\": 25,\n",
    "}\n",
    "\n",
    "met_selection = {\"pt\": 50}\n",
    "\n",
    "lepW_selection = {\"pt\": 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muon = events.Muon\n",
    "# 1024 - Mu50 trigger (https://algomez.web.cern.ch/algomez/testWeb/PFnano_content_v02.html#TrigObj)\n",
    "trigObj_muon = events.TrigObj[(events.TrigObj.id == MU_PDGID) * (events.TrigObj.filterBits >= 1024)]\n",
    "\n",
    "muon_selector = (\n",
    "    (muon[f\"{muon_selection['Id']}Id\"])\n",
    "    * (muon.pt > muon_selection[\"pt\"])\n",
    "    * (np.abs(muon.eta) < muon_selection[\"eta\"])\n",
    "    * (muon.miniPFRelIso_all < muon_selection[\"miniPFRelIso_all\"])\n",
    "    * (np.abs(muon.dxy) < muon_selection[\"dxy\"])\n",
    ")\n",
    "\n",
    "muon_selector = muon_selector * (\n",
    "    ak.count(events.Muon.pt[muon_selector], axis=1) == muon_selection[\"count\"]\n",
    ")\n",
    "muon = ak.pad_none(muon[muon_selector], 1, axis=1)[:, 0]\n",
    "\n",
    "muon_selector = ak.any(muon_selector, axis=1)\n",
    "muon_selector = muon_selector * ak.any(\n",
    "    np.abs(muon.delta_r(trigObj_muon)) <= muon_selection[\"delta_trigObj\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "add_selection(\"muon\", muon_selector, *selection_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# met\n",
    "met = events.MET\n",
    "met_sel = met.pt >= met_selection[\"pt\"]\n",
    "\n",
    "# metfilters = np.ones(len(events), dtype=\"bool\")\n",
    "# metfilterkey = \"data\" if isData else \"mc\"\n",
    "# for mf in self.metfilters[year][metfilterkey]:\n",
    "#     if mf in events.Flag.fields:\n",
    "#         metfilters = metfilters & events.Flag[mf]\n",
    "\n",
    "# add_selection(\"met\", met_selection * metfilters, *selection_args)\n",
    "add_selection(\"met\", met_sel, *selection_args)\n",
    "\n",
    "# leptonic W selection\n",
    "add_selection(\"lepW\", (met + muon).pt >= lepW_selection[\"pt\"], *selection_args)\n",
    "# add_selection(\"lepW\", met.pt + muon.pt >= 100, *selection_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak4_jets = events.Jet\n",
    "\n",
    "ak4_jet_selector_no_btag = (\n",
    "    ak4_jets.isTight\n",
    "    # pileup ID should only be applied for pT < 50 jets (https://twiki.cern.ch/twiki/bin/view/CMS/PileupJetIDUL)\n",
    "    * ((ak4_jets.puId % 2 == 1) + (ak4_jets.pt >= 50))\n",
    "    * (ak4_jets.pt > ak4_jet_selection[\"pt\"])\n",
    "    * (np.abs(ak4_jets.eta) < ak4_jet_selection[\"eta\"])\n",
    "    * (np.abs(ak4_jets.delta_phi(muon)) < ak4_jet_selection[\"delta_phi_muon\"])\n",
    ")\n",
    "\n",
    "ak4_jet_selector = ak4_jet_selector_no_btag * (\n",
    "    ak4_jets.btagDeepFlavB > ak4_jet_selection[\"btagWP\"][year]\n",
    ")\n",
    "\n",
    "ak4_selection = (\n",
    "    (ak.any(ak4_jet_selector, axis=1))\n",
    "    * (ak.sum(ak4_jet_selector_no_btag, axis=1) >= ak4_jet_selection[\"num\"])\n",
    "    * (ak.sum(ak4_jets[ak4_jet_selector].pt, axis=1) >= 250)\n",
    ")\n",
    "\n",
    "# add_selection(\"ak4_jet\", ak.any(ak4_jet_selector, axis=1), *selection_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pileup ID effect\n",
    "\n",
    "# unmatched\n",
    "np.sum(top_match_dict[\"unmatched\"] * ak4_selection[select])\n",
    "print(166 / 170)\n",
    "\n",
    "# w matched\n",
    "np.sum(top_match_dict[\"w_matched\"] * ak4_selection[select])\n",
    "print(10 / 10)\n",
    "\n",
    "# top matched\n",
    "np.sum(top_match_dict[\"top_matched\"] * ak4_selection[select])\n",
    "print(21 / 21)\n",
    "\n",
    "# qcd (removing muon selection, otherwise there are no events)\n",
    "print(6762 / 7168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = selection.all(*selection.names)\n",
    "muon_j_dr = muon.delta_r(events.Jet[events.Jet.isTight])\n",
    "min_muon_j_dr = ak.min(muon_j_dr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jecs = {\n",
    "    \"JES\": \"JES_jes\",\n",
    "    \"JER\": \"JER\",\n",
    "}\n",
    "\n",
    "jec_vars = [\"pt\"]  # vars we're saving that are affected by JECs\n",
    "\n",
    "fatjets, jec_shifted_vars = corrections.get_jec_jets(events, \"2018\", False, jecs)\n",
    "# jmsr_shifted_vars = corrections.get_jmsr(fatjets, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_jets = 2\n",
    "\n",
    "pt_cuts = []\n",
    "\n",
    "for pts in jec_shifted_vars[\"pt\"].values():\n",
    "    pt_cut = np.prod(\n",
    "        pad_val(\n",
    "            (pts > ak8_jet_selection[\"pt\"]),\n",
    "            num_jets,\n",
    "            False,\n",
    "            axis=1,\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    pt_cuts.append(pt_cut)\n",
    "\n",
    "pt_cut = np.any(pt_cuts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jmsValues = {}\n",
    "jmrValues = {}\n",
    "\n",
    "# https://github.com/cms-nanoAOD/nanoAOD-tools/blob/959c9ffb084bc974fb26ba2db41e3369cee04ae7/python/postprocessing/modules/jme/jetmetHelperRun2.py#L85-L110\n",
    "\n",
    "# jet mass resolution: https://twiki.cern.ch/twiki/bin/view/CMS/JetWtagging\n",
    "# nominal, down, up (these are switched in the github!!!)\n",
    "jmrValues[\"msoftdrop\"] = {\n",
    "    \"2016\": [1.0, 0.8, 1.2],\n",
    "    \"2017\": [1.09, 1.04, 1.14],\n",
    "    # Use 2017 values for 2018 until 2018 are released\n",
    "    \"2018\": [1.09, 1.04, 1.14],\n",
    "}\n",
    "\n",
    "# jet mass scale\n",
    "# W-tagging PUPPI softdrop JMS values: https://twiki.cern.ch/twiki/bin/view/CMS/JetWtagging\n",
    "# 2016 values\n",
    "jmsValues[\"msoftdrop\"] = {\n",
    "    \"2016\": [1.00, 0.9906, 1.0094],  # nominal, down, up\n",
    "    \"2017\": [0.982, 0.978, 0.986],\n",
    "    # Use 2017 values for 2018 until 2018 are released\n",
    "    \"2018\": [0.982, 0.978, 0.986],\n",
    "}\n",
    "\n",
    "# https://github.com/cmantill/NanoNN/blob/6bd117357e2d7ec66866b5f74790e747411efcad/python/producers/hh4bProducer.py#L154-L159\n",
    "\n",
    "# nominal, down, up\n",
    "jmrValues[\"particleNet_mass\"] = {\n",
    "    \"2016\": [1.028, 1.007, 1.063],\n",
    "    \"2017\": [1.026, 1.009, 1.059],\n",
    "    \"2018\": [1.031, 1.006, 1.075],\n",
    "}\n",
    "jmsValues[\"particleNet_mass\"] = {\n",
    "    \"2016\": [1.00, 0.998, 1.002],\n",
    "    \"2017\": [1.002, 0.996, 1.008],\n",
    "    \"2018\": [0.994, 0.993, 1.001],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jmsr_vars = [\"msoftdrop\", \"particleNet_mass\"]\n",
    "year = \"2018\"\n",
    "\n",
    "jmsr_shifted_vars = {}\n",
    "\n",
    "for mkey in jmsr_vars:\n",
    "    tdict = {}\n",
    "\n",
    "    mass = utils.pad_val(fatjets[mkey], num_jets, axis=1)\n",
    "\n",
    "    np.random.seed(42)\n",
    "    smearing = np.random.normal(size=mass.shape)\n",
    "    # scale to JMR nom, down, up (minimum at 0)\n",
    "    jmr_nom, jmr_down, jmr_up = [\n",
    "        (smearing * max(jmrValues[mkey][year][i] - 1, 0) + 1) for i in range(3)\n",
    "    ]\n",
    "    jms_nom, jms_down, jms_up = jmsValues[mkey][year]\n",
    "\n",
    "    mass_jms = mass * jms_nom\n",
    "    mass_jmr = mass * jmr_nom\n",
    "\n",
    "    tdict[\"\"] = mass_jms * jmr_nom\n",
    "    tdict[\"JMS_down\"] = mass_jmr * jms_down\n",
    "    tdict[\"JMS_up\"] = mass_jmr * jms_up\n",
    "    tdict[\"JMR_down\"] = mass_jms * jmr_down\n",
    "    tdict[\"JMR_up\"] = mass_jms * jmr_up\n",
    "\n",
    "    jmsr_shifted_vars[mkey] = tdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(jmr_nom.reshape(-1), np.linspace(0, 2, 101), histtype=\"step\")\n",
    "_ = plt.hist(jmr_up.reshape(-1), np.linspace(0, 2, 101), histtype=\"step\")\n",
    "_ = plt.hist(jmr_down.reshape(-1), np.linspace(0, 2, 101), histtype=\"step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(mass[mass > 30], np.linspace(0, 300, 101), histtype=\"step\", label=\"Pre\")\n",
    "_ = plt.hist(tdict[\"\"][mass > 30], np.linspace(0, 300, 101), histtype=\"step\", label=\"Post\")\n",
    "_ = plt.hist(\n",
    "    tdict[\"JMR_up\"][mass > 30], np.linspace(0, 300, 101), histtype=\"step\", label=\"Post JMR Up\"\n",
    ")\n",
    "_ = plt.hist(\n",
    "    tdict[\"JMR_down\"][mass > 30], np.linspace(0, 300, 101), histtype=\"step\", label=\"Post JMR Down\"\n",
    ")\n",
    "_ = plt.hist(\n",
    "    (mass * jms_nom)[mass > 30], np.linspace(0, 300, 101), histtype=\"step\", label=\"Post JMS\"\n",
    ")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkey = \"msd\"\n",
    "jmsr_vars = [\"msd\", \"particleNet_mass\"]\n",
    "year = \"2018\"\n",
    "\n",
    "jms_nom, jms_down, jms_up = jmsValues[mkey][year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatjets = events.FatJet  # CHANGE TO JEC JETS\n",
    "# fatjets = corrections.get_jec_jets(events, \"2018\")\n",
    "\n",
    "num_jets = 1\n",
    "\n",
    "fatjet_selector = (\n",
    "    (fatjets.pt > ak8_jet_selection[\"pt\"])\n",
    "    # * (fatjets.msoftdrop > ak8_jet_selection[\"msd\"][0])\n",
    "    # * (fatjets.msoftdrop < ak8_jet_selection[\"msd\"][1])\n",
    "    * (np.abs(fatjets.eta) < ak8_jet_selection[\"eta\"])\n",
    "    # * (np.abs(fatjets.delta_phi(muon)) > ak8_jet_selection[\"delta_phi_muon\"])\n",
    "    * (fatjets.jetId > ak8_jet_selection[\"jetId\"])\n",
    ")\n",
    "\n",
    "leading_fatjets = ak.pad_none(fatjets[fatjet_selector], num_jets, axis=1)[:, :num_jets]\n",
    "fatjet_idx = ak.argmax(fatjet_selector, axis=1)  # gets first index which is true\n",
    "fatjet_selector = ak.any(fatjet_selector, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hem_region = {\"eta\": [-3.2, -1.3], \"phi\": [-0.87, -1.57]}\n",
    "hem_region_selector = (\n",
    "    (fatjets.eta > hem_region[\"eta\"][0])\n",
    "    * (fatjets.eta < hem_region[\"eta\"][1])\n",
    "    * (fatjets.phi > hem_region[\"phi\"][0])\n",
    "    * (fatjets.phi < hem_region[\"phi\"][1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak4_jets = events.Jet\n",
    "# ak4_jets = ak.flatten(\n",
    "#     ak.pad_none(events.Jet[ak.argsort(events.Jet.btagDeepB, axis=1)[:, -1:]], 1, axis=1)\n",
    "# )\n",
    "\n",
    "ak4_jet_selector = (\n",
    "    (ak4_jets.jetId > ak4_jet_selection[\"jetId\"])\n",
    "    * (ak4_jets.puId >= ak4_jet_selection[\"puId\"])\n",
    "    * (ak4_jets.pt > ak4_jet_selection[\"pt\"])\n",
    "    * (np.abs(ak4_jets.eta) < ak4_jet_selection[\"eta\"])\n",
    "    * (np.abs(ak4_jets.delta_phi(muon)) < ak4_jet_selection[\"delta_phi_muon\"])\n",
    "    * (ak4_jets.btagDeepB > ak4_jet_selection[\"btagWP\"][\"2018\"])\n",
    ")\n",
    "\n",
    "ak4_jet_selector = ak.any(ak4_jet_selector, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select = ak.fill_none(muon_selector * fatjet_selector * ak4_jet_selector, False)\n",
    "select = ak.fill_none(muon_selector * fatjet_selector, False)\n",
    "presel_events = events[select]\n",
    "leading_fatjets = leading_fatjets[select]\n",
    "fatjet_idx = fatjet_idx[select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, gzip\n",
    "\n",
    "with gzip.open(corrections.get_pog_json(\"jec\", \"2017\"), \"r\") as fin:\n",
    "    jec = json.loads(fin.read().decode(\"utf-8\"))\n",
    "\n",
    "for corr in jec[\"corrections\"]:\n",
    "    print(corr[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(corrections.get_pog_json(\"electron\", \"2017\"), \"r\") as fin:\n",
    "    egm = json.loads(fin.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corr in egm[\"corrections\"]:\n",
    "    print(corr[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"../data/jec_compiled.pkl.gz\", \"rb\") as filehandler:\n",
    "    jmestuff = pickle.load(filehandler)\n",
    "\n",
    "jmestuff[\"jet_factory\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_PDGID = 1\n",
    "b_PDGID = 5\n",
    "g_PDGID = 21\n",
    "TOP_PDGID = 6\n",
    "\n",
    "ELE_PDGID = 11\n",
    "vELE_PDGID = 12\n",
    "MU_PDGID = 13\n",
    "vMU_PDGID = 14\n",
    "TAU_PDGID = 15\n",
    "vTAU_PDGID = 16\n",
    "\n",
    "Z_PDGID = 23\n",
    "W_PDGID = 24\n",
    "HIGGS_PDGID = 25\n",
    "\n",
    "b_PDGIDS = [511, 521, 523]\n",
    "\n",
    "GRAV_PDGID = 39\n",
    "\n",
    "GEN_FLAGS = [\"fromHardProcess\", \"isLastCopy\"]\n",
    "\n",
    "FILL_NONE_VALUE = -99999\n",
    "\n",
    "\n",
    "skim_vars = {\n",
    "    \"eta\": \"eta\",\n",
    "    \"phi\": \"phi\",\n",
    "    \"mass\": \"mass\",\n",
    "    \"pt\": \"pt\",\n",
    "}\n",
    "\n",
    "# finding the two gen tops\n",
    "presel_events = events[select]\n",
    "tops = presel_events.GenPart[\n",
    "    (abs(presel_events.GenPart.pdgId) == TOP_PDGID) * presel_events.GenPart.hasFlags(GEN_FLAGS)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaR = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops_children = tops.distinctChildren\n",
    "tops_children = tops_children[tops_children.hasFlags(GEN_FLAGS)]\n",
    "ws = ak.flatten(tops_children[np.abs(tops_children.pdgId) == W_PDGID], axis=2)\n",
    "had_top_sel = np.all(np.abs(ws.children.pdgId) <= 5, axis=2)\n",
    "had_ws = ak.flatten(ws[had_top_sel])\n",
    "had_tops = ak.flatten(tops[had_top_sel])\n",
    "had_top_children = ak.flatten(tops_children[had_top_sel], axis=1)\n",
    "had_bs = had_top_children[np.abs(had_top_children.pdgId) == 5]\n",
    "# add_selection(\n",
    "#     \"hadronic bs\", np.any(had_bs.pdgId, axis=1), selection, cutflow, isData, signGenWeights\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "had_w_jet_match = ak.fill_none(\n",
    "    ak.all(had_ws.children.delta_r(leading_fatjets[:, 0]) < deltaR, axis=1), False\n",
    ")\n",
    "had_b_jet_match = ak.flatten(\n",
    "    pad_val(had_bs.delta_r(leading_fatjets[:, 0]) < deltaR, 1, False, axis=1, to_numpy=False)\n",
    ")\n",
    "merged_top_jet_match = had_w_jet_match * had_b_jet_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_match_dict = {\n",
    "    \"top_matched\": had_w_jet_match * had_b_jet_match,\n",
    "    \"w_matched\": had_w_jet_match * ~had_b_jet_match,\n",
    "    \"unmatched\": ~had_w_jet_match,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(top_match_dict[\"top_matched\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering and Lund plane splittings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_top_events = presel_events[merged_top_jet_match]\n",
    "had_top_jets = merged_top_events.FatJet[:, 0]\n",
    "\n",
    "merged_ak8_pfcands = merged_top_events.FatJetPFCands\n",
    "merged_ak8_pfcands = merged_ak8_pfcands[\n",
    "    merged_ak8_pfcands.jetIdx == fatjet_idx[merged_top_jet_match]\n",
    "]\n",
    "merged_pfcands = merged_top_events.PFCands[merged_ak8_pfcands.pFCandsIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_pfcands_vector_ptetaphi = ak.Array(\n",
    "    [\n",
    "        [{kin_key: cand[kin_key] for kin_key in skim_vars} for cand in event_cands]\n",
    "        for event_cands in merged_pfcands\n",
    "    ],\n",
    "    with_name=\"PtEtaPhiMLorentzVector\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jet definitions\n",
    "dR = 0.8\n",
    "cadef = fastjet.JetDefinition(fastjet.cambridge_algorithm, dR)\n",
    "ktdef = fastjet.JetDefinition(fastjet.kt_algorithm, dR)\n",
    "\n",
    "num_prongs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster first with kT\n",
    "kt_clustering = fastjet.ClusterSequence(merged_pfcands_vector_ptetaphi, ktdef)\n",
    "kt_subjets = kt_clustering.exclusive_jets(num_prongs)\n",
    "kt_subjets_pt = np.sqrt(kt_subjets.px**2 + kt_subjets.py**2)\n",
    "kt_subjet_consts = kt_clustering.exclusive_jets_constituents(3)\n",
    "\n",
    "# then re-cluster with CA\n",
    "# won't need to flatten once https://github.com/scikit-hep/fastjet/pull/145 is released\n",
    "ca_clustering = fastjet.ClusterSequence(ak.flatten(kt_subjet_consts, axis=1), cadef)\n",
    "lds = ak.flatten(ca_clustering.exclusive_jets_lund_declusterings(1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kt_subjets_vec = ak.zip(\n",
    "    {\"x\": kt_subjets.px, \"y\": kt_subjets.py, \"z\": kt_subjets.pz, \"t\": kt_subjets.E},\n",
    "    with_name=\"LorentzVector\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subjet matching and pT extrapolation uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_dR = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_quarks = ak.concatenate(\n",
    "    [had_bs[merged_top_jet_match][:, :1], had_ws.children[merged_top_jet_match][:, :2]], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_quarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_matched = []\n",
    "sj_matched_idx = []\n",
    "\n",
    "for i in range(num_prongs):\n",
    "    sj_q_dr = kt_subjets_vec.delta_r(gen_quarks[:, i])\n",
    "    sj_matched.append(ak.min(sj_q_dr, axis=1) <= matching_dR)\n",
    "    sj_matched_idx.append(ak.argmin(sj_q_dr, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_matched = np.array(sj_matched).T\n",
    "sj_matched_idx = np.array(sj_matched_idx).T\n",
    "\n",
    "sj_matched_idx_mask = np.copy(sj_matched_idx)\n",
    "sj_matched_idx_mask[~sj_matched] = -1\n",
    "double_matched_event = np.any(\n",
    "    [np.sum(sj_matched_idx_mask == i, axis=1) > 1 for i in range(3)], axis=0\n",
    ").astype(int)\n",
    "unmatched_quarks = np.sum(~sj_matched, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calc SFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = uproot.open(\"../corrections/ratio_feb20.root\")\n",
    "\n",
    "# 3D histogram: [subjet_pt, ln(0.8/Delta), ln(kT/GeV)]\n",
    "ratio_nom = f[\"ratio_nom\"].to_numpy()\n",
    "ratio_nom_errs = f[\"ratio_nom\"].errors()\n",
    "ratio_nom_edges = ratio_nom[1:]\n",
    "ratio_nom = ratio_nom[0]\n",
    "\n",
    "zero_vals = ratio_nom == 0\n",
    "ratio_nom[zero_vals] = 1\n",
    "ratio_nom_errs[zero_vals] = 0\n",
    "\n",
    "ratio_shape = f[\"ratio_nom\"].values().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pt_bin = ratio_nom_edges[0][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(ratio_nom[5].T[::-1], extent=[-1, 8, -5, 6.9], cmap=\"turbo\")\n",
    "plt.xlabel(r\"ln$(0.8/\\Delta)$\")\n",
    "plt.ylabel(r\"ln$(k_T/GeV)$\")\n",
    "_ = plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxp = 0\n",
    "# for i in range(ratio_shape[1]):\n",
    "#     for j in range(ratio_shape[2]):\n",
    "#         if len(pt_extrap_params[i][j]) > maxp:\n",
    "#             maxp = len(pt_extrap_params[i][j])\n",
    "\n",
    "# maxp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_extrap_lookups = {\"params\": [], \"errs\": [], \"sys_up_params\": [], \"sys_down_params\": []}\n",
    "max_fparams = 4  # max order (+1) of functions\n",
    "\n",
    "\n",
    "def _np_pad(arr: np.ndarray, target: int = max_fparams):\n",
    "    return np.pad(arr, ((0, target - len(arr))))\n",
    "\n",
    "\n",
    "for i in range(ratio_shape[1]):\n",
    "    for key in pt_extrap_lookups:\n",
    "        pt_extrap_lookups[key].append([])\n",
    "\n",
    "    for j in range(ratio_shape[2]):\n",
    "        func = f[\"pt_extrap\"][f\"func_{i + 1}_{j + 1}\"]\n",
    "        pt_extrap_lookups[\"params\"][-1].append(\n",
    "            _np_pad(func._members[\"fFormula\"]._members[\"fClingParameters\"])\n",
    "        )\n",
    "        pt_extrap_lookups[\"errs\"][-1].append(_np_pad(func._members[\"fParErrors\"]))\n",
    "        pt_extrap_lookups[\"sys_up_params\"][-1].append(\n",
    "            _np_pad(\n",
    "                f[\"pt_extrap\"][f\"func_sys_tot_up_{i + 1}_{j + 1}\"]\n",
    "                ._members[\"fFormula\"]\n",
    "                ._members[\"fClingParameters\"]\n",
    "            )\n",
    "        )\n",
    "        pt_extrap_lookups[\"sys_down_params\"][-1].append(\n",
    "            _np_pad(\n",
    "                f[\"pt_extrap\"][f\"func_sys_tot_down_{i + 1}_{j + 1}\"]\n",
    "                ._members[\"fFormula\"]\n",
    "                ._members[\"fClingParameters\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "for key in pt_extrap_lookups:\n",
    "    pt_extrap_lookups[key] = dense_lookup(np.array(pt_extrap_lookups[key]), ratio_nom_edges[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sf_toys = 100\n",
    "np.random.seed(42)\n",
    "rand_noise = np.random.normal(size=[n_sf_toys, *ratio_nom.shape])\n",
    "\n",
    "# produces array of shape ``[n_sf_toys, subjet_pt bins, ln(0.8/Delta) bins, ln(kT/GeV) bins]``\n",
    "ratio_nom_smeared = ratio_nom + (ratio_nom_errs * rand_noise)\n",
    "ratio_smeared_lookups = [\n",
    "    dense_lookup(ratio_nom_smeared[i], ratio_nom_edges) for i in range(n_sf_toys)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save offsets to recover awkward structure later\n",
    "ld_offsets = lds.kt.layout.offsets\n",
    "flat_logD = np.log(0.8 / ak.flatten(lds).Delta).to_numpy()\n",
    "flat_logkt = np.log(ak.flatten(lds).kt).to_numpy()\n",
    "# repeat subjet pt for each lund declustering\n",
    "flat_subjet_pt = np.repeat(ak.flatten(kt_subjets_pt), ak.count(lds.kt, axis=1)).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_pt_sel = flat_subjet_pt > max_pt_bin\n",
    "hpt_logD = flat_logD[high_pt_sel]\n",
    "hpt_logkt = flat_logkt[high_pt_sel]\n",
    "hpt_sjpt = flat_subjet_pt[high_pt_sel]  # change this to 1/sjpt for next iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store polynomial orders for pT extrapolation\n",
    "sj_pt_orders = np.array([np.power(hpt_sjpt, i) for i in range(max_fparams)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_max, clip_min = 10, 0.1\n",
    "pt_lookup = pt_extrap_lookups[\"params\"]\n",
    "params = pt_lookup(hpt_logD, hpt_logkt)\n",
    "pt_extrap_vals = np.maximum(np.minimum(np.sum(params * sj_pt_orders, axis=1), clip_max), clip_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(\n",
    "    np.log10(np.maximum(np.sum(params * sj_pt_orders, axis=1), 0.1)),\n",
    "    np.linspace(-1, 1, 21),\n",
    "    histtype=\"step\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_nom_vals = ratio_smeared_lookups[0](flat_subjet_pt, flat_logD, flat_logkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_nom_vals[high_pt_sel] = pt_extrap_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_vals = []\n",
    "\n",
    "# could be parallelised but not sure if memory / time trade-off is worth it\n",
    "for i, ratio_nom_lookup in enumerate(ratio_smeared_lookups):\n",
    "    ratio_nom_vals = ratio_nom_lookup(flat_subjet_pt, flat_logD, flat_logkt)\n",
    "    reshaped_ratio_nom_vals = ak.Array(\n",
    "        ak.layout.ListOffsetArray64(ld_offsets, ak.layout.NumpyArray(ratio_nom_vals))\n",
    "    )\n",
    "    sf_vals.append(\n",
    "        np.prod(ak.prod(reshaped_ratio_nom_vals, axis=1).to_numpy().reshape(-1, num_prongs), axis=1)\n",
    "    )\n",
    "\n",
    "sf_vals = np.array(sf_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_vals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old way of uncertainty calculation (not taking into account intra-jet correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save offsets to recover awkward structure later\n",
    "ld_offsets = lds.kt.layout.offsets\n",
    "flat_logD = np.log(0.8 / ak.flatten(lds).Delta).to_numpy()\n",
    "flat_logkt = np.log(ak.flatten(lds).kt).to_numpy()\n",
    "# repeat subjet pt for each lund declustering\n",
    "flat_subjet_pt = np.repeat(ak.flatten(kt_subjets_pt), ak.count(lds.kt, axis=1)).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_nom_vals = ratio_nom_lookup(flat_subjet_pt, flat_logD, flat_logkt)\n",
    "ratio_nom_rel_errs = np.nan_to_num(\n",
    "    (ratio_nom_errs_lookup(flat_subjet_pt, flat_logD, flat_logkt) / ratio_nom_vals) ** 2\n",
    ")\n",
    "\n",
    "reshaped_ratio_nom_vals = ak.Array(\n",
    "    ak.layout.ListOffsetArray64(ld_offsets, ak.layout.NumpyArray(ratio_nom_vals))\n",
    ")\n",
    "reshaped_ratio_nom_rel_errs = ak.Array(\n",
    "    ak.layout.ListOffsetArray64(ld_offsets, ak.layout.NumpyArray(ratio_nom_rel_errs))\n",
    ")\n",
    "\n",
    "sf_nom_vals = np.prod(\n",
    "    ak.prod(reshaped_ratio_nom_vals, axis=1).to_numpy().reshape(-1, num_prongs), axis=1\n",
    ")\n",
    "sf_nom_errs = (\n",
    "    np.sqrt(\n",
    "        np.sum(\n",
    "            ak.sum(reshaped_ratio_nom_rel_errs, axis=1).to_numpy().reshape(-1, num_prongs), axis=1\n",
    "        )\n",
    "    )\n",
    "    * sf_nom_vals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_nom_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_nom_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ld_indices(vals, edges):\n",
    "    indices = []\n",
    "\n",
    "    for val, edge in zip(vals, edges):\n",
    "        indices.append(\n",
    "            np.clip(\n",
    "                np.searchsorted(edge, val, side=\"right\") - 1,\n",
    "                0,\n",
    "                len(edge) - 2,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lund plane bins\n",
    "inds = get_ld_indices((flat_subjet_pt, flat_logD, flat_logkt), ratio_nom_edges)\n",
    "# convert 3D indices to single scalar\n",
    "scalar_inds = np.ravel_multi_index(inds, ratio_nom.shape)\n",
    "reshaped_inds = ak.Array(ak.layout.ListOffsetArray64(ld_offsets, ak.layout.NumpyArray(scalar_inds)))\n",
    "# reshaped_inds = pad_val(reshaped_inds, 40, -1, axis=1, clip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = 0\n",
    "for row in reshaped_inds:\n",
    "    _, counts = np.unique(row, return_counts=True)\n",
    "    dups += np.sum(counts - 1)\n",
    "\n",
    "print(f\"Fraction of duplicate splittings: {dups / len(flat_logD):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15adc7883e707560d0d9727709639b8fe3f3cff1f197d2d643742923ff23a29c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
